{
  "0xk1h0/PentestGPT": {
    "owner": "0xk1h0",
    "repo": "PentestGPT",
    "ref": "a6edb3053ef1b3e0c36286306bc95cd8e6ceb026",
    "num_llm_files": 17,
    "providers": [
      "gemini",
      "langchain",
      "mistral",
      "openai"
    ],
    "files": [
      {
        "file_path": "0xk1h0-PentestGPT-a6edb30/config/chatgpt_config_sample.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "0xk1h0-PentestGPT-a6edb30/pentestgpt/config/chat_config.py",
        "providers": [
          "gemini",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "0xk1h0-PentestGPT-a6edb30/pentestgpt/config/chatgpt_config_sample.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "0xk1h0-PentestGPT-a6edb30/pentestgpt/extract_cookie.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "0xk1h0-PentestGPT-a6edb30/pentestgpt/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "0xk1h0-PentestGPT-a6edb30/pentestgpt/test_connection.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "0xk1h0-PentestGPT-a6edb30/pentestgpt/utils/APIs/azure_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "0xk1h0-PentestGPT-a6edb30/pentestgpt/utils/APIs/chatgpt_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "0xk1h0-PentestGPT-a6edb30/pentestgpt/utils/APIs/gemini_api.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "0xk1h0-PentestGPT-a6edb30/pentestgpt/utils/APIs/gpt4all_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "0xk1h0-PentestGPT-a6edb30/pentestgpt/utils/APIs/module_import.py",
        "providers": [
          "gemini",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "0xk1h0-PentestGPT-a6edb30/pentestgpt/utils/chatgpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "0xk1h0-PentestGPT-a6edb30/pentestgpt/utils/llm_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "0xk1h0-PentestGPT-a6edb30/pentestgpt/utils/pentest_gpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "0xk1h0-PentestGPT-a6edb30/pentestgpt/utils/pentest_gpt_rebuilt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "0xk1h0-PentestGPT-a6edb30/pentestgpt/utils/vectorDB.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "0xk1h0-PentestGPT-a6edb30/tests/test_langfuse.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "Abonia1/Context-Based-LLMChatbot": {
    "owner": "Abonia1",
    "repo": "Context-Based-LLMChatbot",
    "ref": "f21f7e157157d235e0b9ddd2fc997a7d33096da1",
    "num_llm_files": 2,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "Abonia1-Context-Based-LLMChatbot-f21f7e1/chat.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Abonia1-Context-Based-LLMChatbot-f21f7e1/config.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "AgentJ-WR/Private-GPT-Flask": {
    "owner": "AgentJ-WR",
    "repo": "Private-GPT-Flask",
    "ref": "328bbc320a6dacc1a120cfcaf9c88e0fd001b381",
    "num_llm_files": 2,
    "providers": [
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "AgentJ-WR-Private-GPT-Flask-328bbc3/ingest.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "AgentJ-WR-Private-GPT-Flask-328bbc3/privateGPT.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "AgentValley/chromadb-chatbot": {
    "owner": "AgentValley",
    "repo": "chromadb-chatbot",
    "ref": "48c10aa15ae4c0896fc282c4f1c4efdfccbd53bf",
    "num_llm_files": 8,
    "providers": [
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "AgentValley-chromadb-chatbot-48c10aa/chatbot/kb.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AgentValley-chromadb-chatbot-48c10aa/chatbot/profile.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AgentValley-chromadb-chatbot-48c10aa/chatbot/runner.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AgentValley-chromadb-chatbot-48c10aa/const.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AgentValley-chromadb-chatbot-48c10aa/routes/message.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AgentValley-chromadb-chatbot-48c10aa/routes/upload.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "AgentValley-chromadb-chatbot-48c10aa/tools/chat_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AgentValley-chromadb-chatbot-48c10aa/tools/load_data.py",
        "providers": [
          "llama",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "1Panel-dev/MaxKB": {
    "owner": "1Panel-dev",
    "repo": "MaxKB",
    "ref": "v2",
    "num_llm_files": 195,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "langchain",
      "llama",
      "mistral",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/chat_pipeline/step/chat_step/i_chat_step.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/chat_pipeline/step/chat_step/impl/base_chat_step.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/chat_pipeline/step/generate_human_message_step/i_generate_human_message_step.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/chat_pipeline/step/generate_human_message_step/impl/base_generate_human_message_step.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/chat_pipeline/step/reset_problem_step/impl/base_reset_problem_step.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/flow/loop_workflow_manage.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/flow/step_node/ai_chat_step_node/impl/base_chat_node.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/flow/step_node/form_node/impl/base_form_node.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/flow/step_node/image_generate_step_node/impl/base_image_generate_node.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/flow/step_node/image_to_video_step_node/impl/base_image_to_video_node.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/flow/step_node/image_understand_step_node/impl/base_image_understand_node.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/flow/step_node/intent_node/impl/base_intent_node.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/flow/step_node/mcp_node/impl/base_mcp_node.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/flow/step_node/parameter_extraction_node/impl/base_parameter_extraction_node.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/flow/step_node/question_node/impl/base_question_node.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/flow/step_node/reranker_node/impl/base_reranker_node.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/flow/step_node/text_to_video_step_node/impl/base_text_to_video_node.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/flow/step_node/video_understand_step_node/impl/base_video_understand_node.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/flow/tools.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/flow/workflow_manage.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/models/application_chat.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/application/serializers/application.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/chat/api/chat_authentication_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/chat/serializers/chat.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/chat/urls.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/chat/views/chat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/common/event/listener_manage.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/common/handle/impl/response/openai_to_response.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/common/handle/impl/text/pdf_split_handle.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/common/init/init_template.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/knowledge/task/generate.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/knowledge/vector/base_vector.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/knowledge/vector/pg_vector.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/local_model/serializers/model_apply_serializers.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/maxkb/wsgi/web.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/constants/model_provider_constants.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aliyun_bai_lian_model_provider/aliyun_bai_lian_model_provider.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aliyun_bai_lian_model_provider/credential/llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aliyun_bai_lian_model_provider/credential/reranker.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aliyun_bai_lian_model_provider/model/embedding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aliyun_bai_lian_model_provider/model/image.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aliyun_bai_lian_model_provider/model/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aliyun_bai_lian_model_provider/model/reranker.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aliyun_bai_lian_model_provider/model/stt/omni_stt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aliyun_bai_lian_model_provider/model/tti.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aliyun_bai_lian_model_provider/model/ttv.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/anthropic_model_provider/anthropic_model_provider.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/anthropic_model_provider/credential/image.py",
        "providers": [
          "anthropic",
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/anthropic_model_provider/credential/llm.py",
        "providers": [
          "anthropic",
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/anthropic_model_provider/model/image.py",
        "providers": [
          "anthropic",
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/anthropic_model_provider/model/llm.py",
        "providers": [
          "anthropic",
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aws_bedrock_model_provider/aws_bedrock_model_provider.py",
        "providers": [
          "anthropic",
          "cohere",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aws_bedrock_model_provider/credential/image.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aws_bedrock_model_provider/credential/llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aws_bedrock_model_provider/credential/reranker.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aws_bedrock_model_provider/model/embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aws_bedrock_model_provider/model/image.py",
        "providers": [
          "anthropic",
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aws_bedrock_model_provider/model/llm.py",
        "providers": [
          "anthropic",
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/aws_bedrock_model_provider/model/reranker.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/azure_model_provider/azure_model_provider.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/azure_model_provider/credential/embedding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/azure_model_provider/credential/image.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/azure_model_provider/credential/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/azure_model_provider/credential/stt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/azure_model_provider/credential/tti.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/azure_model_provider/credential/tts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/azure_model_provider/model/azure_chat_model.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/azure_model_provider/model/embedding.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/azure_model_provider/model/image.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/azure_model_provider/model/stt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/azure_model_provider/model/tti.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/azure_model_provider/model/tts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/base_chat_open_ai.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/deepseek_model_provider/credential/llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/deepseek_model_provider/model/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/docker_ai_model_provider/credential/image.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/docker_ai_model_provider/credential/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/docker_ai_model_provider/credential/reranker.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/docker_ai_model_provider/docker_ai_model_provider.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/docker_ai_model_provider/model/embedding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/docker_ai_model_provider/model/image.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/docker_ai_model_provider/model/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/docker_ai_model_provider/model/reranker.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/docker_ai_model_provider/model/stt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/docker_ai_model_provider/model/tti.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/docker_ai_model_provider/model/tts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/gemini_model_provider/credential/embedding.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/gemini_model_provider/credential/image.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/gemini_model_provider/credential/llm.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/gemini_model_provider/credential/stt.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/gemini_model_provider/gemini_model_provider.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/gemini_model_provider/model/embedding.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/gemini_model_provider/model/image.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/gemini_model_provider/model/llm.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/gemini_model_provider/model/stt.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/kimi_model_provider/credential/llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/kimi_model_provider/model/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/local_model_provider/credential/reranker/model.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/local_model_provider/model/embedding/model.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/local_model_provider/model/embedding/web.py",
        "providers": [
          "anthropic",
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/local_model_provider/model/reranker/model.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/local_model_provider/model/reranker/web.py",
        "providers": [
          "anthropic",
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/ollama_model_provider/credential/embedding.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/ollama_model_provider/credential/image.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/ollama_model_provider/credential/llm.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/ollama_model_provider/credential/reranker.py",
        "providers": [
          "langchain",
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/ollama_model_provider/model/embedding.py",
        "providers": [
          "langchain",
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/ollama_model_provider/model/image.py",
        "providers": [
          "langchain",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/ollama_model_provider/model/llm.py",
        "providers": [
          "langchain",
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/ollama_model_provider/model/reranker.py",
        "providers": [
          "langchain",
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/ollama_model_provider/ollama_model_provider.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/openai_model_provider/credential/embedding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/openai_model_provider/credential/image.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/openai_model_provider/credential/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/openai_model_provider/credential/stt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/openai_model_provider/credential/tti.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/openai_model_provider/credential/tts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/openai_model_provider/model/embedding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/openai_model_provider/model/image.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/openai_model_provider/model/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/openai_model_provider/model/stt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/openai_model_provider/model/tti.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/openai_model_provider/model/tts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/openai_model_provider/openai_model_provider.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/regolo_model_provider/credential/image.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/regolo_model_provider/credential/llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/regolo_model_provider/model/embedding.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/regolo_model_provider/model/image.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/regolo_model_provider/model/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/regolo_model_provider/model/tti.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/regolo_model_provider/regolo_model_provider.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/siliconCloud_model_provider/credential/image.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/siliconCloud_model_provider/credential/llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/siliconCloud_model_provider/credential/reranker.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/siliconCloud_model_provider/model/embedding.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/siliconCloud_model_provider/model/image.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/siliconCloud_model_provider/model/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/siliconCloud_model_provider/model/reranker.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/siliconCloud_model_provider/model/stt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/siliconCloud_model_provider/model/tti.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/siliconCloud_model_provider/model/tts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/siliconCloud_model_provider/siliconCloud_model_provider.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/tencent_cloud_model_provider/credential/llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/tencent_cloud_model_provider/model/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/tencent_cloud_model_provider/tencent_cloud_model_provider.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/tencent_model_provider/credential/image.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/tencent_model_provider/credential/llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/tencent_model_provider/model/embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/tencent_model_provider/model/hunyuan.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/tencent_model_provider/model/image.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/tencent_model_provider/model/llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/vllm_model_provider/credential/embedding.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/vllm_model_provider/credential/image.py",
        "providers": [
          "langchain",
          "vllm"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/vllm_model_provider/credential/llm.py",
        "providers": [
          "langchain",
          "vllm"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/vllm_model_provider/credential/reranker.py",
        "providers": [
          "langchain",
          "vllm"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/vllm_model_provider/credential/whisper_stt.py",
        "providers": [
          "langchain",
          "vllm"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/vllm_model_provider/model/embedding.py",
        "providers": [
          "langchain",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/vllm_model_provider/model/image.py",
        "providers": [
          "langchain",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/vllm_model_provider/model/llm.py",
        "providers": [
          "langchain",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/vllm_model_provider/model/reranker.py",
        "providers": [
          "cohere",
          "langchain",
          "vllm"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/vllm_model_provider/model/whisper_sst.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/vllm_model_provider/vllm_model_provider.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/volcanic_engine_model_provider/credential/image.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/volcanic_engine_model_provider/credential/llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/volcanic_engine_model_provider/model/embedding.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/volcanic_engine_model_provider/model/image.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/volcanic_engine_model_provider/model/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/volcanic_engine_model_provider/volcanic_engine_model_provider.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/wenxin_model_provider/credential/llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/wenxin_model_provider/model/embedding.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/wenxin_model_provider/model/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/wenxin_model_provider/wenxin_model_provider.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/xf_model_provider/credential/image.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/xf_model_provider/credential/llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/xf_model_provider/model/embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/xf_model_provider/model/image.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/xf_model_provider/model/llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/xinference_model_provider/credential/image.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/xinference_model_provider/credential/llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/xinference_model_provider/credential/reranker.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/xinference_model_provider/model/embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/xinference_model_provider/model/image.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/xinference_model_provider/model/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/xinference_model_provider/model/reranker.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/xinference_model_provider/model/stt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/xinference_model_provider/model/tti.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/xinference_model_provider/model/tts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/xinference_model_provider/xinference_model_provider.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/zhipu_model_provider/credential/image.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/zhipu_model_provider/credential/llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/zhipu_model_provider/model/image.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/zhipu_model_provider/model/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/impl/zhipu_model_provider/model/tti.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/models_provider/serializers/model_apply_serializers.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "1Panel-dev-MaxKB-d33dd45/apps/tools/serializers/tool.py",
        "providers": [
          "langchain"
        ]
      }
    ],
    "error": null
  },
  "All-Hands-AI/OpenHands": {
    "owner": "All-Hands-AI",
    "repo": "OpenHands",
    "ref": "main",
    "num_llm_files": 121,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "groq",
      "litellm",
      "llama",
      "mistral",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/enterprise/enterprise_local/convert_to_env.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/enterprise/experiments/constants.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/enterprise/experiments/experiment_versions/_001_litellm_default_model_experiment.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/enterprise/experiments/experiment_versions/_003_llm_claude4_vs_gpt5_experiment.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/enterprise/experiments/experiment_versions/__init__.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/enterprise/server/constants.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/enterprise/server/routes/api_keys.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/enterprise/server/routes/billing.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/enterprise/storage/saas_settings_store.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/enterprise/tests/unit/test_billing.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/enterprise/tests/unit/test_saas_settings_store.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/EDA/game.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/EDA/run_infer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/algotune/adapter/utils.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/commit0/run_infer.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/discoverybench/eval_utils/eval_w_subhypo_gen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/discoverybench/eval_utils/lm_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/discoverybench/eval_utils/openai_helpers.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/discoverybench/run_infer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/mint/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/multi_swe_bench/run_infer.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/swe_bench/run_infer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/swe_bench/run_infer_interact.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/swe_bench/run_localize.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/swe_bench/scripts/eval/summarize_outputs.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/the_agent_company/run_infer.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/the_agent_company/scripts/summarise_results.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/versicode/inference_utils/api_code_migration.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/versicode/inference_utils/api_test_block_completion.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/versicode/inference_utils/test_block.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/versicode/inference_utils/test_migration.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/versicode/metric/compute_migration_cdc_score.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/visual_swe_bench/run_infer.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/visualwebarena/run_infer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/evaluation/benchmarks/webarena/run_infer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/codeact_agent/codeact_agent.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/codeact_agent/function_calling.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/codeact_agent/tools/bash.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/codeact_agent/tools/browser.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/codeact_agent/tools/condensation_request.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/codeact_agent/tools/finish.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/codeact_agent/tools/ipython.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/codeact_agent/tools/llm_based_edit.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/codeact_agent/tools/str_replace_editor.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/codeact_agent/tools/task_tracker.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/codeact_agent/tools/think.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/loc_agent/function_calling.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/loc_agent/tools/explore_structure.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/loc_agent/tools/search_content.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/readonly_agent/function_calling.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/readonly_agent/readonly_agent.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/readonly_agent/tools/glob.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/readonly_agent/tools/grep.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/agenthub/readonly_agent/tools/view.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/controller/agent.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/controller/agent_controller.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/core/config/arg_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/core/config/llm_config.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/core/config/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/core/exceptions.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/core/logger.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/core/message.py",
        "providers": [
          "groq",
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/events/tool.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/io/json.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/llm/async_llm.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/llm/debug_mixin.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/llm/fn_call_converter.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/llm/llm.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/llm/llm_utils.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/llm/model_features.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/llm/streaming_llm.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/memory/condenser/impl/llm_attention_condenser.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/memory/condenser/impl/structured_summary_condenser.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/memory/conversation_memory.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/resolver/resolver_output.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/runtime/plugins/agent_skills/file_reader/file_readers.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/runtime/plugins/agent_skills/utils/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/security/grayswan/analyzer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/security/grayswan/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/server/mock/listen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/server/routes/public.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/server/services/conversation_service.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/openhands/utils/llm.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/scripts/update_openapi.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/agenthub/test_agents.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/agenthub/test_function_calling.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/agenthub/test_prompt_caching.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/app_server/test_live_status_app_conversation_service.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/app_server/test_sql_app_conversation_info_service.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/app_server/test_sql_app_conversation_start_task_service.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/controller/test_agent_controller.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/core/config/test_arg_parser.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/core/config/test_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/core/config/test_llm_config.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/core/config/test_mcp_settings_merge.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/core/logger/test_logger_litellm.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/core/logger/test_logging.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/core/message/test_message_serialization.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/experiments/test_experiment_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/llm/test_api_connection_error_retry.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/llm/test_litellm_proxy_model_parsing.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/llm/test_llm.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/llm/test_llm_fncall_converter.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/llm/test_model_features.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/mcp/test_mcp_integration.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/memory/condenser/test_condenser.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/memory/test_conversation_memory.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/resolver/github/test_issue_handler_error_handling.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/resolver/github/test_pr_handler_guess_success.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/resolver/gitlab/test_gitlab_issue_handler_error_handling.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/resolver/gitlab/test_gitlab_pr_handler_guess_success.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/security/test_security.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/server/routes/test_conversation_routes.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/server/routes/test_settings_store_functions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/server/routes/test_start_endpoint.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/server/services/test_conversation_service.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/server/session/test_agent_session.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/server/session/test_conversation_init_data.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/server/session/test_session.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/test_conversation_stats.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "OpenHands-OpenHands-bf06b7e/tests/unit/utils/test_environment.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "AntonOsika/gpt-engineer": {
    "owner": "AntonOsika",
    "repo": "gpt-engineer",
    "ref": "main",
    "num_llm_files": 15,
    "providers": [
      "anthropic",
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "AntonOsika-gpt-engineer-a90fcd5/docs/examples/open_llms/langchain_interface.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "AntonOsika-gpt-engineer-a90fcd5/docs/examples/open_llms/openai_api_interface.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AntonOsika-gpt-engineer-a90fcd5/gpt_engineer/applications/cli/main.py",
        "providers": [
          "anthropic",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "AntonOsika-gpt-engineer-a90fcd5/gpt_engineer/benchmark/__main__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "AntonOsika-gpt-engineer-a90fcd5/gpt_engineer/core/ai.py",
        "providers": [
          "anthropic",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "AntonOsika-gpt-engineer-a90fcd5/gpt_engineer/core/default/steps.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "AntonOsika-gpt-engineer-a90fcd5/gpt_engineer/core/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "AntonOsika-gpt-engineer-a90fcd5/gpt_engineer/core/token_usage.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "AntonOsika-gpt-engineer-a90fcd5/gpt_engineer/tools/custom_steps.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "AntonOsika-gpt-engineer-a90fcd5/tests/applications/cli/test_cli_agent.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "AntonOsika-gpt-engineer-a90fcd5/tests/core/default/test_simple_agent.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "AntonOsika-gpt-engineer-a90fcd5/tests/core/default/test_steps.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "AntonOsika-gpt-engineer-a90fcd5/tests/core/test_ai.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "AntonOsika-gpt-engineer-a90fcd5/tests/core/test_salvage_correct_hunks.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "AntonOsika-gpt-engineer-a90fcd5/tests/core/test_token_usage.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "AstrBotDevs/AstrBot": {
    "owner": "AstrBotDevs",
    "repo": "AstrBot",
    "ref": "master",
    "num_llm_files": 26,
    "providers": [
      "anthropic",
      "gemini",
      "groq",
      "llama",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/agent/runners/tool_loop_agent_runner.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/agent/tool.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/config/default.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "llama",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/conversation_mgr.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/knowledge_base/prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/pipeline/process_stage/method/agent_sub_stages/internal.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/provider/entities.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/provider/func_tool_manager.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/provider/manager.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/provider/provider.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/provider/sources/anthropic_source.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/provider/sources/gemini_embedding_source.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/provider/sources/gemini_source.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/provider/sources/gemini_tts_source.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/provider/sources/groq_source.py",
        "providers": [
          "groq",
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/provider/sources/openai_embedding_source.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/provider/sources/openai_source.py",
        "providers": [
          "gemini",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/provider/sources/openai_tts_api_source.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/provider/sources/vllm_rerank_source.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/provider/sources/whisper_api_source.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/provider/sources/whisper_selfhosted_source.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/provider/sources/xinference_stt_provider.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/provider/sources/zhipu_source.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/star/context.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/core/utils/file_extract.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "AstrBotDevs-AstrBot-aa6d07a/astrbot/dashboard/routes/config.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "567-labs/instructor": {
    "owner": "567-labs",
    "repo": "instructor",
    "ref": "main",
    "num_llm_files": 234,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "groq",
      "litellm",
      "llama",
      "mistral",
      "ollama",
      "openai"
    ],
    "files": [
      {
        "file_path": "567-labs-instructor-130c034/examples/anthropic-web-tool/run.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/anthropic/run.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/asyncio-benchmarks/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/auto-ticketer/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/automodel/run.py",
        "providers": [
          "anthropic",
          "cohere",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/avail/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/avail/run_mixtral.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/batch-classification/run-cache.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/batch-classification/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/batch-classification/run_langsmith.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/batch_api/in_memory_batch_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/batch_api/run_batch_test.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/caching/example_diskcache.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/caching/example_redis.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/caching/lru.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/caching/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/caching_prototype/run_real.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/chain-of-density/chain_of_density.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/chain-of-density/finetune.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/citation_with_extraction/citation_fuzzy_match.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/citation_with_extraction/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/citations/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/classification/classifiy_with_validation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/classification/multi_prediction.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/classification/simple_prediction.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/codegen-from-schema/create_fastapi_app.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/codegen-from-schema/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/cohere/cohere.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/crm/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/decimals/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/distilations/three_digit_mul_dispatch.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/extract-table/run_vision.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/extract-table/run_vision_langsmith.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/extract-table/run_vision_org.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/extract-table/run_vision_org_table.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/extract-table/run_vision_receipt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/extract-table/test.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/extracting-pii/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/fastapi_app/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/fastapi_app/script.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/fizzbuzz/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/gpt-engineer/generate.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/gpt-engineer/refactor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/groq/groq_example.py",
        "providers": [
          "groq"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/groq/groq_example2.py",
        "providers": [
          "groq"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/hooks/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/iterables/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/knowledge-graph/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/knowledge-graph/run_stream.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/learn-async/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/llm-judge-relevance/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/logfire-fastapi/server.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/logfire/classify.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/logfire/image.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/logfire/validate.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/logging/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/match_language/run_v1.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/match_language/run_v2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/mistral/mistral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/multi-actions/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/multiple_search_queries/segment_search_queries.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/open_source_examples/openrouter.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/open_source_examples/perplexity.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/open_source_examples/runpod.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/openai-audio/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/parallel/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/partial_streaming/benchmark.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/partial_streaming/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/patching/anyscale.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/patching/oai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/patching/pcalls.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/patching/together.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/proscons/run.py",
        "providers": [
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/query_planner_execution/query_planner_execution.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/recursive_filepaths/parse_recursive_paths.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/reranker/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/resolving-complex-entities/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/retry/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/safer_sql_example/safe_sql.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/simple-extraction/maybe_user.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/simple-extraction/user.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/situate_context/run.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/sqlmodel/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/stream_action_items/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/synethic-data/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/task_planner/task_planner_topological_sort.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/tenacity-benchmarks/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/union/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/validated-multiclass/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/validators/allm_validator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/validators/chain_of_thought_validator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/validators/citations.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/validators/competitors.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/validators/llm_validator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/validators/moderation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/vision/image_to_ad_copy.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/vision/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/vision/run_raw.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/vision/run_table.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/vision/slides.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/watsonx/watsonx.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/youtube-clips/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/youtube-flashcards/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/examples/youtube/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/__init__.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/_types/_alias.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/auto_client.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/batch/__init__.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/batch/models.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/batch/processor.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/batch/providers/__init__.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/batch/providers/anthropic.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/batch/providers/openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/batch/request.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/cache/__init__.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/cli/batch.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/cli/cli.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/cli/files.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/cli/jobs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/cli/usage.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/client.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/core/__init__.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/core/client.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/core/exceptions.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/core/hooks.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/core/patch.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/core/retry.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/distil.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/dsl/citation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/dsl/iterable.py",
        "providers": [
          "anthropic",
          "gemini",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/dsl/parallel.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/dsl/partial.py",
        "providers": [
          "anthropic",
          "gemini",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/dsl/simple_type.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/mode.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/models.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/processing/__init__.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/processing/function_calls.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/processing/multimodal.py",
        "providers": [
          "anthropic",
          "gemini",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/processing/response.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/processing/schema.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/processing/validators.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/__init__.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/anthropic/client.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/anthropic/utils.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/bedrock/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/cerebras/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/cohere/client.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/cohere/utils.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/fireworks/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/gemini/client.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/gemini/utils.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/genai/client.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/groq/client.py",
        "providers": [
          "groq"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/mistral/client.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/mistral/utils.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/openai/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/perplexity/client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/vertexai/client.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/writer/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/providers/xai/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/templating.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/utils/__init__.py",
        "providers": [
          "anthropic",
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/utils/core.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/utils/providers.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/validation/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/validation/llm_validators.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/instructor/validators.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/scripts/audit_patterns.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/scripts/fix_old_patterns.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/scripts/make_desc.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/scripts/make_sitemap.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/docs/test_examples.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/docs/test_hub.py",
        "providers": [
          "groq",
          "llama",
          "mistral",
          "ollama"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/dsl/test_partial.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/shared_config.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_anthropic/conftest.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_anthropic/test_reasoning.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_anthropic/test_system.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_anthropic/util.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_bedrock/test_openai_image_conversion.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_bedrock/test_prepare_kwargs.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_core_providers/__init__.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_core_providers/capabilities.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_core_providers/conftest.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_gemini/conftest.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_gemini/test_list_content.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_gemini/test_multimodal_content.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_gemini/util.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_genai/conftest.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_genai/test_format.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_genai/test_invalid_schema.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_genai/test_schema_conversion.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_genai/test_utils.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_genai/util.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_litellm.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_new_client.py",
        "providers": [
          "anthropic",
          "cohere",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_openai/conftest.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_openai/slow/test_response.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_openai/test_attr.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_openai/test_hooks.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_openai/test_multimodal.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_openai/test_multitask.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_openai/test_patch.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_openai/test_validation_context.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_openai/test_validators.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_openai/util.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_vertexai/test_format.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_vertexai/test_message_parser.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_vertexai/test_modes.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_vertexai/util.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/llm/test_writer/evals/test_classification_enums.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/processing/test_anthropic_json.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_auto_client.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_batch_in_memory.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_cache_integration.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_cache_key.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_dict_operations.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_dict_operations_validation.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_dynamic_model_creation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_exceptions.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_formatting.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_function_calls.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_json_extraction.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_logging.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_message_processing.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_multimodal.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_multitask.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_patch.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_process_response.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_response_model_conversion.py",
        "providers": [
          "anthropic",
          "gemini"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_retry_json_mode.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_schema.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/test_schema_utils.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "567-labs-instructor-130c034/tests/v2/test_provider_modes.py",
        "providers": [
          "anthropic",
          "gemini"
        ]
      }
    ],
    "error": null
  },
  "Aider-AI/aider": {
    "owner": "Aider-AI",
    "repo": "aider",
    "ref": "main",
    "num_llm_files": 43,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "groq",
      "litellm",
      "llama",
      "mistral",
      "ollama",
      "openai"
    ],
    "files": [
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/args.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/args_formatter.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/coders/base_coder.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/coders/patch_coder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/coders/single_wholefile_func_prompts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/coders/wholefile_func_prompts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/commands.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/deprecated.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/exceptions.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/format_settings.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/help.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/history.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/llm.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/main.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/models.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/onboarding.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/openrouter.py",
        "providers": [
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/aider/voice.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/benchmark/benchmark.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/benchmark/over_time.py",
        "providers": [
          "anthropic",
          "gemini",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/benchmark/plots.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/benchmark/rungrid.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/scripts/clean_metadata.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/scripts/recording_audio.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_aws_credentials.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_coder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_commands.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_deprecated.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_editblock.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_exceptions.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_history.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_main.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_models.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_onboarding.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_openrouter.py",
        "providers": [
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_reasoning.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_repo.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_repomap.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_scripting.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_sendchat.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_ssl_verification.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/basic/test_wholefile.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Aider-AI-aider-5683f1c/tests/help/test_help.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "BillSchumacher/Auto-GPT": {
    "owner": "BillSchumacher",
    "repo": "Auto-GPT",
    "ref": "bdd07b18bea674cf756ebfb3a0a8915042d9126f",
    "num_llm_files": 36,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/agent/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/agent/agent_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/api_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/chat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/cli.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/commands/image_gen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/config/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/config/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/configurator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/json_utils/json_fix_llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/llm_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/models/base_open_ai_plugin.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/modelsinfo.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/plugins.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/processing/text.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/token_counter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/autogpt/types/openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/conftest.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/integration/conftest.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/integration/goal_oriented/test_write_file.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/integration/test_local_cache.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/integration/test_setup.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/test_agent_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/test_api_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/test_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/test_image_gen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/test_llm_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/test_token_counter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/unit/models/test_base_open_api_plugin.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/unit/test_chat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/unit/test_commands.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/unit/test_get_self_feedback.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/unit/test_plugins.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BillSchumacher-Auto-GPT-bdd07b1/tests/vcr/openai_filter.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "Azure-Samples/azure-search-openai-demo": {
    "owner": "Azure-Samples",
    "repo": "azure-search-openai-demo",
    "ref": "main",
    "num_llm_files": 39,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/app.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/approaches/approach.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/approaches/chatreadretrieveread.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/approaches/promptmanager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/approaches/retrievethenread.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/core/authentication.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/error.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/prepdocs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/prepdocslib/cloudingestionstrategy.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/prepdocslib/embeddings.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/prepdocslib/figureprocessor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/prepdocslib/filestrategy.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/prepdocslib/integratedvectorizerstrategy.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/prepdocslib/mediadescriber.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/prepdocslib/searchmanager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/prepdocslib/servicesetup.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/prepdocslib/strategy.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/backend/setup_cloud_ingestion.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/functions/figure_processor/function_app.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/app/functions/text_processor/function_app.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/evals/evaluate.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/evals/generate_ground_truth.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/evals/safety_evaluation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/scripts/auth_init.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/tests/conftest.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/tests/e2e.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/tests/mocks.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/tests/test_agentic_retrieval.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/tests/test_app.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/tests/test_app_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/tests/test_chatapproach.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/tests/test_function_apps.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/tests/test_mediadescriber.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/tests/test_pdfparser.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/tests/test_prepdocs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/tests/test_searchmanager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/tests/test_servicesetup.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Azure-Samples-azure-search-openai-demo-35a7885/tests/test_upload.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "Byaidu/PDFMathTranslate": {
    "owner": "Byaidu",
    "repo": "PDFMathTranslate",
    "ref": "main",
    "num_llm_files": 5,
    "providers": [
      "gemini",
      "groq",
      "llama",
      "ollama",
      "openai"
    ],
    "files": [
      {
        "file_path": "PDFMathTranslate-PDFMathTranslate-cde084f/pdf2zh/converter.py",
        "providers": [
          "gemini",
          "groq",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "PDFMathTranslate-PDFMathTranslate-cde084f/pdf2zh/gui.py",
        "providers": [
          "gemini",
          "groq",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "PDFMathTranslate-PDFMathTranslate-cde084f/pdf2zh/pdf2zh.py",
        "providers": [
          "gemini",
          "groq",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "PDFMathTranslate-PDFMathTranslate-cde084f/pdf2zh/translator.py",
        "providers": [
          "gemini",
          "groq",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "PDFMathTranslate-PDFMathTranslate-cde084f/test/test_translator.py",
        "providers": [
          "llama",
          "ollama",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "ChuloAI/BrainChulo": {
    "owner": "ChuloAI",
    "repo": "BrainChulo",
    "ref": "f2d6753177ef9940dcb6994da03fbf5fd323a3b3",
    "num_llm_files": 5,
    "providers": [
      "langchain"
    ],
    "files": [
      {
        "file_path": "ChuloAI-BrainChulo-f2d6753/app/conversations/document_based.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ChuloAI-BrainChulo-f2d6753/app/llms/oobabooga_llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ChuloAI-BrainChulo-f2d6753/app/memory/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ChuloAI-BrainChulo-f2d6753/app/memory/chroma_memory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ChuloAI-BrainChulo-f2d6753/app/prompt_templates/document_based_conversation.py",
        "providers": [
          "langchain"
        ]
      }
    ],
    "error": null
  },
  "CloudDevStudios/Agent-LLM": {
    "owner": "CloudDevStudios",
    "repo": "Agent-LLM",
    "ref": "f89aaebd761a4d016b8a61ee511330f5ed403fe9",
    "num_llm_files": 8,
    "providers": [
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "CloudDevStudios-Agent-LLM-f89aaeb/AgentLLM.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "CloudDevStudios-Agent-LLM-f89aaeb/Config/Agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "CloudDevStudios-Agent-LLM-f89aaeb/Config/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "CloudDevStudios-Agent-LLM-f89aaeb/app.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "CloudDevStudios-Agent-LLM-f89aaeb/commands/image_generator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "CloudDevStudios-Agent-LLM-f89aaeb/provider/chatgpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "CloudDevStudios-Agent-LLM-f89aaeb/provider/llamacpp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "CloudDevStudios-Agent-LLM-f89aaeb/provider/openai.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "Codium-ai/pr-agent": {
    "owner": "Codium-ai",
    "repo": "pr-agent",
    "ref": "41166dc271039f9952c8086005f6c4b242021221",
    "num_llm_files": 6,
    "providers": [
      "anthropic",
      "cohere",
      "litellm",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "qodo-ai-pr-agent-41166dc/pr_agent/algo/__init__.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-41166dc/pr_agent/algo/ai_handler.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-41166dc/pr_agent/algo/pr_processing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-41166dc/pr_agent/servers/bitbucket_pipeline_runner.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-41166dc/pr_agent/servers/github_action_runner.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-41166dc/pr_agent/tools/pr_similar_issue.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "BlinkDL/RWKV-LM": {
    "owner": "BlinkDL",
    "repo": "RWKV-LM",
    "ref": "main",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "DLR-RM/stable-baselines3": {
    "owner": "DLR-RM",
    "repo": "stable-baselines3",
    "ref": "master",
    "num_llm_files": 12,
    "providers": [
      "cohere",
      "openai"
    ],
    "files": [
      {
        "file_path": "DLR-RM-stable-baselines3-c6ce50f/setup.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "DLR-RM-stable-baselines3-c6ce50f/stable_baselines3/common/base_class.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "DLR-RM-stable-baselines3-c6ce50f/stable_baselines3/common/policies.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "DLR-RM-stable-baselines3-c6ce50f/stable_baselines3/common/preprocessing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "DLR-RM-stable-baselines3-c6ce50f/stable_baselines3/common/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "DLR-RM-stable-baselines3-c6ce50f/stable_baselines3/common/vec_env/dummy_vec_env.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "DLR-RM-stable-baselines3-c6ce50f/stable_baselines3/common/vec_env/patch_gym.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "DLR-RM-stable-baselines3-c6ce50f/stable_baselines3/common/vec_env/vec_monitor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "DLR-RM-stable-baselines3-c6ce50f/stable_baselines3/ddpg/ddpg.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "DLR-RM-stable-baselines3-c6ce50f/stable_baselines3/ppo/ppo.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "DLR-RM-stable-baselines3-c6ce50f/stable_baselines3/sac/sac.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "DLR-RM-stable-baselines3-c6ce50f/stable_baselines3/td3/td3.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "DanielSmith0831/DocsGPT": {
    "owner": "DanielSmith0831",
    "repo": "DocsGPT",
    "ref": "6b6737613ad934a28ae4251ffa9716465e6e35dd",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": "failed to download zip zip not found"
  },
  "Doriandarko/BabyAGIChatGPT": {
    "owner": "Doriandarko",
    "repo": "BabyAGIChatGPT",
    "ref": "174491cbbc09d3f6ef0ec511e9e3b94e2615ffa0",
    "num_llm_files": 1,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "Doriandarko-BabyAGIChatGPT-174491c/main.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "EleutherAI/gpt-neo": {
    "owner": "EleutherAI",
    "repo": "gpt-neo",
    "ref": "master",
    "num_llm_files": 1,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "EleutherAI-gpt-neo-23485e3/tasks.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "EleutherAI/gpt-neox": {
    "owner": "EleutherAI",
    "repo": "gpt-neox",
    "ref": "main",
    "num_llm_files": 8,
    "providers": [
      "llama",
      "mistral",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "EleutherAI-gpt-neox-d12c771/megatron/model/moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "EleutherAI-gpt-neox-d12c771/megatron/model/moe_mlp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "EleutherAI-gpt-neox-d12c771/megatron/model/transformer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "EleutherAI-gpt-neox-d12c771/megatron/tokenizer/tokenizer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "EleutherAI-gpt-neox-d12c771/post-training/llama_data.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "EleutherAI-gpt-neox-d12c771/post-training/online_data_example_llama3.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "EleutherAI-gpt-neox-d12c771/tools/ckpts/convert_neox_to_hf.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "EleutherAI-gpt-neox-d12c771/tools/ckpts/convert_raw_llama_weights_to_neox.py",
        "providers": [
          "llama",
          "mistral"
        ]
      }
    ],
    "error": null
  },
  "EmbraceAGI/LocalAGI": {
    "owner": "EmbraceAGI",
    "repo": "LocalAGI",
    "ref": "f2fd7824ee270b8d45b336366ec885a14b809b8b",
    "num_llm_files": 3,
    "providers": [
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "EmbraceAGI-LocalAGI-f2fd782/local_agi.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "EmbraceAGI-LocalAGI-f2fd782/local_agi_mini.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "EmbraceAGI-LocalAGI-f2fd782/local_agi_zh.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "ATheorell/AutoGPTArenaHack": {
    "owner": "ATheorell",
    "repo": "AutoGPTArenaHack",
    "ref": "1e4f2dc004b92b9f236543674f94fb9f0af9bb2e",
    "num_llm_files": 51,
    "providers": [
      "gemini",
      "langchain",
      "litellm",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/agbenchmark_config/benchmarks.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/agent_factory/configurators.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/agents/base.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/agents/prompt_strategies/one_shot.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/app/cli.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/app/configurator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/app/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/commands/image_gen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/commands/web_selenium.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/config/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/config/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/core/ability/builtins/query_language_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/core/agent/simple.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/core/planning/simple.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/core/resource/model_providers/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/core/resource/model_providers/openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/core/resource/model_providers/schema.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/core/runner/client_lib/logging/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/json_utils/utilities.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/llm/api_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/llm/providers/openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/logs/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/memory/vector/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/models/base_open_ai_plugin.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/plugins/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/autogpt/processing/text.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/tests/conftest.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/tests/integration/agent_factory.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/tests/integration/memory/_test_json_file_memory.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/tests/integration/test_image_gen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/tests/integration/test_web_selenium.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/tests/unit/models/test_base_open_api_plugin.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/tests/unit/test_api_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/tests/unit/test_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/tests/unit/test_plugins.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/tests/unit/test_retry_provider_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/tests/unit/test_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/tests/vcr/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/autogpt/tests/vcr/vcr_filter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/forge/forge/sdk/forge_log.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/forge/forge/sdk/llm.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/forge/forge/sdk/prompting.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/gpt-engineer/gpt_engineer/API/api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/gpt-engineer/gpt_engineer/cli/learning.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/gpt-engineer/gpt_engineer/cli/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/gpt-engineer/gpt_engineer/core/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/gpt-engineer/gpt_engineer/core/ai.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/autogpts/gpt-engineer/gpt_engineer/core/steps.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/benchmark/agbenchmark/utils/challenge.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/benchmark/agbenchmark/utils/dependencies/graphs.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "ATheorell-AutoGPTArenaHack-1e4f2dc/cli.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "ExpressGit/langchain-ChatGLM": {
    "owner": "ExpressGit",
    "repo": "langchain-ChatGLM",
    "ref": "21035d7706b24956f845c65e1492690abbb07d8b",
    "num_llm_files": 21,
    "providers": [
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/agent/bing_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/chains/local_doc_qa.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/chains/modules/embeddings.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/chains/modules/vectorstores.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/chains/text_load.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/configs/model_config.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/fastchat/api/conversation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/fastchat/api/fastchat_api.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/loader/image_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/loader/pdf_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/models/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/models/__main__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/models/chatglm_llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/models/extensions/llamacpp_model_alternative.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/models/llama_llm.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/models/loader/args.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/models/loader/loader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/models/moss_llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/textsplitter/ali_text_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/textsplitter/chinese_text_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ExpressGit-langchain-ChatGLM-21035d7/webui.py",
        "providers": [
          "langchain"
        ]
      }
    ],
    "error": null
  },
  "FOLLGAD/Godmode-GPT": {
    "owner": "FOLLGAD",
    "repo": "Godmode-GPT",
    "ref": "4e1dc7055580ab9bb3ce85114f9e17950ac96d7b",
    "num_llm_files": 43,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/api_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/cli.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/commands/image_gen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/config/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/config/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/configurator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/json_utils/json_fix_llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/llm/api_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/llm/base.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/llm/chat.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/llm/llm_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/llm/modelsinfo.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/llm/providers/openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/llm/token_counter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/models/base_open_ai_plugin.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/plugins.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/autogpt/processing/text.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/integration/challenges/information_retrieval/test_information_retrieval_challenge_a.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/integration/challenges/memory/test_memory_challenge_a.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/integration/challenges/memory/test_memory_challenge_b.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/integration/conftest.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/integration/goal_oriented/test_browse_website.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/integration/goal_oriented/test_write_file.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/integration/test_llm_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/integration/test_local_cache.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/integration/test_memory_management.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/integration/test_setup.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/test_agent_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/test_api_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/test_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/test_image_gen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/test_token_counter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/unit/models/test_base_open_api_plugin.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/unit/test_chat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/unit/test_commands.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/unit/test_get_self_feedback.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/unit/test_llm_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/unit/test_plugins.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/vcr/openai_filter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "FOLLGAD-godmode-4e1dc70/tests/vcr/vcr_filter.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "GaiZhenbiao/ChuanhuChatGPT": {
    "owner": "GaiZhenbiao",
    "repo": "ChuanhuChatGPT",
    "ref": "main",
    "num_llm_files": 23,
    "providers": [
      "anthropic",
      "gemini",
      "groq",
      "langchain",
      "llama",
      "mistral",
      "ollama",
      "openai"
    ],
    "files": [
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/ChuanhuChatbot.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/locale/extract_locale.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/config.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/index_func.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/models/Azure.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/models/ChuanhuAgent.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/models/Claude.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/models/DALLE3.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/models/GoogleGemini.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/models/GooglePaLM.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/models/Groq.py",
        "providers": [
          "groq"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/models/LLaMA.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/models/Ollama.py",
        "providers": [
          "llama",
          "mistral",
          "ollama"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/models/OpenAIInstruct.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/models/OpenAIVision.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/models/base_model.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "langchain",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/models/modeling_moss.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/models/models.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "langchain",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/pdf_func.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/presets.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/shared.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/train_func.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "GaiZhenbiao-ChuanhuChatGPT-0271b07/modules/utils.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "EmbraceAGI/awesome-chatgpt-zh": {
    "owner": "EmbraceAGI",
    "repo": "awesome-chatgpt-zh",
    "ref": "main",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "GreyDGL/PentestGPT": {
    "owner": "GreyDGL",
    "repo": "PentestGPT",
    "ref": "a4e5361d76c880a9cf6f79f12e6cff90c8c01da3",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "Haste171/langchain-chatbot": {
    "owner": "Haste171",
    "repo": "langchain-chatbot",
    "ref": "f3999530d57eb8069d8b911024785d82ac5d003d",
    "num_llm_files": 4,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "Haste171-langchain-chatbot-f399953/chatbot.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Haste171-langchain-chatbot-f399953/streamlit.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Haste171-langchain-chatbot-f399953/utils/ingest.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Haste171-langchain-chatbot-f399953/utils/query.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "InternLM/lmdeploy": {
    "owner": "InternLM",
    "repo": "lmdeploy",
    "ref": "main",
    "num_llm_files": 170,
    "providers": [
      "cohere",
      "gemini",
      "llama",
      "mistral",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "InternLM-lmdeploy-2697c96/.github/scripts/eval_base_config.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/.github/scripts/eval_chat_config.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/.github/scripts/eval_regression_base_models.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/.github/scripts/eval_regression_chat_models.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/.github/scripts/eval_stable_object_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/.github/scripts/eval_stable_subject_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/benchmark/test_apiserver_performance.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/benchmark/test_throughput_performance.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/evaluate/eval_config_chat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/evaluate/test_api_evaluate.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/interface/pipeline/test_pipeline_longtext_func.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/interface/restful/test_restful_chat_func.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/interface/restful/test_restful_completions_v1.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/tools/chat/test_command_chat_hf_pytorch.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/tools/chat/test_command_chat_hf_turbomind.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/tools/pipeline/llm_case.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/tools/pipeline/test_pipeline_chat_pytorch_llm.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/tools/pipeline/test_pipeline_chat_turbomind_llm.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/tools/pipeline/test_pipeline_chat_turbomind_mllm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/tools/restful/test_restful_chat_hf_pytorch_llm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/tools/restful/test_restful_chat_hf_turbomind_llm.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/utils/benchmark_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/utils/evaluate_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/utils/get_run_config.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/utils/pipeline_chat.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/utils/quantization_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/utils/run_client_chat.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/autotest/utils/run_restful_chat.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/benchmark/benchmark_decode.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/benchmark/benchmark_serving.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/benchmark/profile_restful_api.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/eval/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/eval/eval.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/api.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/archs.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/cli/cli.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/cli/serve.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/cli/utils.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/lite/apis/calibrate.py",
        "providers": [
          "gemini",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/lite/quantization/awq.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/logger.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/messages.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/metrics/loggers.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/metrics/stats.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/model.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/backends/base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/backends/default/rotary_embedding.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/backends/dlinfer/ascend/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/backends/dlinfer/rotary_embedding.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/backends/rotary_embedding.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/configurations/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/configurations/llama4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/configurations/mllama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/engine/cache_engine.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/engine/engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/engine/executor/base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/engine/executor/mp_executor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/engine/executor/ray_executor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/engine/model_agent.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/kernels/cuda/blocked_fp8_fused_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/kernels/cuda/fused_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/kernels/cuda/w8a8_fused_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/messages.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/model_inputs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/baichuan.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/chatglm2.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/cogvlm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/deepseek.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/deepseek_mtp.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/deepseek_v2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/deepseek_vl2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/gemma.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/gemma3_vl.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/glm4.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/glm4_1v.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/glm4_moe.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/gpt_oss.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/internlm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/internlm2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/internlm2_reward.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/internlm2_ve.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/internlm3.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/llama.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/llama4.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/llama_eagle.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/llama_eagle3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/minicpm3.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/minicpmv26.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/mistral.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/mixtral.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/mllama.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/module_map.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/phi3.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/phi3_moe.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/phi3_v.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/qwen.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/qwen2.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/qwen2_5_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/qwen2_moe.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/qwen2_reward.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/qwen2_vl.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/qwen3.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/qwen3_moe.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/qwen3_next.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/qwen3_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/qwen3_vl_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/sdar.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/sdar_moe.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/models/starcoder2.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/nn/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/nn/rotary_embedding.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/paging/block_manager/default_block_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/paging/scheduler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/ray.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/tools/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/pytorch/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/serve/async_engine.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/serve/openai/api_client.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/serve/openai/api_server.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/serve/openai/harmony_utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/serve/openai/protocol.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/serve/openai/reasoning_parser/deepseek_r1_reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/serve/openai/reasoning_parser/qwen_qwq_reasoning_parser.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/serve/openai/reasoning_parser/reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/serve/openai/tool_parser/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/serve/openai/tool_parser/internlm2_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/serve/openai/tool_parser/llama3_parser.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/serve/openai/tool_parser/qwen2d5_parser.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/serve/openai/tool_parser/qwen3_parser.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/serve/openai/tool_parser/tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/serve/openai/tool_parser/utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/serve/proxy/proxy.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/serve/vl_async_engine.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/tokenizer.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/turbomind/deploy/source_model/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/turbomind/deploy/source_model/baichuan.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/turbomind/deploy/source_model/deepseek2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/turbomind/deploy/source_model/deepseek_vl.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/turbomind/deploy/source_model/glm4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/turbomind/deploy/source_model/gpt_oss.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/turbomind/deploy/source_model/internlm2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/turbomind/deploy/source_model/internvl.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/turbomind/deploy/source_model/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/turbomind/deploy/source_model/llava.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/turbomind/deploy/source_model/minicpmv.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/turbomind/deploy/source_model/mixtral.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/turbomind/deploy/source_model/molmo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/turbomind/deploy/source_model/qwen.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/turbomind/supported_models.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/turbomind/tokenizer_info.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/turbomind/turbomind.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/vl/model/builder.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/vl/model/cogvlm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/vl/model/internvl_llava.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/vl/model/llama4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/vl/model/llava.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/vl/model/minicpmv.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/vl/model/mllama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/vl/model/yi.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/lmdeploy/vl/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/tests/pytorch/config/test_hf_overrides.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/tests/test_lmdeploy/test_auto_backend.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/tests/test_lmdeploy/test_content_merge.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/tests/test_lmdeploy/test_harmony_gpt_oss_parser.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/tests/test_lmdeploy/test_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/tests/test_lmdeploy/test_qwen3_parser.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/tests/test_lmdeploy/test_tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/tests/test_lmdeploy/test_turbomind/test_converter.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "InternLM-lmdeploy-2697c96/tests/test_lmdeploy/test_vl/test_nonhf_chat_template.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "Devansh968/Chat-with-Pdf-using-Qdrant-vector-database": {
    "owner": "Devansh968",
    "repo": "Chat-with-Pdf-using-Qdrant-vector-database",
    "ref": "771195f36a735a6f4ac1b63edc04661c11a67f3f",
    "num_llm_files": 871,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/PIL/SunImagePlugin.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/PyPDF2/_codecs/adobe_glyphs.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/charset_normalizer/api.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/charset_normalizer/cd.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/charset_normalizer/cli/normalizer.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/charset_normalizer/models.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/__init__.py",
        "providers": [
          "anthropic",
          "cohere",
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/__init__.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/amadeus/toolkit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/azure_cognitive_services/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/azure_cognitive_services/toolkit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/csv/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/file_management/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/file_management/toolkit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/github/toolkit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/gmail/toolkit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/jira/toolkit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/json/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/json/toolkit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/nla/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/nla/toolkit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/office365/toolkit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/openapi/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/openapi/planner.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/openapi/planner_prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/openapi/toolkit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/pandas/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/playwright/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/playwright/toolkit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/powerbi/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/powerbi/chat_base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/powerbi/toolkit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/python/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/spark/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/spark_sql/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/spark_sql/toolkit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/sql/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/sql/toolkit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/vectorstore/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/vectorstore/toolkit.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/xorbits/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_toolkits/zapier/toolkit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/agent_types.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/chat/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/chat/output_parser.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/conversational/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/conversational/output_parser.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/conversational/prompt.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/conversational_chat/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/conversational_chat/output_parser.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/conversational_chat/prompt.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/initialize.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/load_tools.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/loading.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/mrkl/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/mrkl/output_parser.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/openai_functions_agent/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/openai_functions_multi_agent/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/react/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/react/output_parser.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/react/textworld_prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/react/wiki_prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/schema.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/self_ask_with_search/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/self_ask_with_search/output_parser.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/self_ask_with_search/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/structured_chat/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/structured_chat/output_parser.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/tools.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/types.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/agents/utils.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/base_language.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/cache.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/__init__.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/aim_callback.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/argilla_callback.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/arize_callback.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/arthur_callback.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/clearml_callback.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/comet_ml_callback.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/context_callback.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/file.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/flyte_callback.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/human.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/infino_callback.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/manager.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/mlflow_callback.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/openai_info.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/promptlayer_callback.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/stdout.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/streaming_aiter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/streaming_aiter_final_only.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/streaming_stdout.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/streaming_stdout_final_only.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/streamlit/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/streamlit/streamlit_callback_handler.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/tracers/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/tracers/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/tracers/evaluation.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/tracers/langchain.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/tracers/langchain_v1.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/tracers/run_collector.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/tracers/schemas.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/tracers/stdout.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/tracers/wandb.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/wandb_callback.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/callbacks/whylabs_callback.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/__init__.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/api/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/api/openapi/chain.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/api/openapi/requests_chain.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/api/openapi/response_chain.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/api/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/chat_vector_db/prompts.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/combine_documents/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/combine_documents/map_reduce.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/combine_documents/map_rerank.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/combine_documents/reduce.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/combine_documents/refine.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/combine_documents/stuff.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/constitutional_ai/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/constitutional_ai/principles.py",
        "providers": [
          "cohere",
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/constitutional_ai/prompts.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/conversation/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/conversation/memory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/conversation/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/conversational_retrieval/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/conversational_retrieval/prompts.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/elasticsearch_database/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/elasticsearch_database/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/elasticsearch_database/prompts.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/flare/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/flare/prompts.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/graph_qa/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/graph_qa/cypher.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/graph_qa/hugegraph.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/graph_qa/kuzu.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/graph_qa/nebulagraph.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/graph_qa/neptune_cypher.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/graph_qa/prompts.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/graph_qa/sparql.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/hyde/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/hyde/prompts.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/llm_bash/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/llm_bash/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/llm_checker/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/llm_checker/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/llm_math/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/llm_math/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/llm_requests.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/llm_summarization_checker/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/llm_symbolic_math/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/llm_symbolic_math/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/loading.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/mapreduce.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/moderation.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/natbot/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/natbot/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/openai_functions/__init__.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/openai_functions/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/openai_functions/citation_fuzzy_match.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/openai_functions/extraction.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/openai_functions/openapi.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/openai_functions/qa_with_structure.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/openai_functions/tagging.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/pal/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/pal/colored_object_prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/pal/math_prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/prompt_selector.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/qa_generation/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/qa_generation/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/qa_with_sources/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/qa_with_sources/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/qa_with_sources/loading.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/qa_with_sources/map_reduce_prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/qa_with_sources/refine_prompts.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/qa_with_sources/retrieval.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/qa_with_sources/stuff_prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/qa_with_sources/vector_db.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/query_constructor/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/query_constructor/parser.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/query_constructor/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/question_answering/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/question_answering/map_reduce_prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/question_answering/map_rerank_prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/question_answering/refine_prompts.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/question_answering/stuff_prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/retrieval_qa/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/retrieval_qa/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/router/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/router/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/router/embedding_router.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/router/llm_router.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/router/multi_prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/router/multi_retrieval_qa.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/sequential.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/sql_database/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/sql_database/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/summarize/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/summarize/map_reduce_prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/summarize/refine_prompts.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/summarize/stuff_prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chains/transform.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chat_models/__init__.py",
        "providers": [
          "anthropic",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chat_models/anthropic.py",
        "providers": [
          "anthropic",
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chat_models/azure_openai.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chat_models/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chat_models/fake.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chat_models/google_palm.py",
        "providers": [
          "gemini",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chat_models/human.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chat_models/jinachat.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chat_models/openai.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chat_models/promptlayer_openai.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/chat_models/vertexai.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/docstore/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/docstore/arbitrary_fn.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/docstore/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/docstore/document.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/docstore/in_memory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/docstore/wikipedia.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/acreom.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/airbyte_json.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/airtable.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/apify_dataset.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/arxiv.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/async_html.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/azlyrics.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/azure_blob_storage_container.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/azure_blob_storage_file.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/bibtex.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/bigquery.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/bilibili.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/blackboard.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/blob_loaders/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/blob_loaders/file_system.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/blob_loaders/schema.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/blob_loaders/youtube_audio.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/blockchain.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/brave_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/browserless.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/chatgpt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/college_confidential.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/confluence.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/conllu.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/csv_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/cube_semantic.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/datadog_logs.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/dataframe.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/diffbot.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/directory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/discord.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/docugami.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/duckdb_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/email.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/embaas.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/epub.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/evernote.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/excel.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/facebook_chat.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/fauna.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/figma.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/gcs_directory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/gcs_file.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/generic.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/geodataframe.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/git.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/gitbook.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/github.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/googledrive.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/gutenberg.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/hn.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/html.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/html_bs.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/hugging_face_dataset.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/ifixit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/image.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/image_captions.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/imsdb.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/iugu.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/joplin.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/json_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/larksuite.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/markdown.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/mastodon.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/max_compute.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/mediawikidump.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/merge.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/mhtml.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/modern_treasury.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/notebook.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/notion.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/notiondb.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/obsidian.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/odt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/onedrive.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/onedrive_file.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/open_city_data.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/org_mode.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/parsers/__init__.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/parsers/audio.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/parsers/generic.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/parsers/grobid.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/parsers/html/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/parsers/html/bs4.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/parsers/language/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/parsers/language/javascript.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/parsers/language/language_parser.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/parsers/language/python.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/parsers/pdf.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/parsers/registry.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/parsers/txt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/pdf.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/powerpoint.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/psychic.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/pyspark_dataframe.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/python.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/readthedocs.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/recursive_url_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/reddit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/roam.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/rocksetdb.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/rst.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/rtf.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/s3_directory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/s3_file.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/sitemap.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/slack_directory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/snowflake_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/spreedly.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/srt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/stripe.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/telegram.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/tencent_cos_directory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/tencent_cos_file.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/text.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/tomarkdown.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/toml.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/trello.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/tsv.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/twitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/unstructured.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/url.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/url_playwright.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/url_selenium.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/weather.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/web_base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/whatsapp_chat.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/wikipedia.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/word_document.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/xml.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/xorbits.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_loaders/youtube.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_transformers/__init__.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_transformers/doctran_text_extract.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_transformers/doctran_text_qa.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_transformers/doctran_text_translate.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_transformers/embeddings_redundant_filter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_transformers/html2text.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_transformers/long_context_reorder.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/document_transformers/openai_functions.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/__init__.py",
        "providers": [
          "cohere",
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/aleph_alpha.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/bedrock.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/clarifai.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/cohere.py",
        "providers": [
          "cohere",
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/dashscope.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/deepinfra.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/elasticsearch.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/embaas.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/fake.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/google_palm.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/gpt4all.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/huggingface.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/huggingface_hub.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/jina.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/llamacpp.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/minimax.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/mlflow_gateway.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/modelscope_hub.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/mosaicml.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/nlpcloud.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/octoai_embeddings.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/openai.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/sagemaker_endpoint.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/self_hosted.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/self_hosted_hugging_face.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/sentence_transformer.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/spacy_embeddings.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/tensorflow_hub.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/embeddings/vertexai.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/env.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/agents/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/agents/trajectory_eval_chain.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/agents/trajectory_eval_prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/comparison/__init__.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/comparison/eval_chain.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/comparison/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/criteria/__init__.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/criteria/eval_chain.py",
        "providers": [
          "anthropic",
          "cohere",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/criteria/prompt.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/embedding_distance/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/embedding_distance/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/loading.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/qa/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/qa/eval_chain.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/qa/eval_prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/qa/generate_chain.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/qa/generate_prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/schema.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/string_distance/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/evaluation/string_distance/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/example_generator.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/autonomous_agents/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/autonomous_agents/autogpt/agent.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/autonomous_agents/autogpt/memory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/autonomous_agents/autogpt/output_parser.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/autonomous_agents/autogpt/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/autonomous_agents/autogpt/prompt_generator.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/autonomous_agents/baby_agi/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/autonomous_agents/baby_agi/baby_agi.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/autonomous_agents/baby_agi/task_creation.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/autonomous_agents/baby_agi/task_execution.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/autonomous_agents/baby_agi/task_prioritization.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/cpal/base.py",
        "providers": [
          "cohere",
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/cpal/models.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/generative_agents/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/generative_agents/generative_agent.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/generative_agents/memory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/llms/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/llms/jsonformer_decoder.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/llms/rellm_decoder.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/plan_and_execute/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/plan_and_execute/agent_executor.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/plan_and_execute/executors/agent_executor.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/plan_and_execute/executors/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/plan_and_execute/planners/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/plan_and_execute/planners/chat_planner.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/experimental/plan_and_execute/schema.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/graphs/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/indexes/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/indexes/graph.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/indexes/prompts/entity_extraction.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/indexes/prompts/entity_summarization.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/indexes/prompts/knowledge_triplet_extraction.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/indexes/vectorstore.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/__init__.py",
        "providers": [
          "anthropic",
          "cohere",
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/ai21.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/aleph_alpha.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/amazon_api_gateway.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/anthropic.py",
        "providers": [
          "anthropic",
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/anyscale.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/aviary.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/azureml_endpoint.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/bananadev.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/baseten.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/beam.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/bedrock.py",
        "providers": [
          "anthropic",
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/cerebriumai.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/chatglm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/clarifai.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/cohere.py",
        "providers": [
          "cohere",
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/ctransformers.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/databricks.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/deepinfra.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/fake.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/forefrontai.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/google_palm.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/gooseai.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/gpt4all.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/huggingface_endpoint.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/huggingface_hub.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/huggingface_pipeline.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/huggingface_text_gen_inference.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/human.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/koboldai.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/llamacpp.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/loading.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/manifest.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/mlflow_ai_gateway.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/modal.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/mosaicml.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/nlpcloud.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/octoai_endpoint.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/openai.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/openllm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/openlm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/petals.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/pipelineai.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/predibase.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/predictionguard.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/promptlayer_openai.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/replicate.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/rwkv.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/sagemaker_endpoint.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/self_hosted.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/self_hosted_hugging_face.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/stochasticai.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/textgen.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/tongyi.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/vertexai.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/llms/writer.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/load/dump.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/load/load.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/load/serializable.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/buffer.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/buffer_window.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/chat_memory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/chat_message_histories/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/chat_message_histories/cassandra.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/chat_message_histories/cosmos_db.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/chat_message_histories/dynamodb.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/chat_message_histories/file.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/chat_message_histories/firestore.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/chat_message_histories/in_memory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/chat_message_histories/momento.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/chat_message_histories/mongodb.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/chat_message_histories/postgres.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/chat_message_histories/redis.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/chat_message_histories/sql.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/chat_message_histories/zep.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/combined.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/entity.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/kg.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/motorhead_memory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/prompt.py",
        "providers": [
          "cohere",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/readonly.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/simple.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/summary.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/summary_buffer.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/token_buffer.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/utils.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/vectorstore.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/memory/zep_memory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/model_laboratory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/output_parsers/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/output_parsers/boolean.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/output_parsers/combining.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/output_parsers/datetime.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/output_parsers/enum.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/output_parsers/fix.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/output_parsers/json.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/output_parsers/list.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/output_parsers/loading.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/output_parsers/openai_functions.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/output_parsers/prompts.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/output_parsers/pydantic.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/output_parsers/rail_parser.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/output_parsers/regex.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/output_parsers/regex_dict.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/output_parsers/retry.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/output_parsers/structured.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/prompts/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/prompts/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/prompts/chat.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/prompts/example_selector/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/prompts/example_selector/length_based.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/prompts/example_selector/ngram_overlap.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/prompts/example_selector/semantic_similarity.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/prompts/few_shot.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/prompts/few_shot_with_templates.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/prompts/loading.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/prompts/pipeline.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/prompts/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/python.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/__init__.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/arxiv.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/azure_cognitive_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/bm25.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/chaindesk.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/chatgpt_plugin_retriever.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/contextual_compression.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/databerry.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/docarray.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/document_compressors/__init__.py",
        "providers": [
          "cohere",
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/document_compressors/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/document_compressors/chain_extract.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/document_compressors/chain_filter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/document_compressors/cohere_rerank.py",
        "providers": [
          "cohere",
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/elastic_search_bm25.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/google_cloud_enterprise_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/kendra.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/knn.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/llama_index.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/merger_retriever.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/metal.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/milvus.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/multi_query.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/pinecone_hybrid_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/pubmed.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/pupmed.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/remote_retriever.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/self_query/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/self_query/chroma.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/self_query/myscale.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/self_query/pinecone.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/self_query/qdrant.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/self_query/weaviate.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/svm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/tfidf.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/time_weighted_retriever.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/vespa_retriever.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/weaviate_hybrid_search.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/wikipedia.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/zep.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/retrievers/zilliz.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/schema/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/schema/document.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/schema/language_model.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/schema/memory.py",
        "providers": [
          "cohere",
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/schema/messages.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/schema/output.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/schema/output_parser.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/schema/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/schema/prompt_template.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/schema/retriever.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/serpapi.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/server.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/smith/__init__.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/smith/evaluation/__init__.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/smith/evaluation/config.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/smith/evaluation/runner_utils.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/smith/evaluation/string_run_evaluator.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/sql_database.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/text_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/__init__.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/amadeus/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/amadeus/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/amadeus/closest_airport.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/amadeus/flight_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/arxiv/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/azure_cognitive_services/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/azure_cognitive_services/form_recognizer.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/azure_cognitive_services/image_analysis.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/azure_cognitive_services/speech2text.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/azure_cognitive_services/text2speech.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/bing_search/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/bing_search/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/brave_search/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/convert_to_openai.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/dataforseo_api_search/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/dataforseo_api_search/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/ddg_search/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/ddg_search/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/file_management/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/file_management/copy.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/file_management/delete.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/file_management/file_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/file_management/list_dir.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/file_management/move.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/file_management/read.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/file_management/write.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/github/tool.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/gmail/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/gmail/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/gmail/create_draft.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/gmail/get_message.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/gmail/get_thread.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/gmail/search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/gmail/send_message.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/golden_query/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/golden_query/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/google_places/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/google_places/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/google_search/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/google_search/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/google_serper/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/google_serper/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/graphql/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/human/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/human/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/ifttt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/interaction/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/jira/tool.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/json/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/metaphor_search/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/metaphor_search/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/office365/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/office365/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/office365/create_draft_message.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/office365/events_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/office365/messages_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/office365/send_event.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/office365/send_message.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/openapi/utils/api_models.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/openapi/utils/openapi_utils.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/openweathermap/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/openweathermap/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/playwright/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/playwright/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/playwright/click.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/playwright/current_page.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/playwright/extract_hyperlinks.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/playwright/extract_text.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/playwright/get_elements.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/playwright/navigate.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/playwright/navigate_back.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/plugin.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/powerbi/tool.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/pubmed/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/python/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/requests/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/scenexplain/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/searx_search/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/shell/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/shell/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/sleep/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/spark_sql/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/sql_database/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/steamship_image_generation/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/steamship_image_generation/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/vectorstore/tool.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/wikipedia/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/wolfram_alpha/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/wolfram_alpha/tool.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/youtube/search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/zapier/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/tools/zapier/tool.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/apify.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/arxiv.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/bing_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/brave_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/dataforseo_api_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/github.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/golden_query.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/google_places_api.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/google_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/google_serper.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/jira.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/loading.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/max_compute.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/metaphor_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/openweathermap.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/portkey.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/pupmed.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/redis.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/scenexplain.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/searx_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/serpapi.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/sql_database.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/twilio.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/wikipedia.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/wolfram_alpha.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utilities/zapier.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/utils/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/_pgvector_data_models.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/alibabacloud_opensearch.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/analyticdb.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/annoy.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/atlas.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/awadb.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/azuresearch.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/cassandra.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/chroma.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/clarifai.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/clickhouse.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/deeplake.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/docarray/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/docarray/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/docarray/hnsw.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/docarray/in_memory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/elastic_vector_search.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/faiss.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/hologres.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/lancedb.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/marqo.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/matching_engine.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/milvus.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/mongodb_atlas.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/myscale.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/opensearch_vector_search.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/pgembedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/pgvector.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/pinecone.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/qdrant.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/redis.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/rocksetdb.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/singlestoredb.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/sklearn.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/starrocks.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/supabase.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/tair.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/tigris.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/typesense.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/utils.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/vectara.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/weaviate.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langchain/vectorstores/zilliz.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langsmith/cli/main.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langsmith/client.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langsmith/run_helpers.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/langsmith/run_trees.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/_openai_scripts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_requestor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/abstract/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/abstract/api_resource.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/abstract/createable_api_resource.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/abstract/deletable_api_resource.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/abstract/engine_api_resource.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/abstract/listable_api_resource.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/abstract/nested_resource_class_methods.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/abstract/updateable_api_resource.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/audio.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/chat_completion.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/completion.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/customer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/deployment.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/edit.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/embedding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/engine.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/error_object.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/experimental/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/experimental/completion_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/file.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/fine_tune.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/image.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/api_resources/moderation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/cli.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/datalib/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/datalib/common.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/datalib/numpy_helper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/datalib/pandas_helper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/embeddings_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/error.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/object_classes.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/openai_object.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/openai_response.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/tests/asyncio/test_endpoints.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/tests/test_api_requestor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/tests/test_endpoints.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/tests/test_exceptions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/tests/test_file_cli.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/tests/test_long_examples_validator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/tests/test_url_composition.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/tests/test_util.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/util.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/validators.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/openai/wandb_logger.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/pip/_vendor/rich/_emoji_codes.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/pygments/lexers/_cocoa_builtins.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/pygments/lexers/graphics.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/pygments/lexers/macaulay2.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/pygments/lexers/wgsl.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/rich/_emoji_codes.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/streamlit/external/langchain/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/streamlit/external/langchain/streamlit_callback_handler.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/streamlit/runtime/metrics_util.py",
        "providers": [
          "anthropic",
          "cohere",
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/tiktoken/core.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/tiktoken/model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/-/Lib/site-packages/tiktoken_ext/openai_public.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/demoapp2.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Devansh968-Chat-with-Pdf-using-Qdrant-vector-database-771195f/newapp.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "Josh-XT/AGiXT": {
    "owner": "Josh-XT",
    "repo": "AGiXT",
    "ref": "de7d913b2853708b9f9d4e7127ea48bca80865b9",
    "num_llm_files": 6,
    "providers": [
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "Josh-XT-AGiXT-de7d913/AgentLLM.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Josh-XT-AGiXT-de7d913/Config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Josh-XT-AGiXT-de7d913/commands/image_generator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Josh-XT-AGiXT-de7d913/provider/chatgpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Josh-XT-AGiXT-de7d913/provider/llamacpp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "Josh-XT-AGiXT-de7d913/provider/openai.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "Jerk400/h2ogpt-dev-local": {
    "owner": "Jerk400",
    "repo": "h2ogpt-dev-local",
    "ref": "ba56d6471080ec447c7c5347a2d4765ae4dba5b4",
    "num_llm_files": 40,
    "providers": [
      "anthropic",
      "cohere",
      "langchain",
      "llama",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/client/h2ogpt_client/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/client/h2ogpt_client/_core.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/client/h2ogpt_client/_utils.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/finetune.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/metrics/quip.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/models/create_model_cards.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/setup.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/cli.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/client_test.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/create_data.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/enums.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/eval.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/evaluate_params.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/export_hf_checkpoint.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/gen.py",
        "providers": [
          "langchain",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/gpt4all_llm.py",
        "providers": [
          "langchain",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/gpt_langchain.py",
        "providers": [
          "langchain",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/gradio_runner.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/h2oai_pipeline.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/image_captions.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/llama_flash_attn_monkey_patch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/llm_exllama.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/loaders.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/make_db.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/prompter.py",
        "providers": [
          "cohere",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/read_wiki_full.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/utils.py",
        "providers": [
          "langchain",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/src/utils_langchain.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/tests/test_cli.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/tests/test_client_calls.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/tests/test_eval.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/tests/test_eval_models.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/tests/test_inference_servers.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/tests/test_langchain_simple.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/tests/test_langchain_units.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/tests/test_long_context.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/tests/test_manual_test.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/tests/test_pipeline.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/tests/test_prompter.py",
        "providers": [
          "cohere",
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "TheJ-Erk400-h2ogpt-dev-local-ba56d64/tests/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "LlamaFamily/Llama-Chinese": {
    "owner": "LlamaFamily",
    "repo": "Llama-Chinese",
    "ref": "main",
    "num_llm_files": 8,
    "providers": [
      "langchain",
      "llama",
      "vllm"
    ],
    "files": [
      {
        "file_path": "LlamaFamily-Llama-Chinese-6fa0fff/examples/llama2_for_langchain.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "LlamaFamily-Llama-Chinese-6fa0fff/inference-speed/GPU/TensorRT-LLM_example/atom_inference.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "LlamaFamily-Llama-Chinese-6fa0fff/inference-speed/GPU/TensorRT-LLM_example/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "LlamaFamily-Llama-Chinese-6fa0fff/inference-speed/GPU/lmdeploy_example/test_api_server.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "LlamaFamily-Llama-Chinese-6fa0fff/inference-speed/GPU/vllm_example/api_server.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "LlamaFamily-Llama-Chinese-6fa0fff/inference-speed/GPU/vllm_example/client_test.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "LlamaFamily-Llama-Chinese-6fa0fff/scripts/api/accelerate_server.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "LlamaFamily-Llama-Chinese-6fa0fff/scripts/convert2hf/convert_llama_weights_to_hf.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "MaartenGr/BERTopic": {
    "owner": "MaartenGr",
    "repo": "BERTopic",
    "ref": "master",
    "num_llm_files": 11,
    "providers": [
      "anthropic",
      "cohere",
      "langchain",
      "litellm",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "MaartenGr-BERTopic-75f2910/bertopic/backend/__init__.py",
        "providers": [
          "cohere",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "MaartenGr-BERTopic-75f2910/bertopic/backend/_cohere.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "MaartenGr-BERTopic-75f2910/bertopic/backend/_langchain.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "MaartenGr-BERTopic-75f2910/bertopic/backend/_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "MaartenGr-BERTopic-75f2910/bertopic/representation/__init__.py",
        "providers": [
          "cohere",
          "langchain",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "MaartenGr-BERTopic-75f2910/bertopic/representation/_cohere.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "MaartenGr-BERTopic-75f2910/bertopic/representation/_langchain.py",
        "providers": [
          "anthropic",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "MaartenGr-BERTopic-75f2910/bertopic/representation/_litellm.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "MaartenGr-BERTopic-75f2910/bertopic/representation/_llamacpp.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "MaartenGr-BERTopic-75f2910/bertopic/representation/_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "MaartenGr-BERTopic-75f2910/bertopic/representation/_textgeneration.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "Mintplex-Labs/anything-llm": {
    "owner": "Mintplex-Labs",
    "repo": "anything-llm",
    "ref": "ebd3a62866e9e17b07a4a973b74329c0297fb78a",
    "num_llm_files": 9,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "Mintplex-Labs-anything-llm-ebd3a62/collector/scripts/gitbook.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Mintplex-Labs-anything-llm-ebd3a62/collector/scripts/link.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Mintplex-Labs-anything-llm-ebd3a62/collector/scripts/medium.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Mintplex-Labs-anything-llm-ebd3a62/collector/scripts/substack.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Mintplex-Labs-anything-llm-ebd3a62/collector/scripts/substack_utils.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Mintplex-Labs-anything-llm-ebd3a62/collector/scripts/watch/convert/as_docx.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Mintplex-Labs-anything-llm-ebd3a62/collector/scripts/watch/convert/as_markdown.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Mintplex-Labs-anything-llm-ebd3a62/collector/scripts/watch/convert/as_pdf.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Mintplex-Labs-anything-llm-ebd3a62/collector/scripts/youtube.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "OpenRLHF/OpenRLHF": {
    "owner": "OpenRLHF",
    "repo": "OpenRLHF",
    "ref": "main",
    "num_llm_files": 30,
    "providers": [
      "llama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/examples/python/agent_func.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/examples/python/agent_func_gem_multiturn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/examples/python/agent_func_nemogym_executor.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/cli/batch_inference.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/cli/interactive_chat.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/cli/serve_rm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/cli/train_dpo.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/cli/train_kd.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/cli/train_kto.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/cli/train_ppo_ray.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/cli/train_prm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/cli/train_rm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/cli/train_sft.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/models/loss.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/models/model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/trainer/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/trainer/ppo_trainer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/trainer/ppo_trainer_async.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/trainer/ppo_utils/experience_maker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/trainer/ppo_utils/experience_maker_async.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/trainer/ray/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/trainer/ray/ppo_actor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/trainer/ray/vllm_engine.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/trainer/ray/vllm_engine_async.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/trainer/ray/vllm_worker_wrap.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/utils/agent.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/utils/distributed_util.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/utils/logging_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/openrlhf/utils/utils.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "OpenRLHF-OpenRLHF-1bfcc33/setup.py",
        "providers": [
          "vllm"
        ]
      }
    ],
    "error": null
  },
  "Gamma-Software/AppifyAi": {
    "owner": "Gamma-Software",
    "repo": "AppifyAi",
    "ref": "1e2a008b29a0a14d590f41056226636dae266931",
    "num_llm_files": 8,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "Gamma-Software-AppifyAi-1e2a008/generative_app/core/app_pages/appifyai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Gamma-Software-AppifyAi-1e2a008/generative_app/core/app_pages/chat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Gamma-Software-AppifyAi-1e2a008/generative_app/core/auth/auth_connection.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Gamma-Software-AppifyAi-1e2a008/generative_app/core/chains/conversational_retrieval_over_code.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Gamma-Software-AppifyAi-1e2a008/generative_app/core/chains/doc_retriever.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Gamma-Software-AppifyAi-1e2a008/generative_app/core/chains/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Gamma-Software-AppifyAi-1e2a008/generative_app/core/chains/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Gamma-Software-AppifyAi-1e2a008/generative_app/core/secure_app.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "NVIDIA/Megatron-LM": {
    "owner": "NVIDIA",
    "repo": "Megatron-LM",
    "ref": "main",
    "num_llm_files": 58,
    "providers": [
      "cohere",
      "llama",
      "mistral",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/mimo/avlm_inference.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/mimo/configs/llava_vlm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/mimo/configs/mock.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/mimo/data/energon_avlm_task_encoder.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/mimo/data/energon_vlm_task_encoder.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/mimo/data/utils/calculate_audio_tokens.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/mimo/model_providers/hf_clip_encoder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/mimo/model_providers/llava_avlm.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/mimo/model_providers/llava_vlm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/multimodal/config.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/multimodal/dataset_helpers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/multimodal/image_processing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/multimodal/model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/multimodal/model_converter/clip_converter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/multimodal/model_converter/siglip_converter.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/multimodal/model_converter/vision_model_tester.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/multimodal/multimodal_args.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/multimodal/run_text_generation.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/post_training/modelopt/finetune.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/post_training/modelopt/generate.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/examples/rl/environments/math/gsm8k_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/dist_checkpointing/strategies/torch.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/export/model_type.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/export/trtllm/engine_builder/trtllm_engine_builder.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/export/trtllm/trt_model_config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/export/trtllm/trt_model_type.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/export/trtllm/trtllm_helper.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/inference/async_stream.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/inference/engines/dynamic_engine.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/inference/text_generation_server/endpoints/completions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/models/common/embeddings/rotary_pos_embedding.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/models/vision/clip_vit_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/post_training/modelopt/gpt/model_specs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/ssm/triton_cache_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/tokenizers/megatron_tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/tokenizers/text/libraries/tiktoken_tokenizer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/tokenizers/text/utils/build_tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/transformer/heterogeneous/heterogeneous_config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/transformer/transformer_config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/core/transformer/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/legacy/model/bert_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/legacy/model/t5_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/legacy/model/transformer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/legacy/model/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/post_training/arguments.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/post_training/model_builder.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/post_training/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/training/arguments.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/training/tokenizer/gpt2_tokenization.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/training/tokenizer/multimodal_tokenizer.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/megatron/training/tokenizer/tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/tests/functional_tests/test_cases/common/ckpt_converter/__main__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/tests/unit_tests/models/test_mimo_audio_submodules.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/tests/unit_tests/models/test_mimo_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/tests/unit_tests/post_training/test_modelopt_module_spec.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/tests/unit_tests/test_tokenizer.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/tools/checkpoint/loader_llama_mistral.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "NVIDIA-Megatron-LM-03b6d31/tools/checkpoint/loader_mixtral_hf.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "OthersideAI/self-operating-computer": {
    "owner": "OthersideAI",
    "repo": "self-operating-computer",
    "ref": "main",
    "num_llm_files": 5,
    "providers": [
      "anthropic",
      "gemini",
      "llama",
      "ollama",
      "openai"
    ],
    "files": [
      {
        "file_path": "OthersideAI-self-operating-computer-fac568e/evaluate.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OthersideAI-self-operating-computer-fac568e/operate/config.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "OthersideAI-self-operating-computer-fac568e/operate/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "OthersideAI-self-operating-computer-fac568e/operate/models/apis.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "OthersideAI-self-operating-computer-fac568e/operate/models/prompts.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "REFRIED-BoolEANS/privatgpt-gui": {
    "owner": "REFRIED-BoolEANS",
    "repo": "privatgpt-gui",
    "ref": "840675927b1ace596dcc2c8ed0f6f483805e33fe",
    "num_llm_files": 2,
    "providers": [
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "REFRIED-BoolEANS-privatgpt-gui-8406759/ingest.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "REFRIED-BoolEANS-privatgpt-gui-8406759/privateGPT.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "QuivrHQ/quivr": {
    "owner": "QuivrHQ",
    "repo": "quivr",
    "ref": "main",
    "num_llm_files": 37,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "groq",
      "langchain",
      "llama",
      "mistral",
      "ollama",
      "openai"
    ],
    "files": [
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/brain/brain.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/brain/brain_defaults.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/brain/serialization.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/config.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/files/file.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/llm/llm_endpoint.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "langchain",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/llm_tools/entity.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/llm_tools/other_tools.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/llm_tools/web_search_tools.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/processor/implementations/default.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/processor/implementations/megaparse_processor.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/processor/implementations/simple_txt_processor.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/processor/implementations/tika_processor.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/processor/processor_base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/rag/entities/chat.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/rag/entities/config.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "langchain",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/rag/entities/models.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/rag/prompts.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/rag/quivr_rag.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/rag/quivr_rag_langgraph.py",
        "providers": [
          "cohere",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/quivr_core/rag/utils.py",
        "providers": [
          "langchain",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/tests/conftest.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/tests/fixture_chunks.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/tests/processor/test_default_implementations.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/tests/processor/test_registry.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/tests/processor/test_simple_txt_processor.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/tests/test_brain.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/tests/test_chat_history.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/tests/test_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/tests/test_llm_endpoint.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/tests/test_quivr_rag.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/core/tests/test_utils.py",
        "providers": [
          "langchain",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/examples/chatbot_voice/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/examples/pdf_document_from_yaml.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/examples/pdf_parsing_tika.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/examples/quivr-whisper/app.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-947a785/examples/simple_question_megaparse.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "RayVentura/ShortGPT": {
    "owner": "RayVentura",
    "repo": "ShortGPT",
    "ref": "stable",
    "num_llm_files": 9,
    "providers": [
      "gemini",
      "openai"
    ],
    "files": [
      {
        "file_path": "RayVentura-ShortGPT-3df4e0f/gui/ui_tab_config.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "RayVentura-ShortGPT-3df4e0f/gui/ui_tab_short_automation.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "RayVentura-ShortGPT-3df4e0f/gui/ui_tab_video_automation.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "RayVentura-ShortGPT-3df4e0f/setup.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "RayVentura-ShortGPT-3df4e0f/shortGPT/config/api_db.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "RayVentura-ShortGPT-3df4e0f/shortGPT/config/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "RayVentura-ShortGPT-3df4e0f/shortGPT/gpt/gpt_utils.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "RayVentura-ShortGPT-3df4e0f/shortGPT/tracking/api_tracking.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "RayVentura-ShortGPT-3df4e0f/shortGPT/tracking/cost_analytics.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "RockChinQ/LangBot": {
    "owner": "RockChinQ",
    "repo": "LangBot",
    "ref": "master",
    "num_llm_files": 34,
    "providers": [
      "anthropic",
      "gemini",
      "langchain",
      "llama",
      "ollama",
      "openai"
    ],
    "files": [
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/core/bootutils/deps.py",
        "providers": [
          "anthropic",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/core/migrations/m002_openai_config_migration.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/core/migrations/m003_anthropic_requester_cfg_completion.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/core/migrations/m004_moonshot_cfg_completion.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/core/migrations/m005_deepseek_cfg_completion.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/core/migrations/m010_ollama_requester_config.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/core/migrations/m040_ppio_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/persistence/migrations/dbm001_migrate_v3_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/pipeline/pipelinemgr.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/302aichatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/anthropicmsgs.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/bailianchatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/chatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/compsharechatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/deepseekchatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/geminichatcmpl.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/jiekouaichatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/lmstudiochatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/modelscopechatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/moonshotchatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/newapichatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/ollamachat.py",
        "providers": [
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/openrouterchatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/ppiochatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/qhaigcchatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/shengsuanyun.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/siliconflowchatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/tokenponychatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/volcarkchatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/xaichatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/modelmgr/requesters/zhipuaichatcmpl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/provider/tools/toolmgr.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "langbot-app-LangBot-2f51f5f/src/langbot/pkg/rag/knowledge/services/chunker.py",
        "providers": [
          "langchain"
        ]
      }
    ],
    "error": null
  },
  "PaddlePaddle/PaddleNLP": {
    "owner": "PaddlePaddle",
    "repo": "PaddleNLP",
    "ref": "develop",
    "num_llm_files": 255,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "langchain",
      "llama",
      "mistral",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/csrc/utils/tune_cublaslt_int8_gemm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/alignment/dpo/run_dpo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/alignment/kto/run_kto.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/alignment/rl/gsm8k_processor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/alignment/rl/tests/test_export.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/alignment/rm/legacy/run_reward.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/alignment/rm/reward_model.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/alignment/rm/run_reward.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/application/distill/distill_data.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/application/distill/grader.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/auto_parallel/deepseek-v3/run_pretrain_auto.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/auto_parallel/gpt-3/run_pretrain_auto.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/auto_parallel/llama/run_pretrain_auto.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/auto_parallel/qwen/run_pretrain_auto.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/auto_parallel/run_dpo_auto.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/auto_parallel/run_finetune_auto.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/benchmark/gsm8k/bench_gsm8k.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/benchmark/mmlu_pro/evaluate_from_api.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/benchmark/rl/api_serve.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/benchmark/rl/torch_infer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/benchmark/serving/benchmark_client.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/config/llama/pretrain_argument.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/devices/intel_hpu/llama/inference_hpu.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/devices/intel_hpu/llama/test_llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/devices/intel_hpu/tests/config/llm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/devices/mlu/llama/download_init0501_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/devices/npu/llama/export_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/experimental/ceval/default/eval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/experimental/ceval/default/evaluator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/experimental/ceval/default/model_evaluator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/predict/export_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/predict/flask_server.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/predict/gradio_ui.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/predict/predictor.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/predict/request_flask_server.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/run_finetune.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/run_pretrain.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/run_quantization.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/server/server/server/checker.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/server/server/server/data/processor.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/server/server/server/download_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/server/server/server/engine/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/server/server/server/http_server/adapter_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/server/server/server/http_server/api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/server/server/server/http_server/app.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/utils/data.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/utils/quant.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/utils/register_reshard.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/llm/utils/sp_async_reduce_scatter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/ops/src/paddlenlp_kernel/triton/mamba/layer_norm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/ops/src/paddlenlp_kernel/triton/mamba/layernorm_gated.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/experimental/transformers/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/experimental/transformers/bloom/modeling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/experimental/transformers/chatglm/modeling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/experimental/transformers/deepseek_v2/modeling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/experimental/transformers/fused_transformer_layers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/experimental/transformers/generation_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/experimental/transformers/llama/modeling.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/experimental/transformers/mistral/modeling.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/experimental/transformers/opt/modeling.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/experimental/transformers/qwen/modeling.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/ops/custom_all_reduce/cuda_wrapper.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/ops/triton_ops/fused_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/peft/prefix/__init__.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/peft/prefix/utils.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/peft/reft/modeling_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/peft/tare/tare_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/rl/models/model_pp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/rl/models/ppo_model_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/rl/trainer/trainer_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/taskflow/taskflow.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/trainer/trainer_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/trainer/training_args.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/trainer/unified_checkpoint/load_dynamic.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/__init__.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/activations.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/auto/configuration.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/auto/image_processing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/auto/modeling.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/auto/processing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/auto/tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/clip/configuration.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/clip/modeling.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/clip/processing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/clip/tokenizer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/clipseg/configuration.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/clipseg/image_processing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/clipseg/modeling.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/clipseg/processing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/configuration_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/convert_slow_tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/ctrl/modeling.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/dallebart/tokenizer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/deberta_v2/modeling.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/deepseek_v2/modeling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/deepseek_v2/modeling_auto.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/deepseek_v2/tokenizer_fast.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/feature_extraction_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/gemma/modeling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/gemma/tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/gemma/tokenizer_fast.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/gpt/modeling.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/gpt/modeling_auto.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/gpt/modeling_auto_pp.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/gpt/modeling_network.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/gpt/modeling_pp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/gpt/tokenizer_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/image_processing_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/jamba/modeling.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/jamba/tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/llama/auto_dist_config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/llama/configuration.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/llama/modeling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/llama/modeling_auto.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/llama/modeling_auto_pp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/llama/modeling_network.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/llama/modeling_pp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/llama/tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/llama/tokenizer_fast.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/long_sequence_strategies/embedding_strategies.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/longlora.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/mamba/modeling.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/minigpt4/configuration.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/minigpt4/image_processing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/minigpt4/modeling.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/minigpt4/processing.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/minimax_text_01/modeling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/mistral/__init__.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/mistral/configuration.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/mistral/modeling.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/mixtral/configuration.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/mixtral/modeling.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/nv_embed/modeling.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/opt/modeling.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/qwen/modeling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/qwen/modeling_auto.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/qwen/modeling_network.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/qwen2/modeling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/qwen2_moe/modeling.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/qwen3/configuration.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/qwen3/modeling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/qwen3_moe/configuration.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/qwen3_moe/modeling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/tokenizer_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/visualglm/modeling.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/visualglm/processing.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/xlm_roberta/tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/yuan/modeling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/transformers/yuan/tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/paddlenlp/trl/llm_utils.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/scripts/codestyle/convert/example/qwen2/configuration.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/scripts/codestyle/convert/example/qwen2/modeling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/scripts/codestyle/convert/example/qwen2/modeling_qwen2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/scripts/codestyle/convert/example/qwen2/modular_qwen2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/scripts/codestyle/convert/main.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/scripts/codestyle/convert/until/rename_identifiers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/examples/benchmark/ceval/eval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/examples/benchmark/ceval/evaluator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/examples/benchmark/ceval/model_evaluator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/examples/benchmark/llm/llama_single_gpu/benchmark.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/examples/benchmark/llm/llama_single_gpu/benchmark_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/examples/benchmark/peft/paddle/benchmark.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/examples/benchmark/peft/paddle/inference_benchmark.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/examples/benchmark/peft/torch/benchmark.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/examples/benchmark/peft/torch/inference_benchmark.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/examples/multimodal/minigpt4/merge_weight.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/examples/multimodal/minigpt4/run_predict.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/model_zoo/gpt-3/ppfleetx/data/tokenizers/gpt_tokenizer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/model_zoo/gpt-3/ppfleetx/data/tokenizers/tokenization_utils_base.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/model_zoo/gpt-3/ppfleetx/models/language_model/gpt/auto/auto_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/model_zoo/gpt-3/ppfleetx/models/language_model/gpt/dygraph/hybrid_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/model_zoo/gpt-3/ppfleetx/models/language_model/gpt/dygraph/single_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/examples/contrastive_training/evaluation/benchmarks.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/examples/contrastive_training/evaluation/eval_mteb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/examples/contrastive_training/evaluation/modelling_quant.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/examples/contrastive_training/shortgpt_prune.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/examples/contrastive_training/train.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/examples/tree-of-thought/demo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/examples/tree-of-thought/run.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/examples/tree-of-thought/src/llm/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/examples/tree-of-thought/src/llm/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/examples/tree-of-thought/src/tot/models.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/examples/tree-of-thought/src/tot/prompts/text.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/examples/tree-of-thought/src/tot/tasks/text.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/pipelines/nodes/preprocessor/text_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/pipelines/nodes/prompt/invocation_layer/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/pipelines/nodes/prompt/invocation_layer/chatgpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/pipelines/nodes/prompt/invocation_layer/open_ai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/pipelines/nodes/prompt/prompt_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/pipelines/nodes/prompt/prompt_node.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/pipelines/nodes/retriever/ernie_encoder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/tests/agents/test_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/tests/nodes/preprocessor/test_text_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/tests/nodes/prompt/invocation_layer/test_chatgpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/tests/nodes/prompt/invocation_layer/test_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/slm/pipelines/tests/nodes/prompt/test_prompt_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/dataset/test_zero_padding.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/generation/test_streamers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/generation/test_synced_gpus.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_adamw_mini.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_dislora.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_dpo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_finetune.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_finetune_prefix_tuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_gradio.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_linchain.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_lokr.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_long_sequence_strategies.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_lora.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_lorapro.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_mora.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_mos_lora.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_nola.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_ppo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_predictor.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_predictor_v1.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_pretrain.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_prm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_ptq.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_reft.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_rm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_speculate_decoding.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/llm/test_vera.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/longlora/test_longlora.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/peft/test_prefix.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/peft/test_reft.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/pose/test_long_sequence_strategies_yarn.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/trainer/test_argparser.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/trainer/test_auto_argparser.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/trainer/test_lora_unified_checkpoint.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/trainer/test_unified_checkpoint.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/auto/test_confiugration.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/auto/test_tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/chatglm/test_modeling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/clip/test_modeling.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/clipseg/test_modeling.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/clipseg/test_processor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/llama/test_modeling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/llama/test_tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/load_subfolder/test_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/load_subfolder/test_image_processor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/load_subfolder/test_processor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/load_subfolder/test_tokenizer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/minigpt4/test_modeling.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/minigpt4/test_processor.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/mistral/test_modeling.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/qwen2/test_modeling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/test_chat_template.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/test_conversion_common.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/test_generation_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/test_modeling_common.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/test_quantization.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/test_refined_recompute.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/test_tensor_parallel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "PaddlePaddle-PaddleNLP-b0276d7/tests/transformers/test_tokenizer_fast.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "SYSTRAN/faster-whisper": {
    "owner": "SYSTRAN",
    "repo": "faster-whisper",
    "ref": "master",
    "num_llm_files": 3,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "SYSTRAN-faster-whisper-ed9a06c/faster_whisper/audio.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "SYSTRAN-faster-whisper-ed9a06c/faster_whisper/transcribe.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "SYSTRAN-faster-whisper-ed9a06c/setup.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "BerriAI/litellm": {
    "owner": "BerriAI",
    "repo": "litellm",
    "ref": "main",
    "num_llm_files": 2251,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "groq",
      "langchain",
      "litellm",
      "llama",
      "mistral",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "BerriAI-litellm-05f800f/.github/scripts/scan_keywords.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/.github/workflows/auto_update_price_and_context_window_file.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/.github/workflows/interpret_load_test.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/.github/workflows/locustfile.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/.github/workflows/run_llm_translation_tests.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/.github/workflows/update_release.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/ci_cd/check_files_match.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/ci_cd/run_migration.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/benchmark/benchmark.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/benchmark/eval_suites_mlflow_autoevals/auto_evals.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/codellama-server/main.py",
        "providers": [
          "anthropic",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/litellm-ollama-docker-image/test.py",
        "providers": [
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/litellm_proxy_server/batch_api/bedrock/bedrock.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/litellm_proxy_server/cli_token_usage.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/litellm_proxy_server/mcp/mcp_with_litellm_proxy.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/litellm_proxy_server/secret_manager/my_secret_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/litellm_router/load_test_proxy.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/litellm_router/load_test_queuing.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/litellm_router/load_test_router.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/litellm_router_load_test/memory_usage/router_endpoint.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/litellm_router_load_test/memory_usage/router_memory_usage copy.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/litellm_router_load_test/memory_usage/router_memory_usage.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/litellm_router_load_test/test_loadtest_openai_client.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/litellm_router_load_test/test_loadtest_router.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/litellm_router_load_test/test_loadtest_router_withs3_cache.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/misc/add_new_models.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/misc/migrate_proxy_config.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/misc/openai_timeouts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/misc/sagmaker_streaming.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/misc/test_responses_api.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/misc/update_json_caching.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/mock_guardrail_server/mock_bedrock_guardrail_server.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/cookbook/veo_video_generation.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/db_scripts/create_views.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/db_scripts/migrate_keys.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/db_scripts/update_unassigned_teams.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/enterprise_hooks/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/enterprise_hooks/aporia_ai.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/enterprise_hooks/banned_keywords.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/enterprise_hooks/blocked_user_list.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/enterprise_hooks/google_text_moderation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/enterprise_hooks/openai_moderation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/enterprise_callbacks/callback_controls.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/enterprise_callbacks/example_logging_api.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/enterprise_callbacks/llama_guard.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/enterprise_callbacks/llm_guard.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/enterprise_callbacks/pagerduty/pagerduty.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/enterprise_callbacks/secret_detection.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/enterprise_callbacks/secrets_plugins/openai_api_key.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/enterprise_callbacks/send_emails/base_email.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/enterprise_callbacks/send_emails/endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/enterprise_callbacks/send_emails/resend_email.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/enterprise_callbacks/send_emails/smtp_email.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/integrations/custom_guardrail.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/litellm_core_utils/litellm_logging.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/proxy/audit_logging_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/proxy/auth/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/proxy/auth/custom_sso_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/proxy/auth/route_checks.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/proxy/auth/user_api_key_auth.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/proxy/common_utils/check_batch_cost.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/proxy/enterprise_routes.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/proxy/hooks/managed_files.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/proxy/management_endpoints/internal_user_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/proxy/management_endpoints/key_management_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/proxy/proxy_server.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/proxy/utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/proxy/vector_stores/endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/enterprise/litellm_enterprise/types/enterprise_callbacks/send_emails.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm-proxy-extras/litellm_proxy_extras/_logging.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm-proxy-extras/litellm_proxy_extras/utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/__init__.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/_lazy_imports.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/_logging.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/_redis.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/_service_logger.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/_version.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/a2a_protocol/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/a2a_protocol/client.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/a2a_protocol/cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/a2a_protocol/main.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/anthropic_interface/__init__.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/anthropic_interface/messages/__init__.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/assistants/main.py",
        "providers": [
          "groq",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/assistants/utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/batch_completion/main.py",
        "providers": [
          "litellm",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/batches/batch_utils.py",
        "providers": [
          "gemini",
          "litellm",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/batches/main.py",
        "providers": [
          "groq",
          "litellm",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/budget_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/caching/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/caching/azure_blob_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/caching/caching.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/caching/caching_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/caching/disk_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/caching/dual_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/caching/gcs_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/caching/in_memory_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/caching/qdrant_semantic_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/caching/redis_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/caching/redis_cluster_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/caching/redis_semantic_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/caching/s3_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/completion_extras/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/completion_extras/litellm_responses_transformation/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/completion_extras/litellm_responses_transformation/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/constants.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/containers/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/containers/main.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/containers/utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/cost_calculator.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/endpoints/speech/speech_to_completion_bridge/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/endpoints/speech/speech_to_completion_bridge/transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/exceptions.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/experimental_mcp_client/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/experimental_mcp_client/client.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/experimental_mcp_client/tools.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/files/main.py",
        "providers": [
          "groq",
          "litellm",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/files/utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/fine_tuning/main.py",
        "providers": [
          "groq",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/google_genai/__init__.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/google_genai/adapters/__init__.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/google_genai/adapters/handler.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/google_genai/adapters/transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/google_genai/main.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/google_genai/streaming_iterator.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/images/main.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/images/utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/SlackAlerting/batching_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/SlackAlerting/budget_alert_types.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/SlackAlerting/hanging_request_check.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/SlackAlerting/slack_alerting.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/SlackAlerting/utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/_types/open_inference.py",
        "providers": [
          "anthropic",
          "cohere",
          "langchain",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/additional_logging_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/agentops/agentops.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/anthropic_cache_control_hook.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/argilla.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/arize/_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/arize/arize.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/arize/arize_phoenix.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/athina.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/azure_storage/azure_storage.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/bitbucket/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/bitbucket/bitbucket_client.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/bitbucket/bitbucket_prompt_manager.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/braintrust_logging.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/cloudzero/cloudzero.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/cloudzero/cz_resource_names.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/cloudzero/database.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/cloudzero/transform.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/custom_batch_logger.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/custom_guardrail.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/custom_logger.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/custom_prompt_management.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/custom_secret_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/custom_sso_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/datadog/datadog.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/datadog/datadog_llm_obs.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/deepeval/api.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/deepeval/deepeval.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/deepeval/utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/dotprompt/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/dotprompt/dotprompt_manager.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/dotprompt/prompt_manager.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/dynamodb.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/email_alerting.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/email_templates/email_footer.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/email_templates/key_created_email.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/email_templates/key_rotated_email.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/email_templates/templates.py",
        "providers": [
          "langchain",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/email_templates/user_invitation_email.py",
        "providers": [
          "anthropic",
          "langchain",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/galileo.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/gcs_bucket/gcs_bucket.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/gcs_bucket/gcs_bucket_base.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/gcs_pubsub/pub_sub.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/generic_api/generic_api_callback.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/gitlab/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/gitlab/gitlab_client.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/gitlab/gitlab_prompt_manager.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/greenscale.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/helicone.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/humanloop.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/lago.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/langfuse/langfuse.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/langfuse/langfuse_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/langfuse/langfuse_otel.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/langfuse/langfuse_otel_attributes.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/langfuse/langfuse_prompt_management.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/langsmith.py",
        "providers": [
          "langchain",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/langtrace.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/literal_ai.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/logfire_logger.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/lunary.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/mlflow.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/openmeter.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/opentelemetry.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/opik/opik.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/opik/opik_payload_builder/api.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/opik/opik_payload_builder/extractors.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/opik/opik_payload_builder/payload_builders.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/posthog.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/prometheus.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/prometheus_helpers/prometheus_api.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/prometheus_services.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/prompt_layer.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/prompt_management_base.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/s3.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/s3_v2.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/sqs.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/supabase.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/traceloop.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/vector_store_integrations/base_vector_store.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/vector_store_integrations/vector_store_pre_call_hook.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/weave/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/weave/weave_otel.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/integrations/weights_biases.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/api_route_to_call_types.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/audio_utils/utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/cached_imports.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/cli_token_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/core_helpers.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/coroutine_checker.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/credential_accessor.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/custom_logger_registry.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/dd_tracing.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/default_encoding.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/exception_mapping_utils.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/fallback_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/get_litellm_params.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/get_llm_provider_logic.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/get_model_cost_map.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/get_provider_specific_headers.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/get_supported_openai_params.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/health_check_helpers.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/health_check_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/initialize_dynamic_callback_params.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/json_validation_rule.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/litellm_logging.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/llm_cost_calc/tool_call_cost_tracking.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/llm_cost_calc/usage_object_transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/llm_cost_calc/utils.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/llm_request_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/llm_response_utils/get_api_base.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/llm_response_utils/get_headers.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/llm_response_utils/response_metadata.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/logging_callback_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/logging_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/logging_worker.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/model_param_helper.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/model_response_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/prompt_templates/common_utils.py",
        "providers": [
          "gemini",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/prompt_templates/factory.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/prompt_templates/huggingface_template_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/prompt_templates/image_handling.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/realtime_streaming.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/redact_messages.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/rules.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/safe_json_dumps.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/safe_json_loads.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/sensitive_data_masker.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/specialty_caches/dynamic_logging_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/streaming_chunk_builder_utils.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/streaming_handler.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/litellm_core_utils/token_counter.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/__init__.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/ai21/chat/transformation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/aiml/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/aiml/image_generation/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/aiml/image_generation/cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/aiml/image_generation/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/aiohttp_openai/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/amazon_nova/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/amazon_nova/cost_calculation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/__init__.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/batches/transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/chat/__init__.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/chat/guardrail_translation/__init__.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/chat/guardrail_translation/handler.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/chat/handler.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/chat/transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/common_utils.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/completion/handler.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/completion/transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/cost_calculation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/experimental_pass_through/adapters/__init__.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/experimental_pass_through/adapters/handler.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/experimental_pass_through/adapters/streaming_iterator.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/experimental_pass_through/adapters/transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/experimental_pass_through/messages/handler.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/experimental_pass_through/messages/streaming_iterator.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/experimental_pass_through/messages/transformation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/experimental_pass_through/messages/utils.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/skills/__init__.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/anthropic/skills/transformation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/assistants.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/audio_transcriptions.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/azure.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/batches/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/chat/gpt_5_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/chat/gpt_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/chat/o_series_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/chat/o_series_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/common_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/completion/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/completion/transformation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/cost_calculation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/exception_mapping.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/files/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/fine_tuning/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/image_edit/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/image_generation/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/image_generation/dall_e_2_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/image_generation/dall_e_3_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/image_generation/gpt_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/passthrough/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/realtime/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/responses/o_series_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/responses/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/text_to_speech/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/vector_stores/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure/videos/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/anthropic/__init__.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/anthropic/handler.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/anthropic/messages_transformation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/anthropic/transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/chat/handler.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/chat/transformation.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/common_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/embed/cohere_transformation.py",
        "providers": [
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/embed/handler.py",
        "providers": [
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/image_edit/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/image_edit/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/image_generation/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/image_generation/cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/image_generation/dall_e_2_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/image_generation/dall_e_3_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/image_generation/flux_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/image_generation/gpt_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/ocr/common_utils.py",
        "providers": [
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/ocr/document_intelligence/transformation.py",
        "providers": [
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/ocr/transformation.py",
        "providers": [
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/rerank/transformation.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/vector_stores/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/azure_ai/vector_stores/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/__init__.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/anthropic_messages/transformation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/audio_transcription/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/base_model_iterator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/base_utils.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/batches/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/bridges/completion_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/chat/transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/completion/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/containers/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/embedding/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/files/transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/google_genai/transformation.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/guardrail_translation/base_translation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/image_edit/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/image_generation/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/image_variations/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/ocr/transformation.py",
        "providers": [
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/passthrough/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/realtime/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/rerank/transformation.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/responses/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/search/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/search/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/skills/transformation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/text_to_speech/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/vector_store/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/vector_store_files/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/base_llm/videos/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/baseten/chat.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/base_aws_llm.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/batches/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/batches/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/__init__.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/agentcore/sse_iterator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/agentcore/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/converse_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/converse_like/handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/converse_transformation.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/invoke_agent/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/invoke_handler.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/invoke_transformations/amazon_ai21_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/invoke_transformations/amazon_cohere_transformation.py",
        "providers": [
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/invoke_transformations/amazon_deepseek_transformation.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/invoke_transformations/amazon_llama_transformation.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/invoke_transformations/amazon_mistral_transformation.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/invoke_transformations/amazon_nova_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/invoke_transformations/amazon_openai_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/invoke_transformations/amazon_qwen2_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/invoke_transformations/amazon_qwen3_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/invoke_transformations/amazon_titan_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/invoke_transformations/amazon_twelvelabs_pegasus_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/invoke_transformations/anthropic_claude2_transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/invoke_transformations/anthropic_claude3_transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/chat/invoke_transformations/base_invoke_transformation.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/common_utils.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/cost_calculation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/count_tokens/handler.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/count_tokens/transformation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/embed/amazon_nova_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/embed/amazon_titan_g1_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/embed/amazon_titan_multimodal_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/embed/amazon_titan_v2_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/embed/cohere_transformation.py",
        "providers": [
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/embed/embedding.py",
        "providers": [
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/embed/twelvelabs_marengo_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/files/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/files/transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/image/amazon_nova_canvas_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/image/amazon_stability1_transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/image/amazon_stability3_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/image/amazon_titan_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/image/cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/image/image_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/messages/invoke_transformations/anthropic_claude3_transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/passthrough/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/rerank/handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/rerank/transformation.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bedrock/vector_stores/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bytez/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/bytez/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cerebras/chat.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/clarifai/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cloudflare/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/codestral/completion/handler.py",
        "providers": [
          "anthropic",
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/codestral/completion/transformation.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cohere/chat/transformation.py",
        "providers": [
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cohere/chat/v2_transformation.py",
        "providers": [
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cohere/common_utils.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cohere/embed/handler.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cohere/embed/transformation.py",
        "providers": [
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cohere/embed/v1_transformation.py",
        "providers": [
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cohere/rerank/guardrail_translation/__init__.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cohere/rerank/guardrail_translation/handler.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cohere/rerank/handler.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cohere/rerank/transformation.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cohere/rerank_v2/transformation.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cometapi/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cometapi/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cometapi/embed/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cometapi/image_generation/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cometapi/image_generation/cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/cometapi/image_generation/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/compactifai/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/compactifai/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/custom_httpx/aiohttp_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/custom_httpx/aiohttp_transport.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/custom_httpx/async_client_cleanup.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/custom_httpx/http_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/custom_httpx/httpx_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/custom_httpx/llm_http_handler.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/custom_llm.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/dashscope/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/dashscope/cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/databricks/chat/transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/databricks/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/databricks/cost_calculator.py",
        "providers": [
          "anthropic",
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/databricks/embed/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/databricks/embed/transformation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/databricks/streaming_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/dataforseo/search/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/datarobot/chat/transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/deepgram/audio_transcription/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/deepgram/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/deepinfra/chat/transformation.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/deepinfra/rerank/transformation.py",
        "providers": [
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/deepseek/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/deepseek/cost_calculator.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/deprecated_providers/aleph_alpha.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/deprecated_providers/palm.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/docker_model_runner/chat/transformation.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/elevenlabs/audio_transcription/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/elevenlabs/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/elevenlabs/text_to_speech/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/empower/chat/transformation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/exa_ai/search/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/exa_ai/search/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fal_ai/cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fal_ai/image_generation/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fal_ai/image_generation/bria_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fal_ai/image_generation/bytedance_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fal_ai/image_generation/flux_pro_v11_transformation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fal_ai/image_generation/flux_pro_v11_ultra_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fal_ai/image_generation/flux_schnell_transformation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fal_ai/image_generation/ideogram_v3_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fal_ai/image_generation/imagen4_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fal_ai/image_generation/recraft_v3_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fal_ai/image_generation/stable_diffusion_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fal_ai/image_generation/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/featherless_ai/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/firecrawl/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/firecrawl/search/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/firecrawl/search/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fireworks_ai/audio_transcription/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fireworks_ai/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fireworks_ai/common_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fireworks_ai/completion/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fireworks_ai/cost_calculator.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fireworks_ai/embed/fireworks_ai_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/fireworks_ai/rerank/transformation.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/friendliai/chat/transformation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/galadriel/chat/transformation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gemini/chat/transformation.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gemini/common_utils.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gemini/cost_calculator.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gemini/count_tokens/handler.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gemini/files/transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gemini/google_genai/transformation.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gemini/image_edit/__init__.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gemini/image_edit/cost_calculator.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gemini/image_edit/transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gemini/image_generation/__init__.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gemini/image_generation/cost_calculator.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gemini/image_generation/transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gemini/realtime/transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gemini/vector_stores/__init__.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gemini/vector_stores/transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gemini/videos/__init__.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gemini/videos/transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/github/chat/transformation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/github_copilot/authenticator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/github_copilot/chat/transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/github_copilot/common_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/github_copilot/embedding/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/github_copilot/responses/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/google_pse/search/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/google_pse/search/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/gradient_ai/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/groq/chat/handler.py",
        "providers": [
          "groq",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/groq/chat/transformation.py",
        "providers": [
          "anthropic",
          "groq",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/groq/stt/transformation.py",
        "providers": [
          "groq",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/heroku/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/hosted_vllm/chat/transformation.py",
        "providers": [
          "litellm",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/hosted_vllm/rerank/transformation.py",
        "providers": [
          "cohere",
          "litellm",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/hosted_vllm/transcriptions/transformation.py",
        "providers": [
          "litellm",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/huggingface/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/huggingface/common_utils.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/huggingface/embedding/handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/huggingface/embedding/transformation.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/huggingface/rerank/transformation.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/hyperbolic/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/infinity/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/infinity/embedding/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/infinity/rerank/transformation.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/jina_ai/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/jina_ai/embedding/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/jina_ai/rerank/transformation.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/lambda_ai/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/lemonade/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/lemonade/cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/litellm_proxy/chat/transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/litellm_proxy/image_edit/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/litellm_proxy/image_generation/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/litellm_proxy/responses/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/llamafile/chat/transformation.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/lm_studio/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/lm_studio/embed/transformation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/maritalk.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/meta_llama/chat/transformation.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/milvus/vector_stores/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/milvus/vector_stores/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/mistral/chat/transformation.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/mistral/embedding.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/mistral/ocr/__init__.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/mistral/ocr/transformation.py",
        "providers": [
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/moonshot/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/morph/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/nebius/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/nebius/embedding/transformation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/nlp_cloud/chat/handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/nlp_cloud/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/nlp_cloud/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/novita/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/nscale/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/nvidia_nim/chat/transformation.py",
        "providers": [
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/nvidia_nim/embed.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/nvidia_nim/rerank/transformation.py",
        "providers": [
          "cohere",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/oci/chat/transformation.py",
        "providers": [
          "cohere",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/oci/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/ollama/chat/transformation.py",
        "providers": [
          "cohere",
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/ollama/common_utils.py",
        "providers": [
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/ollama/completion/handler.py",
        "providers": [
          "litellm",
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/ollama/completion/transformation.py",
        "providers": [
          "cohere",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/ollama_chat.py",
        "providers": [
          "cohere",
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/oobabooga/chat/oobabooga.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/oobabooga/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/oobabooga/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/chat/gpt_5_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/chat/gpt_audio_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/chat/gpt_transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/chat/guardrail_translation/__init__.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/chat/guardrail_translation/handler.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/chat/o_series_handler.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/chat/o_series_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/common_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/completion/guardrail_translation/__init__.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/completion/guardrail_translation/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/completion/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/completion/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/completion/utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/containers/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/cost_calculation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/fine_tuning/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/image_edit/__init__.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/image_edit/dalle2_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/image_edit/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/image_generation/__init__.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/image_generation/dall_e_2_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/image_generation/dall_e_3_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/image_generation/gpt_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/image_generation/guardrail_translation/__init__.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/image_generation/guardrail_translation/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/image_variations/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/image_variations/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/openai.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/realtime/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/responses/guardrail_translation/__init__.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/responses/guardrail_translation/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/responses/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/speech/guardrail_translation/__init__.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/speech/guardrail_translation/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/transcriptions/gpt_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/transcriptions/guardrail_translation/__init__.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/transcriptions/guardrail_translation/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/transcriptions/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/transcriptions/whisper_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/vector_store_files/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/vector_stores/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai/videos/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai_like/chat/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai_like/chat/transformation.py",
        "providers": [
          "litellm",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai_like/common_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai_like/dynamic_config.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai_like/embedding/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openai_like/json_loader.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openrouter/chat/transformation.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/openrouter/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/ovhcloud/audio_transcription/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/ovhcloud/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/ovhcloud/embedding/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/ovhcloud/utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/parallel_ai/search/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/parallel_ai/search/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/pass_through/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/pass_through/guardrail_translation/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/pass_through/guardrail_translation/handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/perplexity/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/perplexity/cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/perplexity/search/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/petals/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/petals/completion/handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/petals/completion/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/pg_vector/vector_stores/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/predibase/chat/handler.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/predibase/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/predibase/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/ragflow/__init__.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/ragflow/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/ragflow/vector_stores/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/recraft/cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/recraft/image_edit/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/recraft/image_generation/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/recraft/image_generation/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/replicate/chat/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/replicate/chat/transformation.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/replicate/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/runwayml/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/runwayml/cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/runwayml/image_generation/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/runwayml/image_generation/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/runwayml/text_to_speech/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/runwayml/videos/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/sagemaker/chat/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/sagemaker/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/sagemaker/common_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/sagemaker/completion/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/sagemaker/completion/transformation.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/sagemaker/embedding/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/sambanova/chat.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/sambanova/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/sambanova/embedding/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/searxng/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/searxng/search/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/searxng/search/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/snowflake/chat/transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/snowflake/embedding/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/snowflake/utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/tavily/search/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/tavily/search/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/together_ai/chat.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/together_ai/completion/handler.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/together_ai/completion/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/together_ai/cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/together_ai/embed.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/together_ai/rerank/handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/together_ai/rerank/transformation.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/topaz/common_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/topaz/image_variations/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/triton/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/triton/completion/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/triton/embedding/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/v0/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vercel_ai_gateway/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vercel_ai_gateway/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/batches/handler.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/batches/transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/common_utils.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/context_caching/transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/context_caching/vertex_ai_context_caching.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/cost_calculator.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/count_tokens/handler.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/files/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/files/transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/fine_tuning/handler.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/gemini/cost_calculator.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/gemini/transformation.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/gemini_embeddings/batch_embed_content_handler.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/gemini_embeddings/batch_embed_content_transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/google_genai/transformation.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/image_edit/__init__.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/image_edit/cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/image_edit/vertex_gemini_transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/image_edit/vertex_imagen_transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/image_generation/__init__.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/image_generation/cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/image_generation/image_generation_handler.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/image_generation/vertex_gemini_transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/image_generation/vertex_imagen_transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/multimodal_embeddings/embedding_handler.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/multimodal_embeddings/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/ocr/transformation.py",
        "providers": [
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/rag_engine/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/rag_engine/ingestion.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/rag_engine/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/rerank/transformation.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/text_to_speech/text_to_speech_handler.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/text_to_speech/transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vector_stores/rag_api/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vector_stores/search_api/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vertex_ai_non_gemini.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vertex_ai_partner_models/__init__.py",
        "providers": [
          "anthropic",
          "litellm",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vertex_ai_partner_models/ai21/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vertex_ai_partner_models/anthropic/experimental_pass_through/transformation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vertex_ai_partner_models/anthropic/transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vertex_ai_partner_models/count_tokens/__init__.py",
        "providers": [
          "anthropic",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vertex_ai_partner_models/count_tokens/handler.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vertex_ai_partner_models/gpt_oss/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vertex_ai_partner_models/llama3/transformation.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vertex_ai_partner_models/main.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vertex_embeddings/bge.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vertex_embeddings/embedding_handler.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vertex_embeddings/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vertex_gemma_models/main.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vertex_gemma_models/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vertex_llm_base.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/vertex_model_garden/main.py",
        "providers": [
          "gemini",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vertex_ai/videos/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vllm/common_utils.py",
        "providers": [
          "litellm",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vllm/completion/handler.py",
        "providers": [
          "litellm",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vllm/completion/transformation.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/vllm/passthrough/transformation.py",
        "providers": [
          "litellm",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/volcengine/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/volcengine/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/volcengine/embedding/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/voyage/embedding/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/voyage/embedding/transformation_contextual.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/wandb/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/watsonx/audio_transcription/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/watsonx/chat/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/watsonx/chat/transformation.py",
        "providers": [
          "litellm",
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/watsonx/common_utils.py",
        "providers": [
          "anthropic",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/watsonx/completion/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/watsonx/embed/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/xai/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/xai/common_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/xai/cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/xai/responses/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/xinference/image_generation/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/xinference/image_generation/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/llms/zai/chat/transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/main.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/ocr/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/ocr/main.py",
        "providers": [
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/passthrough/main.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/_experimental/mcp_server/auth/litellm_auth_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/_experimental/mcp_server/auth/user_api_key_auth_mcp.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/_experimental/mcp_server/cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/_experimental/mcp_server/db.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/_experimental/mcp_server/discoverable_endpoints.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/_experimental/mcp_server/mcp_server_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/_experimental/mcp_server/openapi_to_mcp_generator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/_experimental/mcp_server/rest_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/_experimental/mcp_server/server.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/_experimental/mcp_server/sse_transport.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/_experimental/mcp_server/tool_registry.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/_experimental/mcp_server/utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/_logging.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/_types.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/agent_endpoints/a2a_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/agent_endpoints/agent_registry.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/agent_endpoints/auth/agent_permission_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/agent_endpoints/endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/analytics_endpoints/analytics_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/anthropic_endpoints/endpoints.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/anthropic_endpoints/skills_endpoints.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/auth/auth_checks.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/auth/auth_checks_organization.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/auth/auth_exception_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/auth/auth_utils.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/auth/handle_jwt.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/auth/litellm_license.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/auth/login_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/auth/model_checks.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/auth/oauth2_check.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/auth/oauth2_proxy_hook.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/auth/rds_iam_token.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/auth/route_checks.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/auth/user_api_key_auth.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/batches_endpoints/endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/caching_routes.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/chat.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/cli/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/cli/commands/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/cli/commands/auth.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/cli/commands/chat.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/cli/commands/credentials.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/cli/commands/http.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/cli/commands/keys.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/cli/commands/models.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/cli/commands/teams.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/cli/commands/users.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/cli/interface.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/cli/main.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/client.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/credentials.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/health.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/http_client.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/keys.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/model_groups.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/models.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/client/teams.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_request_processing.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/admin_ui_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/banner.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/callback_utils.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/custom_openapi_spec.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/debug_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/encrypt_decrypt_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/get_routes.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/html_forms/cli_sso_success.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/html_forms/jwt_display_template.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/html_forms/ui_login.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/http_parsing_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/key_rotation_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/load_config_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/openai_endpoint_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/openapi_schema_compat.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/performance_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/proxy_state.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/realtime_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/reset_budget_job.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/swagger_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/common_utils/timezone_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/config_management_endpoints/pass_through_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/container_endpoints/endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/credential_endpoints/endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/custom_auth_auto.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/custom_hooks/custom_ui_sso_hook.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/custom_prompt_management.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/custom_sso.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/db/check_migration.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/db/create_views.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/db/db_spend_update_writer.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/db/db_transaction_queue/base_update_queue.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/db/db_transaction_queue/daily_spend_update_queue.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/db/db_transaction_queue/pod_lock_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/db/db_transaction_queue/redis_update_buffer.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/db/db_transaction_queue/spend_log_cleanup.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/db/db_transaction_queue/spend_update_queue.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/db/dynamo_db.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/db/exception_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/db/log_db_metrics.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/db/prisma_client.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/discovery_endpoints/ui_discovery_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/example_config_yaml/custom_auth.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/example_config_yaml/custom_auth_basic.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/example_config_yaml/custom_callbacks.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/example_config_yaml/custom_callbacks1.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/example_config_yaml/custom_guardrail.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/example_config_yaml/custom_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/fine_tuning_endpoints/endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/google_endpoints/endpoints.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_helpers.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/aim/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/aim/aim.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/aporia_ai/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/aporia_ai/aporia_ai.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/azure/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/azure/base.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/azure/prompt_shield.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/azure/text_moderation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/bedrock_guardrails.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/custom_guardrail.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/dynamoai/dynamoai.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/enkryptai/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/enkryptai/enkryptai.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/generic_guardrail_api/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/generic_guardrail_api/generic_guardrail_api.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/grayswan/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/grayswan/grayswan.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/guardrails_ai/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/guardrails_ai/guardrails_ai.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/ibm_guardrails/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/ibm_guardrails/ibm_detector.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/javelin/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/javelin/javelin.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/lakera_ai.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/lakera_ai_v2.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/lasso/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/lasso/lasso.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/litellm_content_filter/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/litellm_content_filter/content_filter.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/model_armor/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/model_armor/model_armor.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/noma/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/noma/noma.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/onyx/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/onyx/onyx.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/openai/__init__.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/openai/base.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/openai/moderations.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/pangea/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/pangea/pangea.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/panw_prisma_airs/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/panw_prisma_airs/panw_prisma_airs.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/pillar/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/pillar/pillar.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/presidio.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/prompt_security/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/prompt_security/prompt_security.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/tool_permission.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/unified_guardrail/__init__.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/unified_guardrail/unified_guardrail.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/zscaler_ai_guard/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_hooks/zscaler_ai_guard/zscaler_ai_guard.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_initializers.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/guardrail_registry.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/guardrails/init_guardrails.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/health_check.py",
        "providers": [
          "litellm",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/health_check_utils/shared_health_check_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/health_endpoints/_health_endpoints.py",
        "providers": [
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/health_endpoints/health_app_factory.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/hooks/azure_content_safety.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/hooks/batch_rate_limiter.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/hooks/batch_redis_get.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/hooks/cache_control_check.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/hooks/dynamic_rate_limiter.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/hooks/dynamic_rate_limiter_v3.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/hooks/key_management_event_hooks.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/hooks/max_budget_limiter.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/hooks/model_max_budget_limiter.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/hooks/parallel_request_limiter.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/hooks/parallel_request_limiter_v3.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/hooks/prompt_injection_detection.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/hooks/proxy_track_cost_callback.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/hooks/rate_limiter_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/hooks/responses_id_security.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/hooks/user_management_event_hooks.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/image_endpoints/endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/lambda.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/litellm_pre_call_utils.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/budget_management_endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/cache_settings_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/callback_management_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/common_daily_activity.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/cost_tracking_settings.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/customer_endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/internal_user_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/key_management_endpoints.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/mcp_management_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/model_access_group_management_endpoints.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/model_management_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/organization_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/router_settings_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/scim/scim_transformations.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/scim/scim_v2.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/sso_helper_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/tag_management_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/team_callback_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/team_endpoints.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/types.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/ui_sso.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_endpoints/user_agent_analytics_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_helpers/audit_logs.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_helpers/object_permission_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_helpers/team_member_permission_checks.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_helpers/user_invitation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/management_helpers/utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/middleware/prometheus_auth_middleware.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/ocr_endpoints/endpoints.py",
        "providers": [
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/openai_files_endpoints/common_utils.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/openai_files_endpoints/files_endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/pass_through_endpoints/common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/pass_through_endpoints/jsonpath_extractor.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/pass_through_endpoints/llm_passthrough_endpoints.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/pass_through_endpoints/llm_provider_handlers/anthropic_passthrough_logging_handler.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/pass_through_endpoints/llm_provider_handlers/assembly_passthrough_logging_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/pass_through_endpoints/llm_provider_handlers/base_passthrough_logging_handler.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/pass_through_endpoints/llm_provider_handlers/cohere_passthrough_logging_handler.py",
        "providers": [
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/pass_through_endpoints/llm_provider_handlers/gemini_passthrough_logging_handler.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/pass_through_endpoints/llm_provider_handlers/openai_passthrough_logging_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/pass_through_endpoints/llm_provider_handlers/vertex_ai_live_passthrough_logging_handler.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/pass_through_endpoints/llm_provider_handlers/vertex_passthrough_logging_handler.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/pass_through_endpoints/pass_through_endpoints.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/pass_through_endpoints/passthrough_endpoint_router.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/pass_through_endpoints/passthrough_guardrails.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/pass_through_endpoints/streaming_handler.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/pass_through_endpoints/success_handler.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/post_call_rules.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/prisma_migration.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/prompts/init_prompts.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/prompts/prompt_endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/prompts/prompt_registry.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/proxy_cli.py",
        "providers": [
          "anthropic",
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/proxy_server.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "langchain",
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/public_endpoints/public_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/rag_endpoints/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/rag_endpoints/endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/rerank_endpoints/endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/response_api_endpoints/endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/response_polling/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/response_polling/background_streaming.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/response_polling/polling_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/route_llm_request.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/search_endpoints/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/search_endpoints/endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/search_endpoints/search_tool_management.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/search_endpoints/search_tool_registry.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/spend_tracking/cloudzero_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/spend_tracking/cold_storage_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/spend_tracking/spend_management_endpoints.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/spend_tracking/spend_tracking_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/types_utils/utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/ui_crud_endpoints/proxy_setting_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/utils.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/vector_store_endpoints/endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/vector_store_endpoints/management_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/vector_store_endpoints/utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/vector_store_files_endpoints/endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/vertex_ai_endpoints/langfuse_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/proxy/video_endpoints/endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/rag/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/rag/ingestion/__init__.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/rag/ingestion/base_ingestion.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/rag/ingestion/bedrock_ingestion.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/rag/ingestion/gemini_ingestion.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/rag/ingestion/openai_ingestion.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/rag/main.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/rag/text_splitters/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/rag/text_splitters/recursive_character_text_splitter.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/rag/utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/realtime_api/main.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/rerank_api/main.py",
        "providers": [
          "cohere",
          "groq",
          "litellm",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/rerank_api/rerank_utils.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/responses/litellm_completion_transformation/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/responses/litellm_completion_transformation/session_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/responses/litellm_completion_transformation/streaming_iterator.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/responses/litellm_completion_transformation/transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/responses/main.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/responses/mcp/litellm_proxy_mcp_handler.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/responses/mcp/mcp_streaming_iterator.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/responses/streaming_iterator.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/responses/utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_strategy/auto_router/auto_router.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_strategy/auto_router/litellm_encoder.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_strategy/base_routing_strategy.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_strategy/budget_limiter.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_strategy/least_busy.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_strategy/lowest_cost.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_strategy/lowest_latency.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_strategy/lowest_tpm_rpm.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_strategy/lowest_tpm_rpm_v2.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_strategy/simple_shuffle.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_strategy/tag_based_routing.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_utils/add_retry_fallback_headers.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_utils/batch_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_utils/client_initalization_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_utils/clientside_credential_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_utils/common_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_utils/cooldown_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_utils/cooldown_callbacks.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_utils/cooldown_handlers.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_utils/fallback_event_handlers.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_utils/get_retry_from_policy.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_utils/handle_error.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_utils/pattern_match_deployments.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_utils/pre_call_checks/prompt_caching_deployment_check.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_utils/pre_call_checks/responses_api_deployment_check.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_utils/prompt_caching_cache.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_utils/router_callbacks/track_deployment_metrics.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/router_utils/search_api_router.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/scheduler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/search/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/search/cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/search/main.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/secret_managers/aws_secret_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/secret_managers/aws_secret_manager_v2.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/secret_managers/base_secret_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/secret_managers/custom_secret_manager_loader.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/secret_managers/cyberark_secret_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/secret_managers/get_azure_ad_token_provider.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/secret_managers/google_kms.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/secret_managers/google_secret_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/secret_managers/hashicorp_secret_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/secret_managers/main.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/secret_managers/secret_manager_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/skills/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/skills/main.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/timeout.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/adapter.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/agents.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/caching.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/completion.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/containers/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/embedding.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/files.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/fine_tuning.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/google_genai/main.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/guardrails.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/images/main.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/integrations/anthropic_cache_control_hook.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/integrations/cloudzero.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/integrations/datadog.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/integrations/datadog_llm_obs.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/integrations/gcs_bucket.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/integrations/langsmith.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/integrations/pagerduty.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/integrations/prometheus.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/integrations/slack_alerting.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/llms/anthropic.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/llms/anthropic_messages/anthropic_request.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/llms/anthropic_messages/anthropic_response.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/llms/anthropic_skills.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/llms/base.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/llms/bedrock.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/llms/cohere.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/llms/custom_http.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/llms/custom_llm.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/llms/databricks.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/llms/gemini.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/llms/mistral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/llms/oci.py",
        "providers": [
          "cohere",
          "gemini"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/llms/ollama.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/llms/openai.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/llms/vertex_ai.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/llms/watsonx.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/management_endpoints/router_settings_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/mcp.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/mcp_server/mcp_server_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/passthrough_endpoints/pass_through_endpoints.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/prompts/init_prompts.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/proxy/cloudzero_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/proxy/guardrails/guardrail_hooks/azure/azure_prompt_shield.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/proxy/guardrails/guardrail_hooks/generic_guardrail_api.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/proxy/guardrails/guardrail_hooks/lakera_ai_v2.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/proxy/guardrails/guardrail_hooks/litellm_content_filter.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/proxy/guardrails/guardrail_hooks/openai/openai_moderation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/proxy/guardrails/guardrail_hooks/panw_prisma_airs.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/proxy/guardrails/guardrail_hooks/presidio.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/proxy/guardrails/guardrail_hooks/tool_permission.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/proxy/management_endpoints/common_daily_activity.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/proxy/management_endpoints/internal_user_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/proxy/management_endpoints/model_management_endpoints.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/proxy/management_endpoints/scim_v2.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/proxy/management_endpoints/team_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/proxy/management_endpoints/ui_sso.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/proxy/public_endpoints/public_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/proxy/ui_sso.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/rag.py",
        "providers": [
          "langchain",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/realtime.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/rerank.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/responses/main.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/router.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/search.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/secret_managers/main.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/services.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/tag_management.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/utils.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/vector_stores.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/videos/main.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/types/videos/utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/utils.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "langchain",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/vector_store_files/main.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/vector_store_files/utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/vector_stores/main.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/vector_stores/utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/vector_stores/vector_store_registry.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/videos/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/videos/main.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/litellm/videos/utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/scripts/test_groq_streaming_issue.py",
        "providers": [
          "groq",
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/test_litellm/proxy/pass_through_endpoints/test_passthrough_guardrails_field_targeting.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/agent_tests/test_a2a.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/audio_tests/test_audio_speech.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/audio_tests/test_whisper.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/basic_proxy_startup_tests/test_basic_proxy_startup.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/batches_tests/conftest.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/batches_tests/test_batch_rate_limits.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/batches_tests/test_batches_logging_unit_tests.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/batches_tests/test_bedrock_files_and_batches.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/batches_tests/test_fine_tuning_api.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/batches_tests/test_hosted_vllm_batches_and_files.py",
        "providers": [
          "litellm",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/batches_tests/test_openai_batches_and_files.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/azure_client_usage_test.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/ban_constant_numbers.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/ban_copy_deepcopy_kwargs.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/bedrock_pricing.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/callback_manager_test.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/check_data_replace_usage.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/check_fastuuid_usage.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/check_spanattributes_value_usage.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/check_unsafe_enterprise_import.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/code_qa_check_tests.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/enforce_llms_folder_style.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/ensure_async_clients_test.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/info_log_check.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/litellm_logging_code_coverage.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/pass_through_code_coverage.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/prevent_key_leaks_in_exceptions.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/recursive_detector.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/router_code_coverage.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/router_enforce_line_length.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/test_aio_http_image_conversion.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/test_ban_set_verbose.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/test_chat_completion_imports.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/test_proxy_types_import.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/test_router_strategy_async.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/code_coverage_tests/user_api_key_auth_code_coverage.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/documentation_tests/test_api_docs.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/documentation_tests/test_circular_imports.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/documentation_tests/test_env_keys.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/documentation_tests/test_exception_types.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/documentation_tests/test_general_setting_keys.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/documentation_tests/test_optional_params.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/documentation_tests/test_readme_providers.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/documentation_tests/test_requests_lib_usage.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/documentation_tests/test_router_settings.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/documentation_tests/test_standard_logging_payload.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/enterprise/conftest.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/enterprise/litellm_enterprise/enterprise_callbacks/test_prometheus_logging_callbacks.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/enterprise/litellm_enterprise/integrations/test_custom_guardrail.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/enterprise/litellm_enterprise/integrations/test_prometheus.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/enterprise/litellm_enterprise/integrations/test_prometheus_unit_tests.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/enterprise/litellm_enterprise/proxy/auth/test_route_checks.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/enterprise/litellm_enterprise/proxy/auth/test_user_api_key_auth.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/enterprise/litellm_enterprise/proxy/guardrails/test_apply_guardrail_endpoint.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/enterprise/litellm_enterprise/proxy/guardrails/test_bedrock_apply_guardrail.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/enterprise/litellm_enterprise/proxy/hooks/test_managed_files.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/enterprise/litellm_enterprise/proxy/management_endpoints/test_internal_user_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/enterprise/litellm_enterprise/proxy/test_audit_logging_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/guardrails_tests/conftest.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/guardrails_tests/test_bedrock_guardrails.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/guardrails_tests/test_custom_guardrail.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/guardrails_tests/test_dynamoai_guardrails.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/guardrails_tests/test_guardrails_config.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/guardrails_tests/test_javelin_guardrails.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/guardrails_tests/test_lakera_v2.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/guardrails_tests/test_lasso_guardrails.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/guardrails_tests/test_presidio_pii.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/guardrails_tests/test_tracing_guardrails.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/guardrails_tests/test_zscaler_ai_guard.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/image_gen_tests/base_image_generation_test.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/image_gen_tests/conftest.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/image_gen_tests/test_bedrock_image_gen_unit_tests.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/image_gen_tests/test_fal_ai_image_generation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/image_gen_tests/test_image_edits.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/image_gen_tests/test_image_generation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/image_gen_tests/test_image_variation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/image_gen_tests/test_xinference.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm-proxy-extras/test_litellm_proxy_extras_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm/llms/bedrock/embed/test_embedding.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm/llms/gradient_ai/chat/test_gradient_ai_chat_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm/llms/oci/chat/test_oci_chat_transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm/llms/vertex_ai/gemini/test_transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm/llms/vertex_ai/text_to_speech/test_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm_utils_tests/conftest.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm_utils_tests/test_aiohttp_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm_utils_tests/test_aws_secret_manager.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm_utils_tests/test_cyberark.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm_utils_tests/test_get_secret.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm_utils_tests/test_hashicorp.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm_utils_tests/test_health_check.py",
        "providers": [
          "anthropic",
          "cohere",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm_utils_tests/test_litellm_overhead.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm_utils_tests/test_logging_callback_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm_utils_tests/test_proxy_budget_reset.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm_utils_tests/test_secret_manager.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm_utils_tests/test_utils.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/litellm_utils_tests/test_validate_tool_choice.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_responses_api_testing/base_responses_api.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_responses_api_testing/conftest.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_responses_api_testing/test_anthropic_responses_api.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_responses_api_testing/test_azure_responses_api.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_responses_api_testing/test_base_responses_api_streaming_iterator.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_responses_api_testing/test_google_ai_studio_responses_api.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_responses_api_testing/test_openai_responses_api.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/base_audio_transcription_unit_tests.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/base_embedding_unit_tests.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/base_llm_unit_tests.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/base_rerank_unit_tests.py",
        "providers": [
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/conftest.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_aiohttp_openai.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_anthropic_completion.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_aws_base_llm.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_azure_ai.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_azure_o_series.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_azure_openai.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_bedrock_agentcore.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_bedrock_agents.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_bedrock_completion.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_bedrock_dynamic_auth_params_unit_tests.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_bedrock_embedding.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_bedrock_govcloud.py",
        "providers": [
          "anthropic",
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_bedrock_gpt_oss.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_bedrock_invoke_tests.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_bedrock_llama.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_bedrock_nova_embedding.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_bedrock_nova_json.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_clarifai_completion.py",
        "providers": [
          "anthropic",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_cloudflare.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_cohere.py",
        "providers": [
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_convert_dict_to_image.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_databricks.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_deepgram.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_deepseek_completion.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_elevenlabs.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_fireworks_ai_translation.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_gemini.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_gpt4o_audio.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_groq.py",
        "providers": [
          "groq",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_huggingface_chat_completion.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_hyperbolic.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_infinity.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_jina_ai.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_lambda_ai.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_litellm_proxy_provider.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_llm_response_utils/test_convert_dict_to_chat_completion.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_llm_response_utils/test_get_headers.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_mistral_api.py",
        "providers": [
          "anthropic",
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_morph.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_nvidia_nim.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_openai.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_openai_o1.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_openai_realtime.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_openrouter.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_optional_params.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_perplexity_reasoning.py",
        "providers": [
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_prompt_caching.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_prompt_factory.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_rerank.py",
        "providers": [
          "cohere",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_router_llm_translation_tests.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_sambanova_chat_transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_skills_api.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_snowflake.py",
        "providers": [
          "anthropic",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_text_completion.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_text_completion_unit_tests.py",
        "providers": [
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_together_ai.py",
        "providers": [
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_triton.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_unit_test_bedrock_invoke.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_v0.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_voyage_ai.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_watsonx.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/llm_translation/test_xai.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/load_tests/test_datadog_load_test.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/load_tests/test_langsmith_load_test.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/load_tests/test_memory_usage.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/load_tests/test_otel_load_test.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/load_tests/test_vertex_embeddings_load_test.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/load_tests/test_vertex_load_tests.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/cache_unit_tests.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/conftest.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/create_mock_standard_logging_payload.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/stream_chunk_testdata.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_acompletion.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_acompletion_fallbacks.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_acooldowns_router.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_add_function_to_prompt.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_add_update_models.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_aim_guardrails.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_alangfuse.py",
        "providers": [
          "anthropic",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_amazing_vertex_completion.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_anthropic_prompt_caching.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_arize_ai.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_arize_phoenix.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_assistants.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_async_fn.py",
        "providers": [
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_auth_utils.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_azure_content_safety.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_azure_openai.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_azure_perf.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_basic_python_version.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_batch_completion_return_exceptions.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_batch_completions.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_blocked_user_list.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_braintrust.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_budget_manager.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_caching.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_caching_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_caching_ssl.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_class.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_completion.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_completion_cost.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_completion_with_retries.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_config.py",
        "providers": [
          "litellm",
          "llama",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_configs/custom_auth.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_configs/custom_callbacks.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_cost_calc.py",
        "providers": [
          "anthropic",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_custom_api_logger.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_custom_callback_input.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_custom_llm.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_custom_logger.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_disk_cache_unit_tests.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_dual_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_dynamic_rate_limit_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_dynamodb_logs.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_embedding.py",
        "providers": [
          "cohere",
          "gemini",
          "litellm",
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_exceptions.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_file_types.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_function_call_parsing.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_function_calling.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_function_setup.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_gcs_bucket.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_gcs_cache_unit_tests.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_gemini_reasoning_content.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_get_llm_provider.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_get_model_file.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_get_model_info.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_get_optional_params_embeddings.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_get_optional_params_functions_not_supported.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_google_ai_studio_gemini.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_guardrails_ai.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_helicone_integration.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_http_parsing_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_img_resize.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_lakera_ai_prompt_injection.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_langchain_ChatLiteLLM.py",
        "providers": [
          "anthropic",
          "langchain",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_langsmith.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_least_busy_routing.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_litellm_max_budget.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_literalai.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_llm_guard.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_load_test_router_s3.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_loadtest_router.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_logfire.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_logging.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_longer_context_fallback.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_lowest_cost_routing.py",
        "providers": [
          "groq",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_lowest_latency_routing.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_lunary.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_max_tpm_rpm_limiter.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_mem_leak.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_mem_usage.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_mock_request.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_model_alias_map.py",
        "providers": [
          "groq",
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_model_max_token_adjust.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_model_response_typing/server.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_model_response_typing/test.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_multiple_deployments.py",
        "providers": [
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_ollama.py",
        "providers": [
          "litellm",
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_ollama_local.py",
        "providers": [
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_ollama_local_chat.py",
        "providers": [
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_openai_moderations_hook.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_opik.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_pass_through_endpoints.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_profiling_router.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_prometheus_service.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_prompt_caching.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_prompt_injection_detection.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_promptlayer_integration.py",
        "providers": [
          "anthropic",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_provider_specific_config.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_pydantic.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_pydantic_namespaces.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_redis_batch_optimizations.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_register_model.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_auto_router.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_batch_completion.py",
        "providers": [
          "groq",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_budget_limiter.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_caching.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_client_init.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_cooldown_handlers.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_custom_routing.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_debug_logs.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_fallback_handlers.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_fallbacks.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_get_deployments.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_init.py",
        "providers": [
          "cohere",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_max_parallel_requests.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_pattern_matching.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_retries.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_timeout.py",
        "providers": [
          "anthropic",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_utils.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_router_with_fallbacks.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_rules.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_sagemaker.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_scheduler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_secret_detect_hook.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_simple_shuffle.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_spend_calculate_endpoint.py",
        "providers": [
          "groq",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_stream_chunk_builder.py",
        "providers": [
          "groq",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_streaming.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_supabase_integration.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_team_config.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_text_completion.py",
        "providers": [
          "gemini",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_timeout.py",
        "providers": [
          "anthropic",
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_together_ai.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_tpm_rpm_routing_v2.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_traceloop.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_ui_sso_helper_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_unit_test_caching.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_update_spend.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_validate_environment.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/local_testing/test_wandb.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/base_test.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/conftest.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/create_mock_standard_logging_payload.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_alerting.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_amazing_s3_logs.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_assemble_streaming_responses.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_azure_blob_storage.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_bedrock_knowledgebase_hook.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_built_in_tools_cost_tracking.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_custom_callback_router.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_datadog.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_datadog_llm_obs.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_gcs_pub_sub.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_generic_api_callback.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_humanloop_unit_tests.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_langfuse_e2e_test.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_langfuse_unit_tests.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_langsmith_unit_test.py",
        "providers": [
          "langchain",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_log_db_redis_services.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_logging_redaction_e2e_test.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_moderations_api_logging.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_opentelemetry_unit_tests.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_otel_logging.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_pagerduty_alerting.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_posthog.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_spend_logs.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_sqs_logger.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_standard_logging_payload.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_token_counting.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_unit_test_litellm_logging.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_unit_tests_init_callbacks.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/logging_callback_tests/test_view_request_resp_logs.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/mcp_tests/conftest.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/mcp_tests/test_aresponses_api_with_mcp.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/mcp_tests/test_mcp_auth_header_extraction.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/mcp_tests/test_mcp_auth_priority.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/mcp_tests/test_mcp_client_unit.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/mcp_tests/test_mcp_guardrails.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/mcp_tests/test_mcp_hooks.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/mcp_tests/test_mcp_litellm_client.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/mcp_tests/test_mcp_logging.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/mcp_tests/test_mcp_server.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/multi_instance_e2e_tests/test_update_team_e2e.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/ocr_tests/base_ocr_unit_tests.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/ocr_tests/test_ocr_azure_ai.py",
        "providers": [
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/ocr_tests/test_ocr_azure_document_intelligence.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/ocr_tests/test_ocr_mistral.py",
        "providers": [
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/ocr_tests/test_ocr_vertex_ai.py",
        "providers": [
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/bursty_load_test_completion.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/load_test_completion.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/load_test_embedding.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/load_test_embedding_100.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/load_test_embedding_proxy.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/load_test_q.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_anthropic_context_caching.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_anthropic_sdk.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_async.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_gemini_context_caching.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_langchain_embedding.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_langchain_request.py",
        "providers": [
          "anthropic",
          "langchain",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_llamaindex.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_mistral_sdk.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_openai_embedding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_openai_exception_request.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_openai_request.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_openai_request_with_traceparent.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_openai_simple_embedding.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_openai_tts_request.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_pass_through_langfuse.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_q.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_simple_traceparent_openai.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_vertex_sdk_forward_headers.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_vtx_embedding.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/old_proxy_tests/tests/test_vtx_sdk_embedding.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/openai_endpoints_tests/test_bedrock_batches_api.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/openai_endpoints_tests/test_e2e_openai_responses_api.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/openai_endpoints_tests/test_openai_batches_endpoint.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/openai_endpoints_tests/test_openai_files_endpoints.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/openai_endpoints_tests/test_openai_fine_tuning.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/otel_tests/test_e2e_budgeting.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/otel_tests/test_e2e_model_access.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/otel_tests/test_guardrails.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/otel_tests/test_moderations.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/otel_tests/test_otel.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/otel_tests/test_prometheus.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/otel_tests/test_rerank.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/otel_tests/test_team_member_permissions.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/otel_tests/test_team_tag_routing.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_tests/base_anthropic_messages_test.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_tests/test_anthropic_passthrough.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_tests/test_anthropic_passthrough_basic.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_tests/test_hosted_vllm_passthrough.py",
        "providers": [
          "litellm",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_tests/test_mcp_routes.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_tests/test_openai_assistants_passthrough.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_tests/test_vertex_ai.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_unit_tests/base_anthropic_unified_messages_test.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_unit_tests/test_anthropic_messages_passthrough.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_unit_tests/test_assemblyai_unit_tests_passthrough.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_unit_tests/test_bedrock_anthropic_messages_test.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_unit_tests/test_custom_logger_passthrough.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_unit_tests/test_pass_through_unit_tests.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_unit_tests/test_unit_test_anthropic_pass_through.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_unit_tests/test_unit_test_passthrough_router.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_unit_tests/test_unit_test_streaming.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_unit_tests/test_vertex_ai_anthropic_streaming_cost_injection.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/pass_through_unit_tests/test_vertex_ai_live_passthrough.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_admin_ui_tests/conftest.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_admin_ui_tests/test_key_management.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_admin_ui_tests/test_role_based_access.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_admin_ui_tests/test_route_check_unit_tests.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_admin_ui_tests/test_sso_sign_in.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_admin_ui_tests/test_usage_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_security_tests/test_master_key_not_in_db.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/conftest copy.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/conftest.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_aproxy_startup.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_audit_logs_proxy.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_auth_checks.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_banned_keyword_list.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_configs/custom_auth.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_configs/custom_callbacks.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_custom_callback_input.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_custom_logger_s3_gcs.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_custom_tokenizer_bug.py",
        "providers": [
          "groq",
          "litellm",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_db_schema_migration.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_default_end_user_budget_simple.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_deployed_proxy_keygen.py",
        "providers": [
          "anthropic",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_e2e_pod_lock_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_google_gemini_proxy_request.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_jwt.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_key_generate_prisma.py",
        "providers": [
          "gemini",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_model_response_typing/server.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_model_response_typing/test.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_models_fallback_endpoint.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_prisma_client_backoff_retry.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_prompt_test_endpoint.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_proxy_config_unit_test.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_proxy_custom_auth.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_proxy_custom_logger.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_proxy_encrypt_decrypt.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_proxy_exception_mapping.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_proxy_gunicorn.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_proxy_pass_user_config.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_proxy_reject_logging.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_proxy_routes.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_proxy_server.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "langchain",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_proxy_server_caching.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_proxy_server_keys.py",
        "providers": [
          "anthropic",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_proxy_server_langfuse.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_proxy_server_spend.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_proxy_setting_guardrails.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_proxy_token_counter.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_proxy_utils.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_realtime_cache.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_response_polling_handler.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_search_api_logging.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_unit_test_max_model_budget_limiter.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_unit_test_proxy_hooks.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_update_spend.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/proxy_unit_tests/test_user_api_key_auth.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/router_unit_tests/conftest.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/router_unit_tests/create_mock_standard_logging_payload.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/router_unit_tests/test_completion_no_copy.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/router_unit_tests/test_default_deployment_copy.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/router_unit_tests/test_pre_call_checks_optimization.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/router_unit_tests/test_prompt_management_check.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/router_unit_tests/test_router_adding_deployments.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/router_unit_tests/test_router_batch_utils.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/router_unit_tests/test_router_cooldown_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/router_unit_tests/test_router_endpoints.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/router_unit_tests/test_router_handle_error.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/router_unit_tests/test_router_helper_utils.py",
        "providers": [
          "anthropic",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/router_unit_tests/test_router_index_management.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/router_unit_tests/test_router_prompt_caching.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/search_tests/base_search_unit_tests.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/search_tests/test_dataforseo_search.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/search_tests/test_exa_ai_search.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/search_tests/test_firecrawl_search.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/search_tests/test_parallel_ai_search.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/search_tests/test_perplexity_search.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/search_tests/test_search_tool_name_filtering.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/search_tests/test_searxng_search.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/search_tests/test_tavily_search.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/spend_tracking_tests/test_ocr_spend_tracking.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/spend_tracking_tests/test_spend_accuracy_tests.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/store_model_in_db_tests/test_adding_passthrough_model.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/store_model_in_db_tests/test_callbacks_in_db.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/store_model_in_db_tests/test_mcp_servers.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/store_model_in_db_tests/test_openai_error_handling.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/store_model_in_db_tests/test_team_models.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_budget_management.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_callbacks_on_proxy.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_config.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_end_users.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_entrypoint.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_fallbacks.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_gpt5_azure_temperature_support.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_health.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_keys.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/caching/test_azure_blob_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/caching/test_caching_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/caching/test_gcs_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/caching/test_in_memory_cache.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/caching/test_qdrant_semantic_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/caching/test_redis_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/caching/test_redis_cluster_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/caching/test_redis_semantic_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/caching/test_s3_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/completion_extras/litellm_responses_transformation/test_completion_extras_litellm_responses_transformation_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/completion_extras/test_litellm_responses_transformation_transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/conftest.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/containers/test_container_api.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/containers/test_container_integration.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/containers/test_container_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/containers/test_container_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/enterprise/enterprise_callbacks/send_emails/test_base_email.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/enterprise/enterprise_callbacks/send_emails/test_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/enterprise/enterprise_callbacks/send_emails/test_resend_email.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/enterprise/enterprise_callbacks/test_callback_controls.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/enterprise/proxy/test_enterprise_routes.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/experimental_mcp_client/test_mcp_client.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/experimental_mcp_client/test_tools.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/google_genai/test_google_genai_adapter.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/google_genai/test_google_genai_adapter_fixes.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/google_genai/test_google_genai_handler.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/google_genai/test_google_genai_main.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/SlackAlerting/test_budget_alert_types.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/SlackAlerting/test_hanging_request_check.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/SlackAlerting/test_slack_alerting.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/SlackAlerting/test_slack_alerting_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/arize/test_arize.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/arize/test_arize_health_check.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/arize/test_arize_phoenix.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/arize/test_arize_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/bitbucket/test_bitbucket_integration.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/bitbucket/test_bitbucket_prompt_manager.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/cloudzero/test_cloudzero.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/cloudzero/test_cz_stream_api.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/cloudzero/test_dry_run_endpoint.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/cloudzero/test_transform.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/datadog/test_datadog_llm_observability.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/dotprompt/test_prompt_manager.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/gcs_bucket/test_gcs_bucket_base.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/gcs_pubsub/test_pub_sub.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/gitlab/test_gitlab_client.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/gitlab/test_gitlab_integration.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/gitlab/test_gitlab_prompt_manager.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/langfuse/test_langfuse_prompt_management.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_agentops.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_anthropic_cache_control_hook.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_athina.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_braintrust_logging.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_braintrust_span_name.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_custom_guardrail.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_custom_prompt_management.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_deepeval.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_langfuse.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_langfuse_otel.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_langsmith_init.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_mlflow.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_openmeter.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_opentelemetry.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_prometheus_labels.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_prometheus_services.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_s3_v2.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/integrations/test_weave_otel.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/llm_cost_calc/test_azure_assistant_cost_tracking.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/llm_cost_calc/test_llm_cost_calc_utils.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/llm_cost_calc/test_tool_call_cost_tracking.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/prompt_templates/test_litellm_core_utils_prompt_templates_common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/prompt_templates/test_litellm_core_utils_prompt_templates_factory.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/specialty_caches/test_dynamic_logging_cache.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_audio_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_cli_token_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_core_helpers.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_coroutine_checker.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_dd_tracing.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_duration_parser.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_exception_mapping_utils.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_health_check_helpers.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_image_handling.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_litellm_logging.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_logging_worker.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_model_response_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_provider_specific_headers.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_realtime_streaming.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_retry_after_headers.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_safe_divide_seconds.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_safe_json_dumps.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_sensitive_data_masker.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_streaming_chunk_builder_utils.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_streaming_handler.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_token_counter.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/litellm_core_utils/test_token_counter_tool.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/amazon_nova/chat/test_amazon_nova_chat_completion.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/anthropic/chat/test_anthropic_chat_handler.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/anthropic/chat/test_anthropic_chat_transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/anthropic/experimental_pass_through/adapters/test_anthropic_experimental_pass_through_adapters_transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/anthropic/experimental_pass_through/messages/test_anthropic_experimental_pass_through_messages_handler.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/anthropic/experimental_pass_through/messages/test_content_after_stop_reason.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/anthropic/experimental_pass_through/messages/test_parallel_tool_calls.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/anthropic/experimental_pass_through/messages/test_sse_wrapper.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/azure/chat/test_azure_chat_gpt_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/azure/chat/test_azure_chat_o_series_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/azure/chat/test_azure_gpt5_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/azure/image_generation/test_azure_image_generation_init.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/azure/realtime/test_azure_realtime_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/azure/response/test_azure_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/azure/test_azure_common_utils.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/azure/test_azure_exception_mapping.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/azure/text_to_speech/test_azure_tts_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/azure/videos/test_azure_video_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/azure_ai/chat/test_azure_ai_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/azure_ai/claude/test_azure_anthropic_handler.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/azure_ai/claude/test_azure_anthropic_messages_transformation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/azure_ai/claude/test_azure_anthropic_provider_routing.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/azure_ai/claude/test_azure_anthropic_transformation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/azure_ai/image_edit/test_azure_ai_image_edit_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/baseten/chat/test_baseten_completions.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/chat/invoke_transformations/test_amazon_qwen2_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/chat/invoke_transformations/test_amazon_qwen3_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/chat/invoke_transformations/test_bedrock_chat_invoke_transformations_anthropic_claude3_transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/chat/invoke_transformations/test_twelvelabs_pegasus_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/chat/test_converse_transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/chat/test_converse_transformation_nova_2.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/chat/test_invoke_handler.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/chat/test_mistral_config.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/count_tokens/test_bedrock_count_tokens_transformation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/embed/test_bedrock_async_invoke_embedding.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/embed/test_bedrock_embedding.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/files/test_bedrock_files_integration.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/files/test_bedrock_files_transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/image/test_amazon_nova_canvas_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/image/test_amazon_stability3_transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/image/test_bedrock_image_bearer_token.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/image/test_bedrock_image_prepare_request.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/invoke_agent/test_bedrock_agent_transformation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/messages/invoke_transformations/test_anthropic_claude3_transformation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/passthrough/test_bedrock_passthrough_transformation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/rerank/transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/test_anthropic_beta_support.py",
        "providers": [
          "anthropic",
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/test_base_aws_llm.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/test_bedrock_common_utils.py",
        "providers": [
          "anthropic",
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/test_cross_region_inference_profile_mapping.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bedrock/vector_stores/test_bedrock_vector_store_transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/bytez/chat/test_bytez_chat_transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/chat/test_converse_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/cohere/chat/test_cohere_transformation.py",
        "providers": [
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/cohere/embed/test_v1_transformation.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/cohere/rerank/test_rerank_guardrail_handler.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/cometapi/chat/test_cometapi_chat_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/compactifai/test_compactifai.py",
        "providers": [
          "litellm",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/custom_httpx/test_aiohttp_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/custom_httpx/test_aiohttp_transport.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/custom_httpx/test_http_handler.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/custom_httpx/test_llm_http_handler.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/dashscope/test_dashscope_chat_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/dashscope/test_dashscope_cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/databricks/chat/test_databricks_chat_transformation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/databricks/test_databricks_common_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/databricks/test_databricks_pricing.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/datarobot/chat/test_datarobot_chat_transformation.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/datarobot/test_datarobot.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/deepgram/audio_transcription/test_deepgram_audio_transcription_transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/deepgram/test_deepgram_mock_transcription.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/deepinfra/test_deepinfra_chat_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/deepinfra/test_deepinfra_rerank.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/deepinfra/test_deepinfra_rerank_integration.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/deepinfra/test_deepinfra_rerank_transformation.py",
        "providers": [
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/docker_model_runner/test_docker_model_runner_chat_transformation.py",
        "providers": [
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/featherless_ai/chat/test_featherless_chat_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/fireworks_ai/chat/test_fireworks_ai_chat_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/fireworks_ai/rerank/test_fireworks_ai_rerank_transformation.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/gemini/image_edit/test_gemini_image_edit_transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/gemini/realtime/test_gemini_realtime_transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/gemini/test_gemini_client_setup.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/gemini/test_gemini_common_utils.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/gemini/test_gemini_tts.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/gemini/videos/__init__.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/gemini/videos/test_gemini_video_transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/github_copilot/embedding/test_github_copilot_embedding_transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/github_copilot/responses/test_github_copilot_responses_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/github_copilot/test_github_copilot_authenticator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/github_copilot/test_github_copilot_transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/heroku/test_heroku_chat_transformation.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/hosted_vllm/chat/test_hosted_vllm_chat_transformation.py",
        "providers": [
          "litellm",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/hosted_vllm/test_hosted_vllm_rerank_transformation.py",
        "providers": [
          "cohere",
          "litellm",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/huggingface/embedding/test_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/huggingface/rerank/test_huggingface_rerank_transformation.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/jina_ai/embedding/test_jina_embedding_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/lemonade/test_lemonade.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/litellm_proxy/chat/test_litellm_proxy_chat_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/llamafile/chat/test_llamafile_chat_transformation.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/lm_studio/test_lm_studio_chat_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/meta_llama/test_meta_llama_chat_transformation.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/mistral/test_mistral_chat_transformation.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/mistral/test_mistral_completion.py",
        "providers": [
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/moonshot/test_moonshot_chat_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/nebius/test_nebius_chat_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/nebius/test_nebius_embedding_transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/novita/chat/test_novita_chat_transformation.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/nscale/chat/test_nscale_chat_transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/oci/chat/test_oci_chat_transformation.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/oci/chat/test_oci_chat_transformation_for_14158.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/oci/chat/test_oci_cohere_tool_calls.py",
        "providers": [
          "cohere",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/oci/chat/test_oci_streaming_tool_calls.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/ollama/test_ollama_chat_transformation.py",
        "providers": [
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/ollama/test_ollama_completion_transformation.py",
        "providers": [
          "litellm",
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/ollama/test_ollama_embedding.py",
        "providers": [
          "litellm",
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/ollama/test_ollama_model_info.py",
        "providers": [
          "litellm",
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openai/chat/guardrail_translation/test_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openai/completion/test_text_completion_guardrail_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openai/image_generation/test_image_generation_guardrail_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openai/realtime/test_openai_realtime_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openai/responses/test_openai_responses_guardrail_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openai/responses/test_openai_responses_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openai/speech/test_text_to_speech_guardrail_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openai/test_gpt5_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openai/test_o_series_transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openai/test_openai_common_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openai/test_openai_empty_response.py",
        "providers": [
          "litellm",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openai/test_openai_image_edit_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openai/transcriptions/test_audio_transcription_guardrail_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openai/vector_store_files/test_openai_vector_store_files_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openai/vector_stores/test_openai_vector_stores_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openai_like/chat/test_openai_like_chat_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openai_like/test_json_providers.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/openrouter/chat/test_openrouter_chat_transformation.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/ovhcloud/test_ovhcloud_audio_transcription_transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/ovhcloud/test_ovhcloud_chat_transformation.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/ovhcloud/test_ovhcloud_embeddings_transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/perplexity/chat/test_perplexity_chat_transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/perplexity/test_perplexity.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/perplexity/test_perplexity_cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/perplexity/test_perplexity_integration.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/pg_vector/vector_stores/test_pg_vector_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/publicai/test_publicai_chat_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/ragflow/chat/test_ragflow_chat_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/recraft/image_edit/test_recraft_image_edit_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/recraft/image_generation/test_recraft_image_gen_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/runwayml/test_text_to_speech_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/runwayml/videos/test_runway_video_transformation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/sagemaker/test_sagemaker_common_utils.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/sagemaker/test_sagemaker_embedding_voyage.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/sambanova/tests_sambanova_embedding_transformation.py",
        "providers": [
          "litellm",
          "mistral"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/snowflake/chat/test_snowflake_chat_transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/snowflake/embedding/test_snowflake_embedding.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vercel_ai_gateway/chat/test_vercel_ai_gateway_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vercel_ai_gateway/test_vercel_ai_gateway.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/context_caching/test_context_caching_ttl.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/context_caching/test_vertex_ai_context_caching.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/files/test_vertex_ai_files_handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/files/test_vertex_ai_files_integration.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/gemini/test_thought_signature_in_tool_call_id.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/gemini/test_vertex_ai_gemini_transformation.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/gemini/test_vertex_and_google_ai_studio_gemini.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/image_edit/test_vertex_ai_image_edit_transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/image_generation/test_vertex_ai_image_generation_transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/multimodal_embeddings/test_vertex_ai_multimodal_embedding_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/rerank/test_vertex_ai_rerank_integration.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/rerank/test_vertex_ai_rerank_transformation.py",
        "providers": [
          "cohere",
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/test_bge_embedding.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/test_bge_response_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/test_gemini_header_forwarding.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/test_http_status_201.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/test_vertex.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/test_vertex_ai_common_utils.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/test_vertex_ai_psc_endpoint_support.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/test_vertex_image_generation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/test_vertex_llm_base.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/vertex_ai_partner_models/anthropic/test_vertex_ai_partner_models_anthropic_messages_config.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/vertex_ai_partner_models/anthropic/test_vertex_ai_partner_models_anthropic_transformation.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/vertex_ai_partner_models/gpt_oss/test_vertex_ai_gpt_oss_transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/vertex_ai_partner_models/llama3/test_vertex_ai_partner_models_llama3_transformation.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/vertex_gemma_models/test_vertex_gemma_transformation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/vertex_ai/videos/test_vertex_video_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/volcengine/test_volcengine.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/volcengine/test_volcengine_embedding.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/wandb/test_wandb_chat_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/watsonx/audio_transcription/test_watsonx_audio_transcription_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/watsonx/test_watsonx.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/xai/responses/test_xai_responses_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/xai/test_xai_cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/xai/xai_responses/test_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/llms/zai/test_zai_provider.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/passthrough/test_passthrough_main.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/_experimental/mcp_server/auth/test_user_api_key_auth_mcp.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/_experimental/mcp_server/test_discoverable_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/_experimental/mcp_server/test_mcp_cost_calculator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/_experimental/mcp_server/test_mcp_custom_fields.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/_experimental/mcp_server/test_mcp_metadata_preservation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/_experimental/mcp_server/test_mcp_server.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/_experimental/mcp_server/test_mcp_server_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/agent_endpoints/auth/test_agent_permission_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/agent_endpoints/test_a2a_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/anthropic_endpoints/test_endpoints.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/auth/test_auth_checks.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/auth/test_auth_exception_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/auth/test_handle_jwt.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/auth/test_litellm_license.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/auth/test_login_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/auth/test_model_checks.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/auth/test_model_checks_fallbacks.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/auth/test_organization_budget_enforcement.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/auth/test_route_checks.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/auth/test_user_api_key_auth.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "litellm",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/client/cli/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/client/cli/test_auth_commands.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/client/cli/test_credentials_commands.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/client/cli/test_global_options.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/client/cli/test_keys_commands.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/client/cli/test_models_commands.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/client/cli/test_users_commands.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/client/test_chat.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/client/test_client.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/client/test_credentials.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/client/test_http_client.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/client/test_http_commands.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/client/test_keys.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/client/test_model_groups.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/client/test_models.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/client/test_users.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/common_utils/test_callback_utils.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/common_utils/test_custom_openapi_spec.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/common_utils/test_get_routes.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/common_utils/test_http_parsing_utils.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/common_utils/test_key_rotation_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/common_utils/test_load_config_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/common_utils/test_openai_endpoint_utils.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/common_utils/test_reset_budget_job.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/common_utils/test_timezone_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/common_utils/test_upsert_budget_membership.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/db/db_transaction_queue/test_base_update_queue.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/db/db_transaction_queue/test_daily_spend_update_queue.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/db/db_transaction_queue/test_pod_lock_manager.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/db/db_transaction_queue/test_spend_update_queue.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/db/mcp_server/test_db.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/db/test_check_migration.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/db/test_db_spend_update_writer.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/db/test_exception_handler.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/db/test_prisma_client.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/discovery_endpoints/test_ui_discovery_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/experimental/mcp_server/test_tool_registry.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/google_endpoints/test_endpoints.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/google_endpoints/test_google_api_endpoints.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/azure/test_azure_prompt_shield.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/azure/test_azure_text_moderation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/content_filter/test_content_filter.py",
        "providers": [
          "langchain",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/content_filter/test_patterns.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/guardrails_ai/test_guardrails_ai.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/openai/test_moderations.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/test_bedrock_guardrails.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/test_enkryptai.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/test_generic_guardrail_api.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/test_grayswan.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/test_lasso.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/test_model_armor.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/test_noma.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/test_onyx.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/test_pangea.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/test_panw_prisma_airs.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/test_presidio.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/guardrail_hooks/test_tool_permission.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/test_guardrail_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/test_guardrail_registry.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/test_init_guardrails.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/test_pillar_guardrails.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/guardrails/test_prompt_security_guardrails.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/health_endpoints/test_health_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/hooks/test_async_post_call_streaming_iterator_hook.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/hooks/test_dynamic_rate_limiter_v3.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/hooks/test_key_management_event_hooks.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/hooks/test_parallel_request_limiter_v3.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/hooks/test_prompt_injection_detection.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/hooks/test_proxy_track_cost_callback.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/image_endpoints/test_azure_routes.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/image_endpoints/test_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/scim/test_scim_patch_user.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/scim/test_scim_transformations.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/scim/test_scim_v2_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_access_group_management.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_budget_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_cache_settings_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_callback_management_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_common_daily_activity.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_cost_tracking_settings.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_customer_budget.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_customer_endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_delete_callbacks_endpoint.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_entraid_app_roles.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_internal_user_endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_key_management_endpoints.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_mcp_management_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_model_management_endpoints.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_organization_endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_tag_management_endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_team_endpoints.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_endpoints/test_ui_sso.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_helpers/test_management_helpers_utils.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/management_helpers/test_object_permission_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/middleware/test_prometheus_auth_middleware.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/openai_files_endpoint/test_files_endpoint.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/pass_through_endpoints/llm_provider_handlers/test_anthropic_passthrough_logging_handler.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/pass_through_endpoints/llm_provider_handlers/test_cohere_passthrough_logging_handler.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/pass_through_endpoints/llm_provider_handlers/test_gemini_passthrough_logging_handler.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/pass_through_endpoints/llm_provider_handlers/test_openai_passthrough_logging_handler.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/pass_through_endpoints/test_llm_pass_through_endpoints.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/pass_through_endpoints/test_pass_through_endpoints.py",
        "providers": [
          "anthropic",
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/pass_through_endpoints/test_passthrough_endpoints_common_utils.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/pass_through_endpoints/test_passthrough_guardrails.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/pass_through_endpoints/test_vertex_ai_batch_passthrough.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/prompts/test_prompt_endpoints.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/public_endpoints/test_public_endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/response_api_endpoints/test_endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/spend_tracking/test_spend_management_endpoints.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/spend_tracking/test_spend_query_optimization.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/spend_tracking/test_spend_tracking_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_batch_metadata_none_fix.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_caching_routes.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_common_request_processing.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_custom_proxy.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_enforce_user_param.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_fastapi_offline_routes.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_health_check_functions.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_litellm_pre_call_utils.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_model_id_header_propagation.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_proxy_cli.py",
        "providers": [
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_proxy_server.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_proxy_types.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_proxy_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_route_llm_request.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_shared_health_check.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_spend_log_cleanup.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_swagger_chat_completions.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/test_team_member_update.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/ui_crud_endpoints/test_proxy_setting_endpoints.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/proxy/vector_store_endpoints/test_vector_store_endpoints.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/responses/litellm_completion_transformation/test_image_generation_output.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/responses/litellm_completion_transformation/test_litellm_completion_responses.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/responses/litellm_completion_transformation/test_reasoning_content_transformation.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/responses/litellm_completion_transformation/test_session_handler.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/responses/litellm_completion_transformation/test_session_handler_with_cold_storage.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/responses/test_no_duplicate_spend_logs.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/responses/test_responses_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/responses/test_text_format_conversion.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/router_strategy/test_auto_router.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/router_strategy/test_base_routing_strategy.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/router_strategy/test_router_tag_routing.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/router_utils/pre_call_checks/test_responses_api_deployment_check.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/router_utils/test_cooldown_cache.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/router_utils/test_router_utils_common_utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/secret_managers/test_custom_secret_manager.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/secret_managers/test_get_azure_ad_token_provider.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/secret_managers/test_secret_managers_main.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_acompletion_session_reuse_e2e.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_add_deployment_no_master_key.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_aembedding_session_reuse_e2e.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_azure_video_router.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_claude_haiku_4_5_config.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_constants.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_container_router.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_cost_calculation_log_level.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_cost_calculator.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_exception_mapping_request_attribute.py",
        "providers": [
          "cohere",
          "litellm",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_filter_out_litellm_params.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_groq_streaming_encoding.py",
        "providers": [
          "groq",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_logging.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_lowest_latency_zero_tokens.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_main.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_redis.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_responses_id_security.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_router.py",
        "providers": [
          "anthropic",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_router_google_genai.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_shared_session_integration.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_system_message_format_bug.py",
        "providers": [
          "anthropic",
          "litellm",
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_utils.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_uuid_helper.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/test_video_generation.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/types/llms/test_types_llms_openai.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/types/test_completion.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/types/test_types_utils.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/vector_stores/test_vector_store_create_provider_logic.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm/vector_stores/test_vector_store_registry.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_litellm_proxy_responses_config.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_models.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_openai_endpoints.py",
        "providers": [
          "anthropic",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_organizations.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_passthrough_endpoints.py",
        "providers": [
          "cohere",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_ratelimit.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_resource_cleanup.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_spend_logs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_team.py",
        "providers": [
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_team_logging.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_team_members.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/test_users.py",
        "providers": [
          "anthropic",
          "groq",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/unified_google_tests/base_google_test.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/unified_google_tests/conftest.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/unified_google_tests/test_google_ai_studio.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/unified_google_tests/test_vertex_ai_native.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/unified_google_tests/test_vertex_anthropic.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/vector_store_tests/base_vector_store_test.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/vector_store_tests/conftest.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/vector_store_tests/rag/base_rag_tests.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/vector_store_tests/rag/test_rag_bedrock.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/vector_store_tests/rag/test_rag_openai.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/vector_store_tests/rag/test_rag_vertex_ai.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/vector_store_tests/test_azure_ai_vector_store.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/vector_store_tests/test_azure_vector_store.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/vector_store_tests/test_bedrock_vector_store.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/vector_store_tests/test_gemini_vector_store.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/vector_store_tests/test_milvus_vector_store.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/vector_store_tests/test_openai_vector_store.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/vector_store_tests/test_ragflow_vector_store.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/vector_store_tests/test_vertex_ai_search_api_vector_store.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/vector_store_tests/test_vertex_ai_vector_store.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "BerriAI-litellm-05f800f/tests/windows_tests/test_litellm_on_windows.py",
        "providers": [
          "litellm",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "Significant-Gravitas/AutoGPT": {
    "owner": "Significant-Gravitas",
    "repo": "AutoGPT",
    "ref": "9ef4fab084633e4289226a6dd059a598085ec876",
    "num_llm_files": 5,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "Significant-Gravitas-AutoGPT-9ef4fab/scripts/agent_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Significant-Gravitas-AutoGPT-9ef4fab/scripts/ai_functions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Significant-Gravitas-AutoGPT-9ef4fab/scripts/browse.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Significant-Gravitas-AutoGPT-9ef4fab/scripts/chat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Significant-Gravitas-AutoGPT-9ef4fab/scripts/commands.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "SolaceDev/pr-agent": {
    "owner": "SolaceDev",
    "repo": "pr-agent",
    "ref": "5c768572233adb5fb9eadef21a184410b30b5603",
    "num_llm_files": 18,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "groq",
      "langchain",
      "litellm",
      "llama",
      "ollama",
      "openai"
    ],
    "files": [
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/agent/pr_agent.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/algo/__init__.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/algo/ai_handlers/langchain_ai_handler.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/algo/ai_handlers/litellm_ai_handler.py",
        "providers": [
          "anthropic",
          "cohere",
          "groq",
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/algo/ai_handlers/openai_ai_handler.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/algo/pr_processing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/cli_pip.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/servers/github_action_runner.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/tools/pr_add_docs.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/tools/pr_code_suggestions.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/tools/pr_description.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/tools/pr_generate_labels.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/tools/pr_information_from_user.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/tools/pr_line_questions.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/tools/pr_questions.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/tools/pr_reviewer.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/tools/pr_similar_issue.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "SolaceDev-pr-agent-5c76857/pr_agent/tools/pr_update_changelog.py",
        "providers": [
          "litellm"
        ]
      }
    ],
    "error": null
  },
  "Shaunwei/RealChar": {
    "owner": "Shaunwei",
    "repo": "RealChar",
    "ref": "ee36a803e220c8a3f021a61922ea81c59e7242ee",
    "num_llm_files": 9,
    "providers": [
      "anthropic",
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "Shaunwei-RealChar-ee36a80/realtime_ai_character/audio/speech_to_text/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shaunwei-RealChar-ee36a80/realtime_ai_character/audio/speech_to_text/whisper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shaunwei-RealChar-ee36a80/realtime_ai_character/character_catalog/catalog_manager.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "Shaunwei-RealChar-ee36a80/realtime_ai_character/database/chroma.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Shaunwei-RealChar-ee36a80/realtime_ai_character/llm/__init__.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "Shaunwei-RealChar-ee36a80/realtime_ai_character/llm/anthropic_llm.py",
        "providers": [
          "anthropic",
          "langchain"
        ]
      },
      {
        "file_path": "Shaunwei-RealChar-ee36a80/realtime_ai_character/llm/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Shaunwei-RealChar-ee36a80/realtime_ai_character/llm/openai_llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Shaunwei-RealChar-ee36a80/realtime_ai_character/utils.py",
        "providers": [
          "langchain"
        ]
      }
    ],
    "error": null
  },
  "TheR1D/shell_gpt": {
    "owner": "TheR1D",
    "repo": "shell_gpt",
    "ref": "main",
    "num_llm_files": 11,
    "providers": [
      "litellm",
      "openai"
    ],
    "files": [
      {
        "file_path": "TheR1D-shell_gpt-a04167c/sgpt/app.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TheR1D-shell_gpt-a04167c/sgpt/config.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "TheR1D-shell_gpt-a04167c/sgpt/function.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TheR1D-shell_gpt-a04167c/sgpt/handlers/chat_handler.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TheR1D-shell_gpt-a04167c/sgpt/handlers/handler.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "TheR1D-shell_gpt-a04167c/sgpt/llm_functions/common/execute_shell.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TheR1D-shell_gpt-a04167c/sgpt/llm_functions/init_functions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TheR1D-shell_gpt-a04167c/sgpt/llm_functions/mac/apple_script.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TheR1D-shell_gpt-a04167c/tests/_integration.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TheR1D-shell_gpt-a04167c/tests/test_default.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TheR1D-shell_gpt-a04167c/tests/utils.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "StanGirard/quivr": {
    "owner": "StanGirard",
    "repo": "quivr",
    "ref": "b6f38f7aff5f026eb46a071362c9362e057119df",
    "num_llm_files": 47,
    "providers": [
      "anthropic",
      "langchain",
      "litellm",
      "openai"
    ],
    "files": [
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/celery_task.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/celery_worker.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/llm/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/llm/base.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/llm/models/OpenAiAnswer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/llm/openai.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/llm/prompts/CONDENSE_PROMPT.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/llm/prompts/LANGUAGE_PROMPT.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/llm/qa_base.py",
        "providers": [
          "langchain",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/llm/qa_headless.py",
        "providers": [
          "langchain",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/models/brain_entity.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/models/brains.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/models/databases/supabase/brains.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/models/files.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/models/settings.py",
        "providers": [
          "anthropic",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/models/user_identity.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/parsers/audio.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/parsers/code_python.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/parsers/common.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/parsers/csv.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/parsers/docx.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/parsers/epub.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/parsers/github.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/parsers/html.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/parsers/markdown.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/parsers/notebook.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/parsers/odt.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/parsers/pdf.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/parsers/powerpoint.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/parsers/txt.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/parsers/xlsx.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/repository/chat/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/repository/chat/format_chat_history.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/repository/files/upload_file.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/repository/user_identity/create_user_identity.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/repository/user_identity/get_user_identity.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/repository/user_identity/update_user_properties.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/routes/brain_routes.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/routes/chat_routes.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/routes/crawl_routes.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/routes/upload_routes.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/routes/user_routes.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/tests/test_brains.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/tests/test_chats.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/utils/processors.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/utils/vectors.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "QuivrHQ-quivr-b6f38f7/backend/vectorstore/supabase.py",
        "providers": [
          "langchain"
        ]
      }
    ],
    "error": null
  },
  "TransformerOptimus/SuperAGI": {
    "owner": "TransformerOptimus",
    "repo": "SuperAGI",
    "ref": "main",
    "num_llm_files": 66,
    "providers": [
      "gemini",
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/agent/agent_iteration_step_handler.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/agent/agent_message_builder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/agent/agent_tool_step_handler.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/agent/output_handler.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/agent/output_parser.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/agent/queue_step_handler.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/agent/tool_builder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/controllers/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/controllers/organisation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/helper/error_handler.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/helper/llm_loader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/helper/token_counter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/image_llms/openai_dalle.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/jobs/agent_executor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/llms/google_palm.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/llms/llm_model_factory.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/llms/openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/models/agent_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/models/models.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/models/models_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/resource_manager/llama_document_summary.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/resource_manager/llama_vector_store_factory.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/resource_manager/resource_manager.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/resource_manager/resource_summary.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/tools/code/improve_code.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/tools/code/write_code.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/tools/code/write_spec.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/tools/code/write_test.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/tools/duck_duck_go/duck_duck_go_search.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/tools/github/review_pull_request.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/tools/google_search/google_search.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/tools/google_serp_search/google_serp_search.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/tools/image_generation/dalle_image_gen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/tools/image_generation/image_generation_toolkit.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/tools/instagram_tool/instagram.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/tools/knowledge_search/knowledge_search.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/tools/knowledge_search/knowledge_search_toolkit.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/tools/resource/query_resource.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/tools/searx/searx.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/tools/thinking/tools.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/types/model_source_types.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/vector_store/embedding/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/vector_store/embedding/openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/vector_store/embedding/palm.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/vector_store/vector_factory.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/superagi/worker.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/test.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/integration_tests/vector_store/test_qdrant.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/unit_tests/agent/test_tool_builder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/unit_tests/controllers/api/test_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/unit_tests/controllers/test_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/unit_tests/controllers/test_agent_template.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/unit_tests/controllers/test_models_controller.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/unit_tests/helper/test_error_handling.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/unit_tests/helper/test_token_counter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/unit_tests/llms/test_model_factory.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/unit_tests/llms/test_open_ai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/unit_tests/resource_manager/test_llama_document_creation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/unit_tests/resource_manager/test_llama_vector_store_factory.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/unit_tests/resource_manager/test_save_document_to_vector_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/unit_tests/tools/code/test_write_code.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/unit_tests/tools/code/test_write_spec.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/unit_tests/tools/image_generation/test_dalle_image_gen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/unit_tests/types/test_model_source_types.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "TransformerOptimus-SuperAGI-c3c1982/tests/unit_tests/vector_store/test_chromadb.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "Upsonic/Upsonic": {
    "owner": "Upsonic",
    "repo": "Upsonic",
    "ref": "master",
    "num_llm_files": 134,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "groq",
      "litellm",
      "llama",
      "mistral",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/_parts_manager.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/agent/agent.py",
        "providers": [
          "anthropic",
          "groq",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/agent/context_managers/llm_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/agent/deepagent/deepagent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/agent/deepagent/tools/filesystem_toolkit.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/agent/deepagent/tools/planning_toolkit.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/canvas/canvas.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/chat/chat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/chat/cost_calculator.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/direct.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/embeddings/__init__.py",
        "providers": [
          "cohere",
          "gemini",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/embeddings/azure_openai_provider.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/embeddings/bedrock_provider.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/embeddings/factory.py",
        "providers": [
          "cohere",
          "gemini",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/embeddings/gemini_provider.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/embeddings/ollama_provider.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/embeddings/openai_provider.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/interfaces/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/interfaces/manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/knowledge_base/knowledge_base.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/messages/messages.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/models/__init__.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/models/anthropic.py",
        "providers": [
          "anthropic",
          "gemini"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/models/bedrock.py",
        "providers": [
          "anthropic",
          "cohere",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/models/cohere.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/models/google.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/models/groq.py",
        "providers": [
          "groq",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/models/huggingface.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/models/mistral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/models/model_registry.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/models/model_selector.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/models/openai.py",
        "providers": [
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/models/outlines.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/models/settings.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/ocr/deepseek.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/ocr/deepseek_ollama.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/ocr/ocr.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/profiles/__init__.py",
        "providers": [
          "groq",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/profiles/anthropic.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/profiles/cohere.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/profiles/google.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/profiles/groq.py",
        "providers": [
          "groq"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/profiles/harmony.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/profiles/mistral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/profiles/nvidia.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/profiles/openai.py",
        "providers": [
          "llama",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/profiles/qwen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/__init__.py",
        "providers": [
          "anthropic",
          "cohere",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/anthropic.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/azure.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/bedrock.py",
        "providers": [
          "anthropic",
          "cohere",
          "mistral"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/cerebras.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/cohere.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/deepseek.py",
        "providers": [
          "groq",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/fireworks.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/gateway.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/github.py",
        "providers": [
          "cohere",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/google.py",
        "providers": [
          "anthropic",
          "gemini"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/grok.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/groq.py",
        "providers": [
          "groq",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/heroku.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/huggingface.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/litellm.py",
        "providers": [
          "anthropic",
          "cohere",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/mistral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/moonshotai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/nvidia.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/ollama.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/openrouter.py",
        "providers": [
          "anthropic",
          "cohere",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/ovhcloud.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/together.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/vercel.py",
        "providers": [
          "anthropic",
          "cohere",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/providers/vllm.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/safety_engine/policies/crypto_policies.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/safety_engine/policies/technical_policies.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/team/result_combiner.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/text_splitter/agentic.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/text_splitter/factory.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/text_splitter/html_chunker.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/text_splitter/semantic.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/tools/builtin_tools.py",
        "providers": [
          "anthropic",
          "groq",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/uel/branch.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/uel/decorator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/uel/output_parser.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/uel/parallel.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/usage.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/utils/printing.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/vectordb/config.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/src/upsonic/vectordb/providers/weaviate.py",
        "providers": [
          "anthropic",
          "cohere",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/playground.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_agent_policies.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_agent_streaming.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_ask_other_team_members.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_chat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_chunkers.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_deepagent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_enabled_thinking_tool.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_eval_reliability.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_eval_team.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_graph.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_image_input_output.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_knowledgebase_as_tool.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_knowledgebase_context.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_model_selection.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_reflection.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_show_tool_calls.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_smoke_logging.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_smoke_models.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_smoke_task.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_smoke_team.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_storage_dynamic_profile.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_storage_full_memory.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_storage_user_profile_schema.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_structured_task_output.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_structured_team_output.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_structured_tool_io.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_task_cache.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_task_guardrail.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_task_search_parameters.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_team_modes.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_tool_call_limit.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_tool_config_attributes.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_tool_hitl_attributes.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/smoke_tests/test_tool_management.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/unit_tests/agent/test_context_managers.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/unit_tests/agent/test_deep_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/unit_tests/agent/test_direct.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/unit_tests/rag/chunking/test_agentic_chunking_simple.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/unit_tests/rag/embeddings/test_embedding_providers.py",
        "providers": [
          "gemini",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/unit_tests/safety_engine/test_technical_policies.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/unit_tests/test_lcel.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/unit_tests/test_model_selection.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/unit_tests/test_model_specification.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "Upsonic-Upsonic-f586dcf/tests/unit_tests/tools/test_tool_orchestration.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "VTSTech/localagi": {
    "owner": "VTSTech",
    "repo": "localagi",
    "ref": "85ecc246bd50783e9edaa4227493c0ac127912d8",
    "num_llm_files": 4,
    "providers": [
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "VTSTech-localagi-85ecc24/babyagi.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "VTSTech-localagi-85ecc24/extensions/argparseext.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "VTSTech-localagi-85ecc24/tools/results.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "VTSTech-localagi-85ecc24/tools/results_browser.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "SaudM/GPT-LMU-APP": {
    "owner": "SaudM",
    "repo": "GPT-LMU-APP",
    "ref": "882ad9818e49ca004959e17a0f7d2580ebfedb10",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "Vidminas/chatdocs-streamlit": {
    "owner": "Vidminas",
    "repo": "chatdocs-streamlit",
    "ref": "cf4053a1b20116fb0d05e64778e3c4c28b902f2a",
    "num_llm_files": 9,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "Vidminas-chatdocs-streamlit-cf4053a/chatdocs/add.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Vidminas-chatdocs-streamlit-cf4053a/chatdocs/chains.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Vidminas-chatdocs-streamlit-cf4053a/chatdocs/chat.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Vidminas-chatdocs-streamlit-cf4053a/chatdocs/document_loaders/nougat_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Vidminas-chatdocs-streamlit-cf4053a/chatdocs/embeddings.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Vidminas-chatdocs-streamlit-cf4053a/chatdocs/llms.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Vidminas-chatdocs-streamlit-cf4053a/chatdocs/ui.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Vidminas-chatdocs-streamlit-cf4053a/chatdocs/vectorstores.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Vidminas-chatdocs-streamlit-cf4053a/setup.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "abetlen/llama-cpp-python": {
    "owner": "abetlen",
    "repo": "llama-cpp-python",
    "ref": "main",
    "num_llm_files": 44,
    "providers": [
      "cohere",
      "langchain",
      "llama",
      "mistral",
      "openai"
    ],
    "files": [
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/docker/open_llama/hug_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/batch-processing/server.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/gradio_chat/local.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/gradio_chat/server.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/hf_pull/main.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/high_level_api/fastapi_server.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/high_level_api/high_level_api_embedding.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/high_level_api/high_level_api_inference.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/high_level_api/high_level_api_infill.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/high_level_api/high_level_api_streaming.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/high_level_api/langchain_custom_llm.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/low_level_api/Chat.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/low_level_api/Miku.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/low_level_api/ReasonAct.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/low_level_api/common.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/low_level_api/low_level_api_chat_cpp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/low_level_api/low_level_api_llama_cpp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/low_level_api/quantize.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/examples/ray/llm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/_ctypes_extensions.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/_ggml.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/_internals.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/_logger.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/llama.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/llama_cache.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/llama_chat_format.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/llama_cpp.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/llama_grammar.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/llama_speculative.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/llama_tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/llama_types.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/llava_cpp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/mtmd_cpp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/server/__main__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/server/app.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/server/errors.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/server/model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/server/settings.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/llama_cpp/server/types.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/tests/test_llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/tests/test_llama_chat_format.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/tests/test_llama_grammar.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "abetlen-llama-cpp-python-c37132b/tests/test_llama_speculative.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "UKPLab/sentence-transformers": {
    "owner": "UKPLab",
    "repo": "sentence-transformers",
    "ref": "main",
    "num_llm_files": 3,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "huggingface-sentence-transformers-67ff0fe/examples/sentence_transformer/applications/image-search/example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-sentence-transformers-67ff0fe/sentence_transformers/SentenceTransformer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-sentence-transformers-67ff0fe/sentence_transformers/models/CLIPModel.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "ai8hyf/babyagi": {
    "owner": "ai8hyf",
    "repo": "babyagi",
    "ref": "6fcd528a92c80846dbb351f2b7babdd50c38709d",
    "num_llm_files": 5,
    "providers": [
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "ai8hyf-babyagi-6fcd528/babyagi.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "ai8hyf-babyagi-6fcd528/extensions/argparseext.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "ai8hyf-babyagi-6fcd528/langChain-llama.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "ai8hyf-babyagi-6fcd528/tools/results.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ai8hyf-babyagi-6fcd528/tools/results_browser.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "aigeek0x0/chat-with-multiple-pdfs-streamlit-langchain-faiss-openai": {
    "owner": "aigeek0x0",
    "repo": "chat-with-multiple-pdfs-streamlit-langchain-faiss-openai",
    "ref": "3cc2b0ac1522d6a78a998759ea212052ddefb3b7",
    "num_llm_files": 1,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "aigeek0x0-chat-with-multiple-pdfs-streamlit-langchain-faiss-openai-3cc2b0a/app.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "Shubhamsaboo/awesome-llm-apps": {
    "owner": "Shubhamsaboo",
    "repo": "awesome-llm-apps",
    "ref": "main",
    "num_llm_files": 226,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "groq",
      "langchain",
      "litellm",
      "llama",
      "mistral",
      "ollama",
      "openai"
    ],
    "files": [
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_3dpygame_r1/ai_3dpygame_r1.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_chess_agent/ai_chess_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/agents.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/app.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/agent_teams/ai_competitor_intelligence_agent_team/competitor_agent_team.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/agent_teams/ai_finance_agent_team/finance_agent_team.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/agent_teams/ai_game_design_agent_team/game_design_agent_team.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/legal_agent_team.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/local_ai_legal_agent_team/local_legal_agent.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/agent_teams/ai_real_estate_agent_team/ai_real_estate_agent_team.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/agent_teams/ai_real_estate_agent_team/local_ai_real_estate_agent_team.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/agent_teams/ai_recruitment_agent_team/ai_recruitment_agent_team.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/agent_teams/ai_seo_audit_team/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/agent_teams/ai_services_agency/agency.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/agent_teams/ai_teaching_agent_team/teaching_agent_team.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/backend/config/llm.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_coding_agent_team/ai_coding_agent_o3.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_design_agent_team/design_agent_team.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_uiux_feedback_agent_team/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_uiux_feedback_agent_team/tools.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_Self-Evolving_agent/ai_Self-Evolving_agent.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_aqi_analysis_agent/ai_aqi_analysis_agent_gradio.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_aqi_analysis_agent/ai_aqi_analysis_agent_streamlit.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_email_gtm_outreach_agent/ai_email_gtm_outreach_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_financial_coach_agent/ai_financial_coach_agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_home_renovation_agent/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_home_renovation_agent/tools.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_mental_wellbeing_agent/ai_mental_wellbeing_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/agents/audio_generate_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/agents/image_generate_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/agents/scrape_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/agents/script_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/agents/search_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/db/agent_config_v2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/models/tasks_schemas.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/processors/ai_analysis_processor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/processors/embedding_processor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/processors/podcast_generator_processor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/services/celery_tasks.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/services/podcast_service.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/tests/agent_agno_test.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/tests/embedding_search_test.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/tests/tool_browseruse_test.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/tools/embedding_search.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/tools/pipeline/image_generate_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/tools/pipeline/scrape_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/tools/pipeline/script_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/tools/pipeline/search_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/tools/session_state_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/tools/social/x_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/tools/web_search.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/utils/get_articles.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/utils/load_api_keys.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/utils/text_to_audio_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/utils/translate_podcast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/beifong/utils/tts_engine_selector.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_speech_trainer_agent/backend/agents/content_analysis_agent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_speech_trainer_agent/backend/agents/coordinator_agent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_speech_trainer_agent/backend/agents/facial_expression_agent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_speech_trainer_agent/backend/agents/feedback_agent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/ai_speech_trainer_agent/backend/agents/voice_analysis_agent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/multi_agent_researcher/research_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/multi_agent_researcher/research_agent_llama3.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/multi_agent_apps/product_launch_intelligence_agent/product_launch_intelligence_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/ai_consultant_agent/ai_consultant_agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/ai_customer_support_agent/customer_support_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/ai_deep_research_agent/deep_research_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/ai_email_gtm_reachout_agent/ai_email_gtm_reachout.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/ai_health_fitness_agent/health_agent.py",
        "providers": [
          "cohere",
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/ai_investment_agent/investment_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/ai_journalist_agent/journalist_agent.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/ai_meeting_agent/meeting_agent.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/ai_movie_production_agent/movie_production_agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/ai_personal_finance_agent/finance_agent.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/ai_recipe_meal_planning_agent/ai_recipe_meal_planning_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/ai_startup_insight_fire1_agent/ai_startup_insight_fire1_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/ai_system_architect_r1/ai_system_architect_r1.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/windows_use_autonomous_agent/main.py",
        "providers": [
          "anthropic",
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/windows_use_autonomous_agent/windows_use/agent/prompt/service.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/windows_use_autonomous_agent/windows_use/agent/registry/service.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/windows_use_autonomous_agent/windows_use/agent/service.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/windows_use_autonomous_agent/windows_use/agent/tools/service.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/windows_use_autonomous_agent/windows_use/agent/utils.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_ai_agents/single_agent_apps/windows_use_autonomous_agent/windows_use/agent/views.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/chat-with-tarots/app.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/chat-with-tarots/helpers/help_func.py",
        "providers": [
          "langchain",
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/chat_with_X_tutorials/chat_with_github/chat_github.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/chat_with_X_tutorials/chat_with_github/chat_github_llama3.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/chat_with_X_tutorials/chat_with_gmail/chat_gmail.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/chat_with_X_tutorials/chat_with_pdf/chat_pdf.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/chat_with_X_tutorials/chat_with_pdf/chat_pdf_llama3.2.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/chat_with_X_tutorials/chat_with_pdf/chat_pdf_llama3.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/chat_with_X_tutorials/chat_with_research_papers/chat_arxiv.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/chat_with_X_tutorials/chat_with_research_papers/chat_arxiv_llama3.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/chat_with_X_tutorials/chat_with_substack/chat_substack.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/chat_with_X_tutorials/chat_with_youtube_videos/chat_youtube.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/cursor_ai_experiments/ai_web_scrapper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/cursor_ai_experiments/chatgpt_clone_llama3.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/cursor_ai_experiments/llm_router_app/llm_router.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/cursor_ai_experiments/local_chatgpt_clone/chatgpt_clone_llama3.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/cursor_ai_experiments/multi_agent_researcher.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/gpt_oss_critique_improvement_loop/streamlit_app.py",
        "providers": [
          "cohere",
          "groq",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/llm_apps_with_memory_tutorials/ai_arxiv_agent_memory/ai_arxiv_agent_memory.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/llm_apps_with_memory_tutorials/ai_travel_agent_memory/travel_agent_memory.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/llm_apps_with_memory_tutorials/llama3_stateful_chat/local_llama3_chat.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/llm_apps_with_memory_tutorials/llm_app_personalized_memory/llm_app_memory.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/llm_apps_with_memory_tutorials/local_chatgpt_with_memory/local_chatgpt_memory.py",
        "providers": [
          "litellm",
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/llm_apps_with_memory_tutorials/multi_llm_memory/multi_llm_memory.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/llm_finetuning_tutorials/llama3.2_finetuning/finetune_llama3.2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/llm_optimization_tools/toonify_token_optimization/toonify_app.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/llm_optimization_tools/toonify_token_optimization/toonify_demo.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/advanced_llm_apps/resume_job_matcher/app.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/1_starter_agent/creative_writing_agent/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/2_model_agnostic_agent/2_1_openai_adk_agent/agent.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/2_model_agnostic_agent/2_2_anthropic_adk_agent/agent.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/3_structured_output_agent/3_1_customer_support_ticket_agent/customer_support_agent/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/3_structured_output_agent/3_2_email_agent/email_generator_agent/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/4_tool_using_agent/4_1_builtin_tools/code_exec_agent/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/4_tool_using_agent/4_1_builtin_tools/search_agent/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/4_tool_using_agent/4_2_function_tools/calculator_agent/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/4_tool_using_agent/4_2_function_tools/utility_agent/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/4_tool_using_agent/4_3_thirdparty_tools/crewai_agent/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/4_tool_using_agent/4_3_thirdparty_tools/langchain_agent/agent.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/4_tool_using_agent/4_4_mcp_tools/filesystem_agent/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/4_tool_using_agent/4_4_mcp_tools/firecrawl_agent/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/5_memory_agent/5_1_in_memory_conversation_agent/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/5_memory_agent/5_2_persistent_conversation_agent/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/6_callbacks/6_1_agent_lifecycle_callbacks/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/6_callbacks/6_1_agent_lifecycle_callbacks/app.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/6_callbacks/6_2_llm_interaction_callbacks/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/6_callbacks/6_2_llm_interaction_callbacks/app.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/6_callbacks/6_3_tool_execution_callbacks/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/7_plugins/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/8_simple_multi_agent/multi_agent_researcher/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/9_multi_agent_patterns/9_1_sequential_agent/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/9_multi_agent_patterns/9_2_loop_agent/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/9_multi_agent_patterns/9_2_loop_agent/app.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/9_multi_agent_patterns/9_3_parallel_agent/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/google_adk_crash_course/9_multi_agent_patterns/9_3_parallel_agent/app.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/10_tracing_observability/10_1_default_tracing/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/10_tracing_observability/10_1_default_tracing/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/10_tracing_observability/10_2_custom_tracing/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/10_tracing_observability/10_2_custom_tracing/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/10_tracing_observability/custom_tracing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/10_tracing_observability/default_tracing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/11_voice/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/11_voice/realtime/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/11_voice/static/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/11_voice/streamed/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/1_starter_agent/app.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/2_structured_output_agent/product_review_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/2_structured_output_agent/support_ticket_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/3_tool_using_agent/3_2_builtin_tools/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/3_tool_using_agent/calculator_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/4_running_agents/4_3_run_configuration/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/4_running_agents/4_4_streaming_events/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/4_running_agents/4_4_streaming_events/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/4_running_agents/agent_runner.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/7_sessions/7_1_basic_sessions/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/7_sessions/7_1_basic_sessions/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/7_sessions/7_2_memory_operations/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/7_sessions/7_2_memory_operations/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/7_sessions/7_3_multi_sessions/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/7_sessions/streamlit_sessions_app.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/8_handoffs_delegation/8_1_basic_handoffs/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/8_handoffs_delegation/8_1_basic_handoffs/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/8_handoffs_delegation/8_2_advanced_handoffs/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/8_handoffs_delegation/8_2_advanced_handoffs/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/8_handoffs_delegation/advanced_handoffs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/8_handoffs_delegation/basic_handoffs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/9_multi_agent_orchestration/9_1_parallel_execution/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/9_multi_agent_orchestration/9_1_parallel_execution/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/9_multi_agent_orchestration/9_2_agents_as_tools/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/9_multi_agent_orchestration/9_2_agents_as_tools/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/9_multi_agent_orchestration/agents_as_tools.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/ai_agent_framework_crash_course/openai_sdk_crash_course/9_multi_agent_orchestration/parallel_execution.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/mcp_ai_agents/ai_travel_planner_mcp_agent_team/app.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/mcp_ai_agents/browser_mcp_agent/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/mcp_ai_agents/github_mcp_agent/github_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/mcp_ai_agents/multi_mcp_agent/multi_mcp_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/mcp_ai_agents/notion_mcp_agent/notion_mcp_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/agentic_rag_embedding_gemma/agentic_rag_embeddinggemma.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/agentic_rag_gpt5/agentic_rag_gpt5.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/agentic_rag_math_agent/rag/guardrails.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/agentic_rag_math_agent/rag/query_router.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/agentic_rag_math_agent/rag/vector.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/agentic_rag_with_reasoning/rag_reasoning_agent.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/ai_blog_search/app.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/autonomous_rag/autorag.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/corrective_rag/corrective_rag.py",
        "providers": [
          "anthropic",
          "gemini",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/deepseek_local_rag_agent/deepseek_rag_agent.py",
        "providers": [
          "langchain",
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/gemini_agentic_rag/agentic_rag_gemini.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/hybrid_search_rag/main.py",
        "providers": [
          "anthropic",
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/llama3.1_local_rag/llama3.1_local_rag.py",
        "providers": [
          "langchain",
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/local_hybrid_search_rag/local_main.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/local_rag_agent/local_rag_agent.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/qwen_local_rag/qwen_local_rag_agent.py",
        "providers": [
          "langchain",
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/rag-as-a-service/rag_app.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/rag_agent_cohere/rag_agent_cohere.py",
        "providers": [
          "cohere",
          "langchain"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/rag_chain/app.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/rag_database_routing/rag_database_routing.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/rag_tutorials/vision_rag/vision_rag.py",
        "providers": [
          "cohere",
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/ai_blog_to_podcast_agent/blog_to_podcast_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/ai_breakup_recovery_agent/ai_breakup_recovery_agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/ai_data_analysis_agent/ai_data_analyst.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/ai_data_visualisation_agent/ai_data_visualisation_agent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/ai_life_insurance_advisor_agent/life_insurance_advisor_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/ai_medical_imaging_agent/ai_medical_imaging.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/ai_meme_generator_agent_browseruse/ai_meme_generator_agent.py",
        "providers": [
          "anthropic",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/ai_music_generator_agent/music_generator_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/ai_reasoning_agent/local_ai_reasoning_agent.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/ai_reasoning_agent/reasoning_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/ai_startup_trend_analysis_agent/startup_trends_agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/ai_travel_agent/local_travel_agent.py",
        "providers": [
          "cohere",
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/ai_travel_agent/travel_agent.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/mixture_of_agents/mixture-of-agents.py",
        "providers": [
          "cohere",
          "mistral"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/multimodal_ai_agent/multimodal_reasoning_agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/multimodal_ai_agent/mutimodal_agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/opeani_research_agent/research_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/web_scrapping_ai_agent/ai_scrapper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/starter_ai_agents/web_scrapping_ai_agent/local_ai_scrapper.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/voice_ai_agents/ai_audio_tour_agent/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/voice_ai_agents/ai_audio_tour_agent/ai_audio_tour_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/voice_ai_agents/ai_audio_tour_agent/manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/voice_ai_agents/customer_support_voice_agent/customer_support_voice_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "Shubhamsaboo-awesome-llm-apps-ff75e62/voice_ai_agents/voice_rag_openaisdk/rag_voice.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "alejandro-ao/ask-multiple-pdfs": {
    "owner": "alejandro-ao",
    "repo": "ask-multiple-pdfs",
    "ref": "362e85213a01d73772d5319fb9819e026ecbe8a7",
    "num_llm_files": 1,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "alejandro-ao-ask-multiple-pdfs-362e852/app.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "alexdphan/babyagi-chroma-agent": {
    "owner": "alexdphan",
    "repo": "babyagi-chroma-agent",
    "ref": "a5379280e526fd559c49d3b85513a339afc302e5",
    "num_llm_files": 1,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "alexdphan-babyagi-chroma-agent-a537928/babyagi-chroma.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "arc53/DocsGPT": {
    "owner": "arc53",
    "repo": "DocsGPT",
    "ref": "744d4ebbaf4349444d8d361593c4c04652c6c54b",
    "num_llm_files": 22,
    "providers": [
      "cohere",
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "arc53-DocsGPT-744d4eb/application/api/answer/routes.py",
        "providers": [
          "cohere",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/application/core/settings.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/application/llm/huggingface.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/application/llm/llama_cpp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/application/llm/llm_creator.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/application/llm/openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/application/parser/file/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/application/parser/open_ai_func.py",
        "providers": [
          "cohere",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/application/parser/py2doc.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/application/parser/schema/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/application/vectorstore/base.py",
        "providers": [
          "cohere",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/application/vectorstore/faiss.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/application/worker.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/scripts/code_docs_gen.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/scripts/ingest.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/scripts/old/ingest_rst.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/scripts/old/ingest_rst_sphinx.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/scripts/parser/file/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/scripts/parser/open_ai_func.py",
        "providers": [
          "cohere",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/scripts/parser/py2doc.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/scripts/parser/schema/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "arc53-DocsGPT-744d4eb/tests/llm/test_openai.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "amauryfischer/Auto-GPT-WebUI": {
    "owner": "amauryfischer",
    "repo": "Auto-GPT-WebUI",
    "ref": "cea68df18f309b094912bdaa6ce2cd484dca5a13",
    "num_llm_files": 16,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "amauryfischer-Auto-GPT-WebUI-cea68df/autogpt/chat.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "amauryfischer-Auto-GPT-WebUI-cea68df/autogpt/cli.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "amauryfischer-Auto-GPT-WebUI-cea68df/autogpt/commands/image_gen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "amauryfischer-Auto-GPT-WebUI-cea68df/autogpt/config/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "amauryfischer-Auto-GPT-WebUI-cea68df/autogpt/config/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "amauryfischer-Auto-GPT-WebUI-cea68df/autogpt/configurator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "amauryfischer-Auto-GPT-WebUI-cea68df/autogpt/json_utils/json_fix_llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "amauryfischer-Auto-GPT-WebUI-cea68df/autogpt/llm_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "amauryfischer-Auto-GPT-WebUI-cea68df/autogpt/logs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "amauryfischer-Auto-GPT-WebUI-cea68df/autogpt/memory/base.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "amauryfischer-Auto-GPT-WebUI-cea68df/autogpt/processing/text.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "amauryfischer-Auto-GPT-WebUI-cea68df/autogpt/token_counter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "amauryfischer-Auto-GPT-WebUI-cea68df/tests/test_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "amauryfischer-Auto-GPT-WebUI-cea68df/tests/test_token_counter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "amauryfischer-Auto-GPT-WebUI-cea68df/tests/unit/test_chat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "amauryfischer-Auto-GPT-WebUI-cea68df/tests/unit/test_commands.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "arndvs/gpt4-langchain-ingest-api-data-private-chroma-aws": {
    "owner": "arndvs",
    "repo": "gpt4-langchain-ingest-api-data-private-chroma-aws",
    "ref": "5259ae39cd23892c3d0030b98ae99148fb5b7284",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "benjaminearlevans/Chatgpt-babyagi-plugin": {
    "owner": "benjaminearlevans",
    "repo": "Chatgpt-babyagi-plugin",
    "ref": "771a5ba6e6b69c30020da7a139ccec868b4a3dc7",
    "num_llm_files": 1,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "benjaminearlevans-Chatgpt-babyagi-plugin-771a5ba/main.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "bentoml/OpenLLM": {
    "owner": "bentoml",
    "repo": "OpenLLM",
    "ref": "main",
    "num_llm_files": 3,
    "providers": [
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "bentoml-OpenLLM-5725415/src/openllm/__main__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "bentoml-OpenLLM-5725415/src/openllm/local.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "bentoml-OpenLLM-5725415/src/openllm/repo.py",
        "providers": [
          "vllm"
        ]
      }
    ],
    "error": null
  },
  "bigscience-workshop/petals": {
    "owner": "bigscience-workshop",
    "repo": "petals",
    "ref": "main",
    "num_llm_files": 12,
    "providers": [
      "llama"
    ],
    "files": [
      {
        "file_path": "bigscience-workshop-petals-22afba6/benchmarks/benchmark_inference.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "bigscience-workshop-petals-22afba6/src/petals/cli/run_server.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "bigscience-workshop-petals-22afba6/src/petals/models/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "bigscience-workshop-petals-22afba6/src/petals/models/llama/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "bigscience-workshop-petals-22afba6/src/petals/models/llama/block.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "bigscience-workshop-petals-22afba6/src/petals/models/llama/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "bigscience-workshop-petals-22afba6/src/petals/models/llama/model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "bigscience-workshop-petals-22afba6/src/petals/models/llama/speculative_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "bigscience-workshop-petals-22afba6/src/petals/utils/hf_auth.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "bigscience-workshop-petals-22afba6/tests/test_full_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "bigscience-workshop-petals-22afba6/tests/test_optimized_layers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "bigscience-workshop-petals-22afba6/tests/test_speculative_generation.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "X-D-Lab/LangChain-ChatGLM-Webui": {
    "owner": "X-D-Lab",
    "repo": "LangChain-ChatGLM-Webui",
    "ref": "ef829a28234228761a97541e4ebae9da4f4e6800",
    "num_llm_files": 12,
    "providers": [
      "langchain",
      "llama"
    ],
    "files": [
      {
        "file_path": "X-D-Lab-LangChain-ChatGLM-Webui-ef829a2/app.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "X-D-Lab-LangChain-ChatGLM-Webui-ef829a2/chatllm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "X-D-Lab-LangChain-ChatGLM-Webui-ef829a2/chinese_text_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "X-D-Lab-LangChain-ChatGLM-Webui-ef829a2/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "X-D-Lab-LangChain-ChatGLM-Webui-ef829a2/jina_serving.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "X-D-Lab-LangChain-ChatGLM-Webui-ef829a2/modelscope/app.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "X-D-Lab-LangChain-ChatGLM-Webui-ef829a2/modelscope/chatglm_llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "X-D-Lab-LangChain-ChatGLM-Webui-ef829a2/modelscope/modelscope_hub.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "X-D-Lab-LangChain-ChatGLM-Webui-ef829a2/paddlepaddle/app.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "X-D-Lab-LangChain-ChatGLM-Webui-ef829a2/paddlepaddle/chatllm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "X-D-Lab-LangChain-ChatGLM-Webui-ef829a2/paddlepaddle/cli.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "X-D-Lab-LangChain-ChatGLM-Webui-ef829a2/paddlepaddle/paddle_embedding.py",
        "providers": [
          "langchain"
        ]
      }
    ],
    "error": null
  },
  "c0sogi/LLMChat": {
    "owner": "c0sogi",
    "repo": "LLMChat",
    "ref": "b0fe554ca2327d2dc43dc819934b7973e662ffdb",
    "num_llm_files": 17,
    "providers": [
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "c0sogi-LLMChat-b0fe554/app/common/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "c0sogi-LLMChat-b0fe554/app/database/connection.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "c0sogi-LLMChat-b0fe554/app/models/gpt_llms.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "c0sogi-LLMChat-b0fe554/app/models/gpt_tokenizers.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "c0sogi-LLMChat-b0fe554/app/routers/index.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "c0sogi-LLMChat-b0fe554/app/routers/websocket.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "c0sogi-LLMChat-b0fe554/app/utils/chatgpt/chatgpt_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "c0sogi-LLMChat-b0fe554/app/utils/chatgpt/chatgpt_fileloader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "c0sogi-LLMChat-b0fe554/app/utils/chatgpt/chatgpt_generation.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "c0sogi-LLMChat-b0fe554/app/utils/chatgpt/chatgpt_llama_cpp.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "c0sogi-LLMChat-b0fe554/app/utils/chatgpt/chatgpt_vectorstore_manager.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "c0sogi-LLMChat-b0fe554/app/utils/chatgpt/chatgpt_websocket_manager.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "c0sogi-LLMChat-b0fe554/app/utils/langchain/redis_vectorstore.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "c0sogi-LLMChat-b0fe554/gpu.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "c0sogi-LLMChat-b0fe554/main.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "c0sogi-LLMChat-b0fe554/tests/test_chatgpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "c0sogi-LLMChat-b0fe554/tests/test_vectorstore.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "camel-ai/camel": {
    "owner": "camel-ai",
    "repo": "camel",
    "ref": "71d466d9d67d1d7230ebfa1be6db95f5c53e38d9",
    "num_llm_files": 31,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "camel-ai-camel-71d466d/apps/agents/agents.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/agents/chat_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/agents/tool_agents/hugging_face_tool_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/configs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/functions/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/functions/math_functions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/functions/openai_function.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/functions/search_functions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/messages/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/messages/base.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/messages/func_message.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/models/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/models/base_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/models/model_factory.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/models/openai_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/models/stub_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/prompts/misalignment.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/typing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/utils/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/camel/utils/functions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/examples/function_call/role_playing_with_function.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/examples/summarization/gpt_solution_extraction.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/examples/translation/translator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/test/agents/test_chat_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/test/agents/test_role_playing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/test/conftest.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/test/functions/test_openai_function.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/test/messages/test_func_message.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/test/messages/test_message_base.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/test/models/test_openai_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "camel-ai-camel-71d466d/test/utils/test_python_interpreter.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "catid/Supercharger-Auto-GPT": {
    "owner": "catid",
    "repo": "Supercharger-Auto-GPT",
    "ref": "2f8066fb4121ba0f724cbe92c4cbef91ecf5cc29",
    "num_llm_files": 3,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "catid-Supercharger-Auto-GPT-2f8066f/scripts/chat.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "catid-Supercharger-Auto-GPT-2f8066f/scripts/config.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "catid-Supercharger-Auto-GPT-2f8066f/scripts/token_counter.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "blu3mo/scrapchat": {
    "owner": "blu3mo",
    "repo": "scrapchat",
    "ref": "ce78a875399b069d3d5c44c738cb10fb3704c0fd",
    "num_llm_files": 9,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "blu3mo-scrapchat-ce78a87/archive/app.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "blu3mo-scrapchat-ce78a87/archive/chain.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "blu3mo-scrapchat-ce78a87/archive/ingest.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "blu3mo-scrapchat-ce78a87/archive/ingest_examples.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "blu3mo-scrapchat-ce78a87/callback.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "blu3mo-scrapchat-ce78a87/ingest.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "blu3mo-scrapchat-ce78a87/main.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "blu3mo-scrapchat-ce78a87/query_data.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "blu3mo-scrapchat-ce78a87/scrapchat/ScrapboxLoader.py",
        "providers": [
          "langchain"
        ]
      }
    ],
    "error": null
  },
  "chenhunghan/code-review-private-ai": {
    "owner": "chenhunghan",
    "repo": "code-review-private-ai",
    "ref": "17f00ec43ba35f3914fea322ad84f4b1a888500f",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "chidiwilliams/buzz": {
    "owner": "chidiwilliams",
    "repo": "buzz",
    "ref": "main",
    "num_llm_files": 38,
    "providers": [
      "groq",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/cli.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/file_transcriber_queue_worker.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/model_loader.py",
        "providers": [
          "groq",
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/settings/settings.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/store/keyring_store.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/transcriber/local_whisper_cpp_server_transcriber.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/transcriber/openai_whisper_api_file_transcriber.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/transcriber/recording_transcriber.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/transcriber/transcriber.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/transcriber/whisper_file_transcriber.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/translator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/widgets/main_window.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/widgets/menu_bar.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/widgets/openai_api_key_line_edit.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/widgets/preferences_dialog/folder_watch_preferences_widget.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/widgets/preferences_dialog/general_preferences_widget.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/widgets/preferences_dialog/models/file_transcription_preferences.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/widgets/preferences_dialog/models_preferences_widget.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/widgets/preferences_dialog/preferences_dialog.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/widgets/recording_transcriber_widget.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/widgets/transcriber/advanced_settings_dialog.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/widgets/transcriber/file_transcriber_widget.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/widgets/transcriber/file_transcription_form_widget.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/widgets/transcriber/transcription_options_group_box.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/widgets/transcription_task_folder_watcher.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/widgets/transcription_tasks_table_widget.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/widgets/transcription_viewer/transcription_resizer_widget.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/buzz/widgets/transcription_viewer/transcription_viewer_widget.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/tests/gui_test.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/tests/transcriber/openai_whisper_api_file_transcriber_test.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/tests/transcriber/whisper_file_transcriber_test.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/tests/transformers_whisper_test.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/tests/translator_test.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/tests/widgets/model_type_combo_box_test.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/tests/widgets/openai_api_key_line_edit_test.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/tests/widgets/preferences_dialog/general_preferences_widget_test.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/tests/widgets/transcription_viewer/transcription_viewer_widget_additional_test.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chidiwilliams-buzz-11e59db/tests/widgets/transcription_viewer_test.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "chinesewebman/doc-chatbot": {
    "owner": "chinesewebman",
    "repo": "doc-chatbot",
    "ref": "d17caf9f0414bc7bc802774de1f13c5d746966fb",
    "num_llm_files": 6,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "chinesewebman-doc-chatbot-d17caf9/src/Home.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chinesewebman-doc-chatbot-d17caf9/src/modules/chatbot.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "chinesewebman-doc-chatbot-d17caf9/src/modules/embedder.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "chinesewebman-doc-chatbot-d17caf9/src/modules/layout.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chinesewebman-doc-chatbot-d17caf9/src/modules/sidebar.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "chinesewebman-doc-chatbot-d17caf9/src/modules/utils.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "chatchat-space/Langchain-Chatchat": {
    "owner": "chatchat-space",
    "repo": "Langchain-Chatchat",
    "ref": "bc7f01925fe49c622cf7d6e2540c03fd5a0679e1",
    "num_llm_files": 113,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "groq",
      "langchain",
      "llama",
      "mistral",
      "ollama",
      "openai"
    ],
    "files": [
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/agent/agent_factory/agents_registry.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/agent/agent_factory/glm3_agent.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/agent/agent_factory/qwen_agent.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/agent/container.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/agent/tools_factory/arxiv.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/agent/tools_factory/calculate.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/agent/tools_factory/search_internet.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/agent/tools_factory/search_youtube.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/agent/tools_factory/shell.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/agent/tools_factory/text2image.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/agent/tools_factory/tools_registry.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/agent/tools_factory/wolfram.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/api_server/api_schemas.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/api_server/openai_routes.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/api_server/server_app.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/callback_handler/agent_callback_handler.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/callback_handler/conversation_callback_handler.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/chat/chat.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/chat/completion.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/chat/file_chat.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/chat/utils.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/document_loaders/FilteredCSVloader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/document_loaders/mydocloader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/document_loaders/myimgloader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/document_loaders/mypdfloader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/document_loaders/mypptloader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/knowledge_base/kb_cache/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/knowledge_base/kb_cache/faiss_cache.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/knowledge_base/kb_doc_api.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/knowledge_base/kb_service/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/knowledge_base/kb_service/chromadb_kb_service.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/knowledge_base/kb_service/default_kb_service.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/knowledge_base/kb_service/es_kb_service.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/knowledge_base/kb_service/faiss_kb_service.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/knowledge_base/kb_service/milvus_kb_service.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/knowledge_base/kb_service/pg_kb_service.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/knowledge_base/kb_service/zilliz_kb_service.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/knowledge_base/kb_summary/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/knowledge_base/kb_summary/summary_chunk.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/knowledge_base/kb_summary_api.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/knowledge_base/model/kb_document_model.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/knowledge_base/utils.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/llm_api_shutdown.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/llm_api_stale.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/localai_embeddings.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/memory/conversation_db_buffer_memory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/minx_chat_openai.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/pydantic_v1.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/reranker/reranker.py",
        "providers": [
          "cohere",
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/text_splitter/ali_text_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/text_splitter/chinese_recursive_text_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/text_splitter/chinese_text_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/text_splitter/zh_title_enhance.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat-server/chatchat_server/utils.py",
        "providers": [
          "langchain",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat/chatchat/startup.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat/chatchat/tests/api/test_kb_api.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat/chatchat/tests/api/test_kb_api_request.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat/chatchat/tests/api/test_kb_summary_api.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat/chatchat/tests/api/test_openai_wrap.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat/chatchat/tests/custom_splitter/test_different_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat/chatchat/tests/test_qwen_agent.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/chatchat/chatchat/webui.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/__main__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/bootstrap_web/openai_bootstrap_web.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/bootstrap/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/bootstrap/base.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/entities/message_entities.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/entities/provider_configuration.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/anthropic/anthropic.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/anthropic/llm/llm.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/azure_openai/_common.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/azure_openai/_constant.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/azure_openai/azure_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/azure_openai/llm/llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/azure_openai/speech2text/speech2text.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/azure_openai/text_embedding/text_embedding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/azure_openai/tts/tts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/bedrock/bedrock.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/bedrock/llm/llm.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/chatglm/llm/llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/cohere/cohere.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/cohere/llm/llm.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/cohere/rerank/rerank.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/cohere/text_embedding/text_embedding.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/google/google.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/google/llm/llm.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/groq/groq.py",
        "providers": [
          "groq",
          "llama"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/groq/llm/llm.py",
        "providers": [
          "groq",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/localai/llm/llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/mistralai/llm/llm.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/mistralai/mistralai.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/moonshot/llm/llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/ollama/llm/llm.py",
        "providers": [
          "cohere",
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/ollama/ollama.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/ollama/text_embedding/text_embedding.py",
        "providers": [
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/openai/_common.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/openai/llm/llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/openai/moderation/moderation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/openai/openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/openai/speech2text/speech2text.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/openai/text_embedding/text_embedding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/openai/tts/tts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/openai_api_compatible/llm/llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/openai_api_compatible/text_embedding/text_embedding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/spark/llm/llm.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/togetherai/llm/llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/tongyi/llm/_client.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/tongyi/llm/llm.py",
        "providers": [
          "anthropic",
          "langchain"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/model_runtime/model_providers/xinference/llm/llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/model-providers/chatchat_model_providers/core/provider_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/webui-pages/chatchat_webui_pages/loom_view_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/webui-pages/chatchat_webui_pages/openai_plugins/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "chatchat-space-Langchain-Chatchat-bc7f019/webui-pages/chatchat_webui_pages/openai_plugins/base.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "activeloopai/deeplake": {
    "owner": "activeloopai",
    "repo": "deeplake",
    "ref": "main",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "codeacme17/examor": {
    "owner": "codeacme17",
    "repo": "examor",
    "ref": "891ed727b711c6b59e3c6899f7fa08f0df773c30",
    "num_llm_files": 11,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "codeacme17-examor-891ed72/server/apis/question.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "codeacme17-examor-891ed72/server/db_services/profile.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "codeacme17-examor-891ed72/server/lang_chain/chain.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "codeacme17-examor-891ed72/server/lang_chain/llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "codeacme17-examor-891ed72/server/loaders/markdown.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "codeacme17-examor-891ed72/server/prompts/cn/answer_exmine.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "codeacme17-examor-891ed72/server/prompts/cn/question_generate.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "codeacme17-examor-891ed72/server/prompts/en/answer_exmine.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "codeacme17-examor-891ed72/server/prompts/en/question_generate.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "codeacme17-examor-891ed72/server/utils/file_handler.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "codeacme17-examor-891ed72/server/utils/types.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "daveshap/ChromaDB_Chatbot_Public": {
    "owner": "daveshap",
    "repo": "ChromaDB_Chatbot_Public",
    "ref": "ad7df3a7391c07ab59298e48ac05c24c8698698b",
    "num_llm_files": 1,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "daveshap-ChromaDB_Chatbot_Public-ad7df3a/chat.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "cpacker/MemGPT": {
    "owner": "cpacker",
    "repo": "MemGPT",
    "ref": "6e2c92e3abda617b9efc96c88b582195579717c8",
    "num_llm_files": 44,
    "providers": [
      "llama",
      "mistral",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/autogen/examples/agent_autoreply.py",
        "providers": [
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/autogen/examples/agent_docs.py",
        "providers": [
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/autogen/examples/agent_groupchat.py",
        "providers": [
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/cli/cli.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/cli/cli_config.py",
        "providers": [
          "llama",
          "mistral",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/cli/cli_load.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/config.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/connectors/local.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/connectors/storage.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/constants.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/embeddings.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/functions/function_sets/extras.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/chat_completion_proxy.py",
        "providers": [
          "llama",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/constants.py",
        "providers": [
          "llama",
          "mistral",
          "ollama",
          "vllm"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/koboldcpp/api.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/llamacpp/api.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/llamacpp/settings.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/llm_chat_completion_wrappers/airoboros.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/llm_chat_completion_wrappers/dolphin.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/llm_chat_completion_wrappers/simple_summary_wrapper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/llm_chat_completion_wrappers/zephyr.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/lmstudio/api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/lmstudio/settings.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/ollama/api.py",
        "providers": [
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/ollama/settings.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/utils.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/vllm/api.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/webui/api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/webui/legacy_api.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/webui/legacy_settings.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/local_llm/webui/settings.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/memory.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/openai_tools.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/personas/examples/docqa/generate_embeddings_for_docs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/personas/examples/docqa/openai_parallel_request_processor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/personas/examples/docqa/scrape_docs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/presets/presets.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/server/websocket_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/memgpt/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/tests/test_storage.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/tests/test_websocket_interface.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "letta-ai-letta-6e2c92e/tests/utils.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "davideuler/gpt4-pdf-chatbot-langchain-chromadb": {
    "owner": "davideuler",
    "repo": "gpt4-pdf-chatbot-langchain-chromadb",
    "ref": "5c0f8daba056483afebf9e8a46a988e07c58ee99",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "dory111111/babyagi-streamlit": {
    "owner": "dory111111",
    "repo": "babyagi-streamlit",
    "ref": "088aa7376c39d541543a3518df8bd5db46633f51",
    "num_llm_files": 4,
    "providers": [
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "dory111111-babyagi-streamlit-088aa73/babyagi.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "dory111111-babyagi-streamlit-088aa73/extensions/argparseext.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "dory111111-babyagi-streamlit-088aa73/tools/results.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "dory111111-babyagi-streamlit-088aa73/tools/results_browser.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "dotneet/smart-chatbot-ui": {
    "owner": "dotneet",
    "repo": "smart-chatbot-ui",
    "ref": "6a07b944b73ca53996a1a06cdf65ab19ed2a19ab",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "c121914yu/FastGPT": {
    "owner": "c121914yu",
    "repo": "FastGPT",
    "ref": "2ae8d43216d4e6fb739143c3cc12285fed048596",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "dotvignesh/PDFChat": {
    "owner": "dotvignesh",
    "repo": "PDFChat",
    "ref": "bb46824b7835386d39f76cd0c70b427dc42997c9",
    "num_llm_files": 1,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "dotvignesh-PDFChat-bb46824/app.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "edik7333/Auto-GPT-llama-cpp": {
    "owner": "edik7333",
    "repo": "Auto-GPT-llama-cpp",
    "ref": "2b4bf189825c0abe28bf6f020b87921d82636d67",
    "num_llm_files": 9,
    "providers": [
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "edik7333-Auto-GPT-llama-cpp-2b4bf18/scripts/chat.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "edik7333-Auto-GPT-llama-cpp-2b4bf18/scripts/config.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "edik7333-Auto-GPT-llama-cpp-2b4bf18/scripts/image_gen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "edik7333-Auto-GPT-llama-cpp-2b4bf18/scripts/llm_utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "edik7333-Auto-GPT-llama-cpp-2b4bf18/scripts/main.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "edik7333-Auto-GPT-llama-cpp-2b4bf18/scripts/memory/base.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "edik7333-Auto-GPT-llama-cpp-2b4bf18/scripts/testmodel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "edik7333-Auto-GPT-llama-cpp-2b4bf18/scripts/token_counter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "edik7333-Auto-GPT-llama-cpp-2b4bf18/tests/test_config.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "deepset-ai/haystack": {
    "owner": "deepset-ai",
    "repo": "haystack",
    "ref": "main",
    "num_llm_files": 107,
    "providers": [
      "anthropic",
      "cohere",
      "groq",
      "llama",
      "mistral",
      "openai"
    ],
    "files": [
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/e2e/pipelines/test_evaluation_pipeline.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/e2e/pipelines/test_pdf_content_extraction_pipeline.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/e2e/pipelines/test_rag_pipelines_e2e.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/agents/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/audio/whisper_local.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/audio/whisper_remote.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/builders/chat_prompt_builder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/builders/prompt_builder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/connectors/openapi_service.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/converters/image/document_to_image.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/converters/image/file_to_image.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/converters/image/pdf_to_image.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/converters/openapi_functions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/embedders/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/embedders/azure_document_embedder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/embedders/azure_text_embedder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/embedders/openai_document_embedder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/embedders/openai_text_embedder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/evaluators/context_relevance.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/evaluators/faithfulness.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/evaluators/llm_evaluator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/extractors/image/llm_document_content_extractor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/extractors/llm_metadata_extractor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/generators/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/generators/azure.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/generators/chat/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/generators/chat/azure.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/generators/chat/azure_responses.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/generators/chat/fallback.py",
        "providers": [
          "anthropic",
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/generators/chat/hugging_face_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/generators/chat/hugging_face_local.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/generators/chat/openai.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/generators/chat/openai_responses.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/generators/openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/generators/openai_dalle.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/joiners/answer_joiner.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/joiners/branch.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/joiners/list_joiner.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/joiners/string_joiner.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/query/query_expander.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/routers/llm_messages_router.py",
        "providers": [
          "groq",
          "llama"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/routers/transformers_text_router.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/components/validators/json_schema.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/core/pipeline/async_pipeline.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/core/pipeline/pipeline.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/core/super_component/super_component.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/dataclasses/chat_message.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/dataclasses/image_content.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/dataclasses/streaming_chunk.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/tools/component_tool.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/tools/pipeline_tool.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/haystack/utils/auth.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/agents/test_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/agents/test_agent_breakpoints.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/agents/test_agent_breakpoints_inside_pipeline.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/audio/test_whisper_remote.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/builders/test_answer_builder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/connectors/test_openapi_service.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/converters/test_openapi_functions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/embedders/test_azure_document_embedder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/embedders/test_azure_text_embedder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/embedders/test_openai_document_embedder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/embedders/test_openai_text_embedder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/evaluators/test_context_relevance_evaluator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/evaluators/test_faithfulness_evaluator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/evaluators/test_llm_evaluator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/extractors/image/test_llm_document_content_extractor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/extractors/test_llm_metadata_extractor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/generators/chat/test_azure.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/generators/chat/test_azure_responses.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/generators/chat/test_hugging_face_api.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/generators/chat/test_hugging_face_local.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/generators/chat/test_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/generators/chat/test_openai_async.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/generators/chat/test_openai_responses.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/generators/conftest.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/generators/test_azure.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/generators/test_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/generators/test_openai_dalle.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/generators/test_utils.py",
        "providers": [
          "anthropic",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/joiners/test_list_joiner.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/query/test_query_expander.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/retrievers/test_multi_query_embedding_retriever.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/retrievers/test_multi_query_text_retriever.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/routers/test_llm_messages_router.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/tools/test_tool_invoker.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/validators/test_json_schema.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/components/websearch/test_searchapi.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/core/pipeline/break_points/test_pipeline_breakpoints_agent_function_calling.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/core/pipeline/break_points/test_pipeline_breakpoints_answer_joiner.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/core/pipeline/break_points/test_pipeline_breakpoints_branch_joiner.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/core/pipeline/break_points/test_pipeline_breakpoints_list_joiner.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/core/pipeline/break_points/test_pipeline_breakpoints_loops.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/core/pipeline/break_points/test_pipeline_breakpoints_rag_hybrid.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/core/pipeline/features/test_run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/core/pipeline/test_pipeline_base.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/core/pipeline/test_templates.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/core/pipeline/test_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/core/super_component/test_super_component.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/core/test_importing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/dataclasses/test_chat_message.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/dataclasses/test_streaming_chunk.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/tools/test_component_tool.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/tools/test_parameters_schema_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/tools/test_pipeline_tool.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/utils/test_deserialization.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "deepset-ai-haystack-e4ca3ef/test/utils/test_jinja2_chat_extension.py",
        "providers": [
          "anthropic"
        ]
      }
    ],
    "error": null
  },
  "edrickdch/chat-pdf": {
    "owner": "edrickdch",
    "repo": "chat-pdf",
    "ref": "bf5343fef116a360424245b1c154edc2bac07bfd",
    "num_llm_files": 2,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "edrickdch-chat-pdf-bf5343f/src/ingest.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "edrickdch-chat-pdf-bf5343f/src/single-pdf.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "facebookresearch/detr": {
    "owner": "facebookresearch",
    "repo": "detr",
    "ref": "main",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "facebookresearch/DiT": {
    "owner": "facebookresearch",
    "repo": "DiT",
    "ref": "main",
    "num_llm_files": 8,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "facebookresearch-DiT-ed81ce2/diffusion/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "facebookresearch-DiT-ed81ce2/diffusion/diffusion_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "facebookresearch-DiT-ed81ce2/diffusion/gaussian_diffusion.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "facebookresearch-DiT-ed81ce2/diffusion/respace.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "facebookresearch-DiT-ed81ce2/diffusion/timestep_sampler.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "facebookresearch-DiT-ed81ce2/models.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "facebookresearch-DiT-ed81ce2/sample_ddp.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "facebookresearch-DiT-ed81ce2/train.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "eosphoros-ai/DB-GPT": {
    "owner": "eosphoros-ai",
    "repo": "DB-GPT",
    "ref": "1519df7f0179be0957008e75fd27eafb9d6890f1",
    "num_llm_files": 31,
    "providers": [
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/examples/app.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/examples/embdserver.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/examples/gpt_index.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/examples/t5_example.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/agent/json_fix_llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/configs/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/language/lang_content_mapping.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/model/adapter.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/model/llm/monkey_patch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/model/llm_out/proxy_llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/model/llm_out/vicuna_llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/model/loader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/prompts/prompt_template.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/pturning/lora/finetune.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/scene/base_message.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/server/vectordb_qa.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/source_embedding/chn_document_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/source_embedding/csv_embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/source_embedding/knowledge_embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/source_embedding/markdown_embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/source_embedding/pdf_embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/source_embedding/pdf_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/source_embedding/search_milvus.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/source_embedding/string_embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/source_embedding/url_embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/summary/db_summary_client.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/vector_store/chroma_store.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/vector_store/extract_tovec.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/vector_store/file_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/pilot/vector_store/milvus_store.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "eosphoros-ai-DB-GPT-1519df7/tests/unit/test_plugins.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "facebookresearch/dino": {
    "owner": "facebookresearch",
    "repo": "dino",
    "ref": "main",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "facebookresearch/xformers": {
    "owner": "facebookresearch",
    "repo": "xformers",
    "ref": "main",
    "num_llm_files": 11,
    "providers": [
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "facebookresearch-xformers-6d6e6f0/examples/llama_inference/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "facebookresearch-xformers-6d6e6f0/examples/llama_inference/model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "facebookresearch-xformers-6d6e6f0/xformers/benchmarks/benchmark_attn_decoding.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "facebookresearch-xformers-6d6e6f0/xformers/benchmarks/benchmark_mem_eff_attention.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "facebookresearch-xformers-6d6e6f0/xformers/benchmarks/benchmark_sequence_parallel_fused.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "facebookresearch-xformers-6d6e6f0/xformers/benchmarks/benchmark_tiled_matmul.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "facebookresearch-xformers-6d6e6f0/xformers/ops/_triton/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "facebookresearch-xformers-6d6e6f0/xformers/ops/_triton/tiled_matmul_kernels.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "facebookresearch-xformers-6d6e6f0/xformers/ops/rope_padded.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "facebookresearch-xformers-6d6e6f0/xformers/ops/tiled_matmul.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "facebookresearch-xformers-6d6e6f0/xformers/utils.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "fendouai/babyagi_zh": {
    "owner": "fendouai",
    "repo": "babyagi_zh",
    "ref": "bc907f1d94cd0a6b57db5f6e2b1d0ffbabf6b864",
    "num_llm_files": 4,
    "providers": [
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "fendouai-babyagi_zh-bc907f1/babyagi.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "fendouai-babyagi_zh-bc907f1/extensions/argparseext.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "fendouai-babyagi_zh-bc907f1/tools/results.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "fendouai-babyagi_zh-bc907f1/tools/results_browser.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "facebookresearch/vggt": {
    "owner": "facebookresearch",
    "repo": "vggt",
    "ref": "main",
    "num_llm_files": 1,
    "providers": [
      "llama"
    ],
    "files": [
      {
        "file_path": "facebookresearch-vggt-44b3afb/vggt/layers/rope.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "fishaudio/fish-speech": {
    "owner": "fishaudio",
    "repo": "fish-speech",
    "ref": "main",
    "num_llm_files": 13,
    "providers": [
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "fishaudio-fish-speech-80db25e/fish_speech/inference_engine/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fishaudio-fish-speech-80db25e/fish_speech/models/text2semantic/inference.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fishaudio-fish-speech-80db25e/fish_speech/models/text2semantic/lit_module.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fishaudio-fish-speech-80db25e/fish_speech/models/text2semantic/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fishaudio-fish-speech-80db25e/fish_speech/tokenizer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "fishaudio-fish-speech-80db25e/fish_speech/train.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fishaudio-fish-speech-80db25e/tools/api_server.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fishaudio-fish-speech-80db25e/tools/llama/merge_lora.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fishaudio-fish-speech-80db25e/tools/llama/quantize.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fishaudio-fish-speech-80db25e/tools/run_webui.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fishaudio-fish-speech-80db25e/tools/server/api_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fishaudio-fish-speech-80db25e/tools/server/model_manager.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fishaudio-fish-speech-80db25e/tools/webui/variables.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "frasergr/anything-llm": {
    "owner": "frasergr",
    "repo": "anything-llm",
    "ref": "5fa61458724fd019a15e243b8db8e71bead950b5",
    "num_llm_files": 9,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "frasergr-anything-llm-5fa6145/collector/scripts/gitbook.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "frasergr-anything-llm-5fa6145/collector/scripts/link.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "frasergr-anything-llm-5fa6145/collector/scripts/medium.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "frasergr-anything-llm-5fa6145/collector/scripts/substack.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "frasergr-anything-llm-5fa6145/collector/scripts/substack_utils.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "frasergr-anything-llm-5fa6145/collector/scripts/watch/convert/as_docx.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "frasergr-anything-llm-5fa6145/collector/scripts/watch/convert/as_markdown.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "frasergr-anything-llm-5fa6145/collector/scripts/watch/convert/as_pdf.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "frasergr-anything-llm-5fa6145/collector/scripts/youtube.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "gabacode/ChatBot-PDF": {
    "owner": "gabacode",
    "repo": "ChatBot-PDF",
    "ref": "320476ac687db4ea0e9051b4b25ef6904d3a014d",
    "num_llm_files": 5,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "gabacode-ChatBot-PDF-320476a/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "gabacode-ChatBot-PDF-320476a/modules/chatbot.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "gabacode-ChatBot-PDF-320476a/modules/embedder.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "gabacode-ChatBot-PDF-320476a/modules/layout.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "gabacode-ChatBot-PDF-320476a/modules/sidebar.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "goetzrobin/MemGPT": {
    "owner": "goetzrobin",
    "repo": "MemGPT",
    "ref": "0e8918e79935d24210991d78da09bf0e4c796d2e",
    "num_llm_files": 71,
    "providers": [
      "llama",
      "mistral",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/examples/google_search.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/examples/openai_client_assistants.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/agent_store/db.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/agent_store/lancedb.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/agent_store/storage.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/autogen/examples/agent_autoreply.py",
        "providers": [
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/autogen/examples/agent_docs.py",
        "providers": [
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/autogen/examples/agent_groupchat.py",
        "providers": [
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/autogen/memgpt_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/cli/cli.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/cli/cli_config.py",
        "providers": [
          "llama",
          "mistral",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/cli/cli_load.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/constants.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/credentials.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/data_sources/connectors.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/data_types.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/embeddings.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/interface.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/llm_api_tools.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/chat_completion_proxy.py",
        "providers": [
          "llama",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/constants.py",
        "providers": [
          "llama",
          "mistral",
          "ollama",
          "vllm"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/koboldcpp/api.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/llamacpp/api.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/llamacpp/settings.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/llm_chat_completion_wrappers/airoboros.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/llm_chat_completion_wrappers/configurable_wrapper.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/llm_chat_completion_wrappers/dolphin.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/llm_chat_completion_wrappers/simple_summary_wrapper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/llm_chat_completion_wrappers/zephyr.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/lmstudio/api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/lmstudio/settings.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/ollama/api.py",
        "providers": [
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/ollama/settings.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/utils.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/vllm/api.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/webui/api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/webui/legacy_api.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/webui/legacy_settings.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/local_llm/webui/settings.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/memory.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/migrate.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/models/chat_completion_request.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/models/embedding_response.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/models/openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/models/pydantic_models.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/openai_backcompat/openai_object.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/presets/presets.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/server/rest_api/openai_assistants/assistants.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/server/rest_api/server.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/server/server.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/server/ws_api/example_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/memgpt/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/tests/test_agent_function_update.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/tests/test_autogen_integration.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/tests/test_base_functions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/tests/test_cli.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/tests/test_client.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/tests/test_different_embedding_size.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/tests/test_load_archival.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/tests/test_metadata_store.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/tests/test_migrate.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/tests/test_openai_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/tests/test_persistence.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/tests/test_server.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/tests/test_storage.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/tests/test_summarize.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/tests/test_websocket_interface.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "goetzrobin-MemGPT-0e8918e/tests/utils.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "groovybits/gaib": {
    "owner": "groovybits",
    "repo": "gaib",
    "ref": "887e8edf7f6ce112af4790ac5f45c629b05e3225",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": "failed to download zip zip not found"
  },
  "h2oai/h2ogpt": {
    "owner": "h2oai",
    "repo": "h2ogpt",
    "ref": "15f3a2d564541020f78cfc83bc90722dcda8a960",
    "num_llm_files": 38,
    "providers": [
      "anthropic",
      "langchain",
      "llama",
      "ollama",
      "openai"
    ],
    "files": [
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/client/h2ogpt_client/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/client/h2ogpt_client/_core.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/client/h2ogpt_client/_utils.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/finetune.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/gradio_utils/prompt_form.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/metrics/quip.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/models/create_model_cards.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/setup.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/cli.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/client_test.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/create_data.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/enums.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/eval.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/evaluate_params.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/export_hf_checkpoint.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/gen.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/gpt4all_llm.py",
        "providers": [
          "langchain",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/gpt_langchain.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/gradio_runner.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/h2oai_pipeline.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/image_captions.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/llama_flash_attn_monkey_patch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/loaders.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/make_db.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/prompter.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/read_wiki_full.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/src/utils_langchain.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/tests/test_cli.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/tests/test_client_calls.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/tests/test_eval.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/tests/test_eval_models.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/tests/test_inference_servers.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/tests/test_langchain_simple.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/tests/test_langchain_units.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/tests/test_manual_test.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/tests/test_pipeline.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/tests/test_prompter.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "h2oai-h2ogpt-15f3a2d/tests/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "hamelsmu/chat-langchain": {
    "owner": "hamelsmu",
    "repo": "chat-langchain",
    "ref": "8252cc469335da08230afb049cdc7dfb178c328b",
    "num_llm_files": 4,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "hamelsmu-chat-langchain-8252cc4/callback.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hamelsmu-chat-langchain-8252cc4/ingest.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "hamelsmu-chat-langchain-8252cc4/main.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hamelsmu-chat-langchain-8252cc4/query_data.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "haotian-liu/LLaVA": {
    "owner": "haotian-liu",
    "repo": "LLaVA",
    "ref": "main",
    "num_llm_files": 28,
    "providers": [
      "cohere",
      "llama",
      "mistral",
      "openai"
    ],
    "files": [
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/conversation.py",
        "providers": [
          "cohere",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/eval/eval_gpt_review.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/eval/eval_gpt_review_bench.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/eval/eval_gpt_review_visual.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/eval/eval_science_qa_gpt4.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/eval/eval_science_qa_gpt4_requery.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/eval/generate_webpage_data_from_table.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/eval/qa_baseline_gpt35.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/eval/run_llava.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/eval/summarize_gpt_review.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/model/__init__.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/model/apply_delta.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/model/builder.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/model/language_model/llava_llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/model/language_model/llava_mistral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/model/make_delta.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/model/multimodal_encoder/builder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/model/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/serve/cli.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/serve/gradio_web_server.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/train/llama_flash_attn_monkey_patch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/train/llama_xformers_attn_monkey_patch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/train/train.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/train/train_xformers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/llava/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/predict.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "haotian-liu-LLaVA-c121f04/scripts/convert_sqa_to_llava_base_prompt.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "fangyinc/DB-GPT": {
    "owner": "fangyinc",
    "repo": "DB-GPT",
    "ref": "f317740d5557b56899d1a3e786ca7cc583fdd700",
    "num_llm_files": 69,
    "providers": [
      "anthropic",
      "cohere",
      "langchain",
      "llama",
      "mistral",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/_private/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/_private/llm_metadata.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/app/chat_adapter.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/app/initialization/embedding_component.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/app/knowledge/service.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/app/openapi/api_v1/api_v1.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/configs/model_config.py",
        "providers": [
          "anthropic",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/core/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/core/interface/llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/core/interface/message.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/adapter.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/base.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/cluster/apiserver/api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/cluster/apiserver/tests/test_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/cluster/embedding/loader.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/cluster/embedding/remote_embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/cluster/worker/embedding_worker.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/conversation.py",
        "providers": [
          "cohere",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/llm/llama_cpp/llama_cpp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/llm/monkey_patch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/llm_out/gpt4all_llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/llm_out/hf_chat_llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/llm_out/llama_cpp_llm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/llm_out/proxy_llm.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/llm_out/vicuna_llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/llm_out/vllm_llm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/loader.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/model_adapter.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/parameter.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/proxy/llms/chatgpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/model/proxy/llms/claude.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/csv_embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/embedding_engine.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/embedding_factory.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/encode_text_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/loader/chn_document_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/loader/csv_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/loader/docx_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/loader/pdf_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/loader/ppt_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/loader/splitter_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/markdown_embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/pdf_embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/ppt_embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/pre_text_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/search_milvus.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/source_embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/string_embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/url_embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/embedding_engine/word_embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/extracter/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/extracter/summary.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/graph_engine/graph_engine.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/graph_engine/graph_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/graph_engine/index_struct.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/graph_engine/kv_index.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/graph_engine/node.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/rag/summary/db_summary_client.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/storage/vector_store/chroma_store.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/storage/vector_store/milvus_store.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/storage/vector_store/pgvector_store.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/storage/vector_store/weaviate_store.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/util/benchmarks/llm/llm_benchmarks.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/util/global_helper.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/dbgpt/util/system_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/examples/sdk/simple_sdk_llm_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/examples/sdk/simple_sdk_llm_sql_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/setup.py",
        "providers": [
          "langchain",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "fangyinc-DB-GPT-f317740/tests/unit_tests/test_plugins.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "hlohaus/Agent-LLM": {
    "owner": "hlohaus",
    "repo": "Agent-LLM",
    "ref": "d8a46dacea35c6224effd3e733d5c085bea1949a",
    "num_llm_files": 10,
    "providers": [
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "hlohaus-Agent-LLM-d8a46da/AgentLLM.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "hlohaus-Agent-LLM-d8a46da/Config/Agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "hlohaus-Agent-LLM-d8a46da/Config/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "hlohaus-Agent-LLM-d8a46da/app.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "hlohaus-Agent-LLM-d8a46da/commands/image_generator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "hlohaus-Agent-LLM-d8a46da/provider/chatgpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "hlohaus-Agent-LLM-d8a46da/provider/gpt4free.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "hlohaus-Agent-LLM-d8a46da/provider/huggingchat.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hlohaus-Agent-LLM-d8a46da/provider/llamacpp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hlohaus-Agent-LLM-d8a46da/provider/openai.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "hiyouga/LLaMA-Factory": {
    "owner": "hiyouga",
    "repo": "LLaMA-Factory",
    "ref": "main",
    "num_llm_files": 199,
    "providers": [
      "cohere",
      "llama",
      "mistral",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/api_example/test_image.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/api_example/test_toolcall.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/bench_qwen.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/convert_ckpt/llamafy_baichuan2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/convert_ckpt/llamafy_qwen.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/convert_ckpt/tiny_llama4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/eval_bleu_rouge.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/llama_pro.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/loftq_init.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/megatron_merge.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/pissa_init.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/qwen_omni_merge.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/stat_utils/cal_flops.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/stat_utils/cal_lr.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/stat_utils/cal_mfu.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/stat_utils/cal_ppl.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/stat_utils/length_cdf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/scripts/vllm_infer.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/setup.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/api.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/api/app.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/api/chat.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/api/common.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/api/protocol.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/chat/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/chat/base_engine.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/chat/chat_model.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/chat/hf_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/chat/kt_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/chat/sglang_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/chat/vllm_engine.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/cli.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/data/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/data/collator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/data/converter.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/data/data_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/data/formatter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/data/loader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/data/mm_plugin.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/data/parser.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/data/processor/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/data/processor/feedback.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/data/processor/pairwise.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/data/processor/pretrain.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/data/processor/processor_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/data/processor/supervised.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/data/processor/unsupervised.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/data/template.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/data/tool_utils.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/eval/evaluator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/eval/template.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/extras/constants.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/extras/env.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/extras/logging.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/extras/misc.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/extras/packages.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/extras/ploting.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/hparams/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/hparams/data_args.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/hparams/evaluation_args.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/hparams/finetuning_args.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/hparams/generating_args.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/hparams/model_args.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/hparams/parser.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/hparams/training_args.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/launcher.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/adapter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/loader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/model_utils/attention.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/model_utils/checkpointing.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/model_utils/embedding.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/model_utils/ktransformers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/model_utils/kv_cache.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/model_utils/liger_kernel.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/model_utils/longlora.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/model_utils/misc.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/model_utils/mod.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/model_utils/moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/model_utils/packing.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/model_utils/quantization.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/model_utils/rope.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/model_utils/unsloth.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/model_utils/valuehead.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/model_utils/visual.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/model/patcher.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/third_party/muon/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/third_party/muon/muon.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/callbacks.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/dpo/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/dpo/trainer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/dpo/workflow.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/fp8_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/ksft/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/ksft/workflow.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/kto/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/kto/trainer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/kto/workflow.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/mca/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/mca/trainer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/mca/workflow.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/ppo/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/ppo/ppo_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/ppo/trainer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/ppo/workflow.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/pt/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/pt/trainer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/pt/workflow.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/rm/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/rm/metric.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/rm/trainer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/rm/workflow.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/sft/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/sft/metric.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/sft/trainer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/sft/workflow.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/test_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/trainer_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/train/tuner.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/accelerator/distributed.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/accelerator/helper.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/config/data_args.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/config/model_args.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/config/parser.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/config/sample_args.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/config/training_args.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/core/base_trainer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/core/chat_sampler.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/core/data_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/core/model_worker.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/core/trainer_utils/data_collator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/extras/packages.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/extras/types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/launcher.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/plugins/data_plugins/converter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/plugins/data_plugins/loader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/plugins/data_plugins/template.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/plugins/model_plugins/kernels/constants.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/plugins/model_plugins/kernels/mlp/npu_fused_moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/plugins/model_plugins/kernels/mlp/npu_swiglu.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/plugins/model_plugins/kernels/registry.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/plugins/model_plugins/kernels/rms_norm/npu_rms_norm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/plugins/model_plugins/kernels/rope/npu_rope.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/plugins/trainer_plugins/distributed/accelerate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/v1/trainers/sft_trainer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/chatter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/common.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/components/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/components/chatbot.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/components/data.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/components/eval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/components/export.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/components/footer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/components/infer.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/components/top.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/components/train.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/control.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/css.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/interface.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/locales.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/manager.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/llamafactory/webui/runner.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/train.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/src/webui.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/check_license.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/data/processor/test_feedback.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/data/processor/test_pairwise.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/data/processor/test_processor_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/data/processor/test_supervised.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/data/processor/test_unsupervised.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/data/test_collator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/data/test_converter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/data/test_formatter.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/data/test_loader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/data/test_mm_plugin.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/data/test_template.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/e2e/test_chat.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/e2e/test_sglang.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/e2e/test_train.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/eval/test_eval_template.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/model/model_utils/test_add_tokens.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/model/model_utils/test_attention.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/model/model_utils/test_checkpointing.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/model/model_utils/test_misc.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/model/model_utils/test_packing.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/model/model_utils/test_visual.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/model/test_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/model/test_freeze.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/model/test_full.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/model/test_lora.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/model/test_pissa.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/train/test_sft_trainer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests_v1/core/test_data_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests_v1/plugins/data_plugins/test_converter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hiyouga-LLaMA-Factory-5744f1e/tests_v1/plugins/model_plugins/test_kernel_plugin.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "huggingface/pytorch-image-models": {
    "owner": "huggingface",
    "repo": "pytorch-image-models",
    "ref": "main",
    "num_llm_files": 8,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "huggingface-pytorch-image-models-d66283d/timm/data/constants.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-pytorch-image-models-d66283d/timm/layers/attention_pool2d.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-pytorch-image-models-d66283d/timm/models/byobnet.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-pytorch-image-models-d66283d/timm/models/convnext.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-pytorch-image-models-d66283d/timm/models/eva.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-pytorch-image-models-d66283d/timm/models/fastvit.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-pytorch-image-models-d66283d/timm/models/vision_transformer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-pytorch-image-models-d66283d/timm/models/vitamin.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "huggingface/peft": {
    "owner": "huggingface",
    "repo": "peft",
    "ref": "main",
    "num_llm_files": 52,
    "providers": [
      "llama",
      "mistral",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "huggingface-peft-f2c0668/examples/alora_finetuning/alora_finetuning.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/corda_finetuning/datautils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/corda_finetuning/preprocess.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/delora_finetuning/delora_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/dora_finetuning/dora_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/ephemeral_gpu_offloading/load_with_dora.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/eva_finetuning/eva_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/eva_finetuning/eva_finetuning_multi_accelerator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/gralora_finetuning/gralora_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/loftq_finetuning/quantize_save_load.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/lorafa_finetune/lorafa_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/olora_finetuning/olora_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/pissa_finetuning/pissa_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/qalora_finetuning/qalora_gptq_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/randlora_finetuning/randlora_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/road_finetuning/road_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/shira_finetuning/shira_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/waveft_finetuning/waveft_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/examples/xlora/xlora_inference_mistralrs.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/method_comparison/MetaMathQA/data.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/method_comparison/MetaMathQA/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/method_comparison/MetaMathQA/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/src/peft/helpers.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/src/peft/peft_model.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/src/peft/tuners/adaption_prompt/config.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/src/peft/tuners/adaption_prompt/layer.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/src/peft/tuners/adaption_prompt/model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/src/peft/tuners/adaption_prompt/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/src/peft/tuners/fourierft/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/src/peft/tuners/ln_tuning/model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/src/peft/tuners/lora/config.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/src/peft/tuners/road/config.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/src/peft/tuners/road/layer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/src/peft/tuners/tuners_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/src/peft/tuners/xlora/model.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/src/peft/utils/constants.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/src/peft/utils/other.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/tests/test_adaption_prompt.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/tests/test_common_gpu.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/tests/test_decoder_models.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/tests/test_gptqmodel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/tests/test_gpu_examples.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/tests/test_initialization.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/tests/test_lora_variants.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/tests/test_low_level_api.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/tests/test_multitask_prompt_tuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/tests/test_other.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/tests/test_seq_classifier.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/tests/test_target_parameters.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/tests/test_trainable_tokens.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/tests/test_tuners_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-peft-f2c0668/tests/testing_common.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "huggingface/trl": {
    "owner": "huggingface",
    "repo": "trl",
    "ref": "main",
    "num_llm_files": 67,
    "providers": [
      "anthropic",
      "cohere",
      "llama",
      "mistral",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "huggingface-trl-d401a42/examples/datasets/hh-rlhf-helpful-base.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/datasets/lm-human-preferences-descriptiveness.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/datasets/lm-human-preferences-sentiment.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/datasets/prm800k.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/datasets/tldr.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/datasets/tldr_preference.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/datasets/ultrafeedback.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/scripts/bco.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/scripts/evals/judge_tldr.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/scripts/grpo_vlm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/scripts/nash_md.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/scripts/online_dpo.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/scripts/online_dpo_vlm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/scripts/openenv/browsergym.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/scripts/openenv/catch.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/scripts/openenv/echo.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/scripts/openenv/wordle.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/scripts/rloo.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/scripts/rloo_vlm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/scripts/sft_gpt_oss.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/scripts/sft_vlm.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/examples/scripts/xpo.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/scripts/generate_tiny_models.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/tests/experimental/test_gold_trainer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/tests/experimental/test_online_dpo_trainer.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/tests/test_data_utils.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/tests/test_dataset_formatting.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/tests/test_dpo_trainer.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/tests/test_grpo_trainer.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/tests/test_modeling_value_head.py",
        "providers": [
          "cohere",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/tests/test_reward_trainer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/tests/test_rloo_trainer.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/tests/test_sft_trainer.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/tests/test_vllm_client_server.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/tests/testing_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/__init__.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/cli.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/data_utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/experimental/bco/bco_trainer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/experimental/cpo/cpo_trainer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/experimental/gfpo/gfpo_trainer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/experimental/gkd/gkd_trainer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/experimental/gold/gold.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/experimental/gold/gold_config.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/experimental/gold/gold_trainer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/experimental/grpo_with_replay_buffer/grpo_with_replay_buffer_trainer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/experimental/gspo_token/grpo_trainer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/experimental/judges/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/experimental/judges/judges.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/experimental/online_dpo/online_dpo_config.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/experimental/online_dpo/online_dpo_trainer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/experimental/openenv/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/experimental/orpo/orpo_trainer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/extras/vllm_client.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/import_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/models/utils.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/scripts/env.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/scripts/vllm_serve.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/trainer/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/trainer/grpo_config.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/trainer/grpo_trainer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/trainer/judges.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/trainer/kto_trainer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/trainer/rloo_config.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/trainer/rloo_trainer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/trainer/sft_trainer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-trl-d401a42/trl/trainer/utils.py",
        "providers": [
          "mistral"
        ]
      }
    ],
    "error": null
  },
  "fighting41love/funNLP": {
    "owner": "fighting41love",
    "repo": "funNLP",
    "ref": "master",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "iMagist486/ElasticSearch-Langchain-Chatglm2": {
    "owner": "iMagist486",
    "repo": "ElasticSearch-Langchain-Chatglm2",
    "ref": "304d3d204a00782a0078fd76be232fa5802f4307",
    "num_llm_files": 3,
    "providers": [
      "langchain"
    ],
    "files": [
      {
        "file_path": "iMagist486-ElasticSearch-Langchain-Chatglm2-304d3d2/doc_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "iMagist486-ElasticSearch-Langchain-Chatglm2-304d3d2/model/chatglm_llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "iMagist486-ElasticSearch-Langchain-Chatglm2-304d3d2/web.py",
        "providers": [
          "langchain"
        ]
      }
    ],
    "error": null
  },
  "imartinez/privateGPT": {
    "owner": "imartinez",
    "repo": "privateGPT",
    "ref": "2f3aab9cfdc139f399387dbb90300d5a8bf8d2f1",
    "num_llm_files": 2,
    "providers": [
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "zylon-ai-private-gpt-2f3aab9/ingest.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "zylon-ai-private-gpt-2f3aab9/privateGPT.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "intel/ipex-llm": {
    "owner": "intel",
    "repo": "ipex-llm",
    "ref": "main",
    "num_llm_files": 291,
    "providers": [
      "cohere",
      "langchain",
      "llama",
      "mistral",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "intel-ipex-llm-197f653/docker/llm/finetune/lora/cpu/docker/lora_finetune.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/docker/llm/serving/cpu/docker/benchmark_vllm_throughput.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/docker/llm/serving/cpu/docker/vllm_offline_inference.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/docker/llm/serving/xpu/docker/audio_language.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/docker/llm/serving/xpu/docker/benchmark_vllm_latency.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/docker/llm/serving/xpu/docker/benchmark_vllm_throughput.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/docker/llm/serving/xpu/docker/vllm_offline_inference.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/docker/llm/serving/xpu/docker/vllm_offline_inference_vision_language.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/docker/llm/serving/xpu/docker/vllm_online_benchmark.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/docker/llm/serving/xpu/docker/vllm_online_benchmark_multimodal.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/dev/benchmark/LongBench/pred.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/dev/benchmark/all-in-one/run-stress-test.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/dev/benchmark/all-in-one/run.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/dev/benchmark/all-in-one/save.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/dev/benchmark/ceval/eval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/dev/benchmark/ceval/evaluators/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/dev/benchmark/ceval/organize_results.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/dev/benchmark/harness/run_llb.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/dev/benchmark/harness/run_multi_llb.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/dev/print_glib_requirement.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/Applications/autogen/teachability_new_knowledge.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/Applications/streaming-llm/run_streaming_llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/Applications/streaming-llm/streaming_llm/enable_streaming_llm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/Applications/streaming-llm/streaming_llm/modify_llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/Applications/streaming-llm/streaming_llm/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/Deepspeed-AutoTP/deepspeed_autotp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Advanced-Quantizations/AWQ/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Advanced-Quantizations/GGUF/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Advanced-Quantizations/GPTQ/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Model/codellama/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Model/cohere/generate.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Model/deepseek-moe/modeling_deepseek.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Model/deepseek_v3/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Model/llama2/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Model/llama3.1/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Model/llama3/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Model/mistral/generate.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Model/mixtral/generate.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Model/qwen-vl/chat.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Model/vicuna/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Model/whisper/long-segment-recognize.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Model/whisper/recognize.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Model/wizardcoder-python/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Model/yuan2/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Model/yuan2/yuan2-2B-instruct/yuan_hf_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/More-Data-Types/transformers_low_bit_pipeline.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/HF-Transformers-AutoModels/Save-Load/transformers_low_bit_pipeline.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/LangChain/chat.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/LangChain/llm_math.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/LangChain/low_bit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/LangChain/rag.py",
        "providers": [
          "langchain",
          "llama",
          "mistral",
          "ollama",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/LangChain/voiceassistant.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/LlamaIndex/rag.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/Native-Models/native_int4_pipeline.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/PyTorch-Models/Model/aquila2/generate.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/PyTorch-Models/Model/codellama/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/PyTorch-Models/Model/cohere/generate.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/PyTorch-Models/Model/llama2/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/PyTorch-Models/Model/llama3/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/PyTorch-Models/Model/llava/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/PyTorch-Models/Model/mamba/model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/PyTorch-Models/Model/meta-llama/example_chat_completion.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/PyTorch-Models/Model/meta-llama/example_text_completion.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/PyTorch-Models/Model/mistral/generate.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/PyTorch-Models/Model/mixtral/generate.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/PyTorch-Models/Model/openai-whisper/recognize.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/PyTorch-Models/Model/wizardcoder-python/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/PyTorch-Models/Model/yuan2/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/PyTorch-Models/Model/yuan2/yuan2-2B-instruct/yuan_hf_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/PyTorch-Models/More-Data-Types/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/PyTorch-Models/Save-Load/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/QLoRA-FineTuning/alpaca-qlora/alpaca_qlora_finetuning_cpu.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/QLoRA-FineTuning/qlora_finetuning_cpu.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/Speculative-Decoding/EAGLE/evaluation/gen_ea_answer_llama2chat.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/Speculative-Decoding/EAGLE/evaluation/speed.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/Speculative-Decoding/Self-Speculation/chatglm3/speculative.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/Speculative-Decoding/Self-Speculation/llama2/speculative.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/Speculative-Decoding/Self-Speculation/llama3/speculative.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/Speculative-Decoding/Self-Speculation/mistral/speculative.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/Speculative-Decoding/Self-Speculation/mixtral/speculative.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/Speculative-Decoding/Self-Speculation/starcoder/speculative.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/Speculative-Decoding/Self-Speculation/ziya/speculative.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/CPU/vLLM-Serving/offline_inference.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/Applications/autogen/teachability_new_knowledge.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/Applications/streaming-llm/run_streaming_llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/DeepSeek-R1/benchmark.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/DeepSeek-R1/generate_hybrid.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/Deepspeed-AutoTP-FastAPI/serving.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/Deepspeed-AutoTP/deepspeed_autotp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/Advanced-Quantizations/AWQ/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/Advanced-Quantizations/GGUF-IQ2/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/Advanced-Quantizations/GGUF/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/Advanced-Quantizations/GPTQ/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/LLM/chinese-llama2/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/LLM/codellama/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/LLM/cohere/generate.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/LLM/llama2/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/LLM/llama3.1/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/LLM/llama3.2/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/LLM/llama3/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/LLM/mistral/generate.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/LLM/mixtral/generate.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/LLM/vicuna/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/LLM/yuan2/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/LLM/yuan2/yuan2-2B-instruct/yuan_hf_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/More-Data-Types/transformers_low_bit_pipeline.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/Multimodal/MiniCPM-Llama3-V-2_5/chat.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/Multimodal/voiceassistant/generate.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/Multimodal/whisper/recognize.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/HuggingFace/Save-Load/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/DPO/dpo_finetuning.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/DPO/export_merged_model.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/GaLore/galore_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/HF-PEFT/alpaca-lora/finetune.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/LISA/lisa_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/LoRA/alpaca_lora_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/LoRA/export_merged_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/QA-LoRA/alpaca_qalora_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/QA-LoRA/export_merged_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/QLoRA/alpaca-qlora/alpaca_qlora_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/QLoRA/alpaca-qlora/export_merged_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/QLoRA/alpaca-qlora/save_low_bit_70b_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/QLoRA/simple-example/export_merged_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/QLoRA/simple-example/qlora_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/QLoRA/trl-example/export_merged_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/QLoRA/trl-example/qlora_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/ReLora/alpaca_relora_finetuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LLM-Finetuning/ReLora/export_merged_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LangChain/chat.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LangChain/low_bit.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LangChain/rag.py",
        "providers": [
          "langchain",
          "llama",
          "mistral",
          "ollama",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/Lightweight-Serving/lightweight_serving.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/LlamaIndex/rag.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/Long-Context/LLaMA2-32K/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/Lookahead/llama2/lookahead.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/Pipeline-Parallel-Inference/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/Pipeline-Parallel-Serving/benchmark.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/Pipeline-Parallel-Serving/gradio_webui.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/Pipeline-Parallel-Serving/pipeline_serving.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/PyTorch-Models/Model/codellama/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/PyTorch-Models/Model/cohere/generate.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/PyTorch-Models/Model/llama2/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/PyTorch-Models/Model/llama2/low_memory_generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/PyTorch-Models/Model/llama3.2-vision/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/PyTorch-Models/Model/llama3/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/PyTorch-Models/Model/mamba/model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/PyTorch-Models/Model/mistral/generate.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/PyTorch-Models/Model/mixtral/generate.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/PyTorch-Models/Model/openai-whisper/recognize.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/PyTorch-Models/Model/yuan2/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/PyTorch-Models/Model/yuan2/yuan2-2B-instruct/yuan_hf_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/PyTorch-Models/More-Data-Types/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/PyTorch-Models/Save-Load/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/Speculative-Decoding/EAGLE/evaluation/gen_ea_answer_llama2chat_e2_ipex_optimize.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/Speculative-Decoding/EAGLE/evaluation/speed.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/Speculative-Decoding/Self-Speculation/chatglm3/speculative.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/Speculative-Decoding/Self-Speculation/llama2/speculative.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/Speculative-Decoding/Self-Speculation/mistral/speculative.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/GPU/vLLM-Serving/offline_inference.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/NPU/HF-Transformers-AutoModels/LLM/CPP_Examples/convert.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/NPU/HF-Transformers-AutoModels/LLM/llama2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/NPU/HF-Transformers-AutoModels/LLM/llama3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/NPU/HF-Transformers-AutoModels/Multimodal/minicpm-llama3-v2.5.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/example/NPU/HF-Transformers-AutoModels/Save-Load/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/portable-zip/chat.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/setup.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/convert_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/ggml/convert.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/ggml/convert_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/ggml/model/bloom/bloom.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/ggml/model/bloom/bloom_cpp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/ggml/model/generation/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/ggml/model/gptneox/gptneox.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/ggml/model/gptneox/gptneox_cpp.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/ggml/model/gptneox/gptneox_types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/ggml/model/llama/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/ggml/model/llama/llama.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/ggml/model/llama/llama_cpp.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/ggml/model/llama/llama_types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/ggml/model/starcoder/starcoder.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/ggml/model/starcoder/starcoder_cpp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/ggml/quantize.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/gptq/convert/convert_gptq_to_ggml.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/langchain/embeddings/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/langchain/embeddings/bigdlllm.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/langchain/embeddings/transformersembeddings.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/langchain/llms/__init__.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/langchain/llms/bigdlllm.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/langchain/llms/transformersllm.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/langchain/llms/transformerspipelinellm.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/langchain/vllm/vllm.py",
        "providers": [
          "langchain",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/llamaindex/llms/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/llamaindex/llms/bigdlllm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/llm_patching.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/models.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/optimize.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/serving/fastapi/api_server.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/serving/fastapi/openai_protocol.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/serving/fastchat/bigdl_llm_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/serving/fastchat/ipex_llm_worker.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/serving/fastchat/model_worker.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/serving/fastchat/tgi_api_server.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/serving/fastchat/vllm_worker.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/awq/awq.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/convert.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/convert_ipex.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/gguf/api.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/gguf/gguf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/gguf/models/baichuan.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/gguf/models/bloom.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/gguf/models/falcon.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/gguf/models/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/gguf/models/mistral.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/gguf/models/mixtral.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/gguf/models/model_implement/yuan2/yuan_hf_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/gguf/models/yuan2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/kv.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/lisa.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/loader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/low_bit_linear.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/modelling_bigdl.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/models/decilm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/models/deepseek_v3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/models/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/models/minicpm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/models/mistral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/models/mllama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/models/phixtral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/models/qwen_vl.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/models/utils.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/models/whisper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_models/baichuan.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_models/baichuan_mp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_models/common.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_models/convert.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_models/convert_mp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_models/glm_edge.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_models/kv.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_models/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_models/llama_mp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_models/minicpm_mp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_models/mistral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_models/paraformer_mp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_models/phi3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_models/phi3_v.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_models/stablelm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_models/xlm_mp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_pipeline_model/common.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_pipeline_model/convert_pipeline.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/npu_pipeline_model/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/pipeline_parallel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/relora.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/speculative.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/transformers/utils.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/utils/benchmark_util_4_42.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/utils/benchmark_util_4_43.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/utils/benchmark_util_4_44.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/utils/benchmark_util_4_45.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/utils/benchmark_util_4_47.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/utils/benchmark_util_deepseek.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/utils/convert_util.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/utils/lazy_load_torch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/vllm/cpu/engine/engine.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/vllm/cpu/entrypoints/api_server.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/vllm/cpu/entrypoints/openai/api_server.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/vllm/cpu/entrypoints/openai/cli_args.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/vllm/cpu/ipex_llm_v1_wrapper.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/vllm/cpu/ipex_llm_wrapper.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/vllm/cpu/model_convert.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/vllm/xpu/engine/engine.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/vllm/xpu/entrypoints/openai/api_server.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/vllm/xpu/entrypoints/openai/cli_args.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/vllm/xpu/ipex_llm_v1_wrapper.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/vllm/xpu/ipex_llm_wrapper.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/src/ipex_llm/vllm/xpu/model_convert.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/test/convert/test_convert_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/test/inference/test_call_models.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/test/inference/test_transformers_api.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/test/inference_gpu/test_transformers_api.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/test/inference_gpu/test_transformers_api_RMSNorm.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/test/inference_gpu/test_transformers_api_attention.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/test/inference_gpu/test_transformers_api_final_logits.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/test/inference_gpu/test_transformers_api_mlp.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/test/langchain/test_langchain.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/test/langchain/test_transformers_api.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/test/langchain_gpu/test_transformers_api.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/test/llamaindex/test_llamaindex.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/test/llamaindex_gpu/test_llamaindex.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "intel-ipex-llm-197f653/python/llm/test/win/download_from_huggingface.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "huggingface/transformers": {
    "owner": "huggingface",
    "repo": "transformers",
    "ref": "main",
    "num_llm_files": 692,
    "providers": [
      "cohere",
      "gemini",
      "llama",
      "mistral",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "huggingface-transformers-2db992d/benchmark/benches/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/conftest.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/3D_parallel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/modular-transformers/configuration_duplicated_method.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/modular-transformers/configuration_my_new_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/modular-transformers/image_processing_new_imgproc_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/modular-transformers/modeling_add_function.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/modular-transformers/modeling_multimodal2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/modular-transformers/modeling_my_new_model2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/modular-transformers/modeling_switch_function.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/modular-transformers/modular_add_function.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/modular-transformers/modular_duplicated_method.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/modular-transformers/modular_global_indexing.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/modular-transformers/modular_my_new_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/modular-transformers/modular_my_new_model2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/modular-transformers/modular_super.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/modular-transformers/modular_switch_function.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/pytorch/3d_parallel_checks.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/pytorch/continuous_batching.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/pytorch/continuous_batching_simple.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/pytorch/test_pytorch_examples.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/pytorch/text-generation/run_generation.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/examples/quantization/custom_quantization_int8_example.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/setup.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/__init__.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/activations.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/cache_utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/cli/add_new_model_like.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/cli/chat.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/cli/serve.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/configuration_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/conversion_mapping.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/convert_slow_tokenizer.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/convert_slow_tokenizers_checkpoints_to_fast.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/core_model_loading.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/dependency_versions_table.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/generation/candidate_generator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/generation/configuration_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/generation/continuous_batching/cache.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/generation/logits_process.py",
        "providers": [
          "cohere",
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/generation/streamers.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/generation/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/generation/watermarking.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/image_processing_base.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/image_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/integrations/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/integrations/awq.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/integrations/bitnet.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/integrations/bitsandbytes.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/integrations/fbgemm_fp8.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/integrations/ggml.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/integrations/hub_kernels.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/integrations/mistral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/integrations/mxfp4.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/integrations/tensor_parallel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/masking_utils.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/modeling_gguf_pytorch_utils.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/modeling_rope_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/modeling_utils.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/__init__.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/afmoe/modeling_afmoe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/afmoe/modular_afmoe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/aimv2/modeling_aimv2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/aimv2/modular_aimv2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/apertus/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/apertus/configuration_apertus.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/apertus/modular_apertus.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/arcee/modular_arcee.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/aria/configuration_aria.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/aria/convert_aria_weights_to_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/aria/modeling_aria.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/aria/modular_aria.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/aria/processing_aria.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/auto/configuration_auto.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/auto/image_processing_auto.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "ollama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/auto/modeling_auto.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/auto/processing_auto.py",
        "providers": [
          "cohere",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/auto/tokenization_auto.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/auto/video_processing_auto.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/aya_vision/configuration_aya_vision.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/aya_vision/modeling_aya_vision.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/aya_vision/modular_aya_vision.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/bamba/modular_bamba.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/bit/image_processing_bit.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/bit/image_processing_bit_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/bitnet/modeling_bitnet.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/bitnet/modular_bitnet.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/blip/image_processing_blip.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/blip/image_processing_blip_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/blip_2/convert_blip_2_original_to_pytorch.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/blt/modeling_blt.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/blt/modular_blt.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/bridgetower/image_processing_bridgetower.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/bridgetower/image_processing_bridgetower_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/chameleon/convert_chameleon_weights_to_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/chameleon/modeling_chameleon.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/chameleon/processing_chameleon.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/chinese_clip/image_processing_chinese_clip.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/chinese_clip/image_processing_chinese_clip_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/clip/configuration_clip.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/clip/convert_clip_original_pytorch_to_hf.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/clip/image_processing_clip.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/clip/image_processing_clip_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/clip/modeling_clip.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/clipseg/convert_clipseg_original_pytorch_to_hf.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/clipseg/modeling_clipseg.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/clvp/modeling_clvp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/code_llama/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/code_llama/tokenization_code_llama.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cohere/__init__.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cohere/configuration_cohere.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cohere/modeling_cohere.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cohere/modular_cohere.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cohere/tokenization_cohere.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cohere2/__init__.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cohere2/configuration_cohere2.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cohere2/modeling_cohere2.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cohere2/modular_cohere2.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cohere2_vision/__init__.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cohere2_vision/configuration_cohere2_vision.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cohere2_vision/image_processing_cohere2_vision_fast.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cohere2_vision/modeling_cohere2_vision.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cohere2_vision/modular_cohere2_vision.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cohere2_vision/processing_cohere2_vision.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/colpali/modular_colpali.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/colpali/processing_colpali.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/csm/convert_csm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/csm/modeling_csm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/csm/modular_csm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/ctrl/modeling_ctrl.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cwm/configuration_cwm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cwm/modeling_cwm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/cwm/modular_cwm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/dab_detr/convert_dab_detr_original_pytorch_checkpoint_to_pytorch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/dbrx/modeling_dbrx.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/dbrx/modular_dbrx.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/decision_transformer/modeling_decision_transformer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/deepseek_v2/modular_deepseek_v2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/deepseek_v3/modular_deepseek_v3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/deepseek_vl/configuration_deepseek_vl.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/deepseek_vl/convert_deepseek_vl_weights_to_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/deepseek_vl/image_processing_deepseek_vl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/deepseek_vl/image_processing_deepseek_vl_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/deepseek_vl/modeling_deepseek_vl.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/deepseek_vl/modular_deepseek_vl.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/deepseek_vl/processing_deepseek_vl.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/deepseek_vl_hybrid/configuration_deepseek_vl_hybrid.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/deepseek_vl_hybrid/convert_deepseek_vl_hybrid_weights_to_hf.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/deepseek_vl_hybrid/image_processing_deepseek_vl_hybrid.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/deepseek_vl_hybrid/image_processing_deepseek_vl_hybrid_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/deepseek_vl_hybrid/modeling_deepseek_vl_hybrid.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/deepseek_vl_hybrid/modular_deepseek_vl_hybrid.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/deepseek_vl_hybrid/processing_deepseek_vl_hybrid.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/dia/modular_dia.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/diffllama/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/diffllama/configuration_diffllama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/diffllama/modeling_diffllama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/diffllama/modular_diffllama.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/dinov3_vit/modular_dinov3_vit.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/doge/modeling_doge.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/doge/modular_doge.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/dots1/modeling_dots1.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/edgetam_video/modeling_edgetam_video.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/efficientloftr/modeling_efficientloftr.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/emu3/convert_emu3_weights_to_hf.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/emu3/image_processing_emu3.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/emu3/modular_emu3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/ernie4_5/convert_ernie4_5_tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/ernie4_5/modular_ernie4_5.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/ernie4_5_moe/modeling_ernie4_5_moe.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/ernie4_5_moe/modular_ernie4_5_moe.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/evolla/configuration_evolla.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/evolla/modular_evolla.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/evolla/processing_evolla.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/exaone4/configuration_exaone4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/exaone4/modular_exaone4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/falcon/modeling_falcon.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/falcon_h1/modular_falcon_h1.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/falcon_mamba/modeling_falcon_mamba.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/flava/image_processing_flava.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/flava/modeling_flava.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/flex_olmo/modeling_flex_olmo.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/flex_olmo/modular_flex_olmo.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/florence2/modular_florence2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/fuyu/convert_fuyu_model_weights_to_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/fuyu/processing_fuyu.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gemma/modeling_gemma.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gemma/modular_gemma.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gemma2/modeling_gemma2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gemma3/convert_gemma3_weights.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gemma3/modeling_gemma3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gemma3n/convert_gemma3n_weights.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gemma3n/modeling_gemma3n.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gemma3n/modular_gemma3n.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/glm/modular_glm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/glm46v/image_processing_glm46v.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/glm46v/image_processing_glm46v_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/glm46v/video_processing_glm46v.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/glm4_moe/modeling_glm4_moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/glm4_moe/modular_glm4_moe.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/glm4v/convert_glm4v_mgt_weights_to_hf.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/glm4v/image_processing_glm4v.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/glm4v/image_processing_glm4v_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/glm4v/modeling_glm4v.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/glm4v/modular_glm4v.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/glm4v/video_processing_glm4v.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/glm4v_moe/convert_glm4v_moe_mgt_weights_to_hf.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/glm4v_moe/modeling_glm4v_moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/glm4v_moe/modular_glm4v_moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/got_ocr2/configuration_got_ocr2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/got_ocr2/convert_got_ocr2_weights_to_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/got_ocr2/image_processing_got_ocr2.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/got_ocr2/image_processing_got_ocr2_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/got_ocr2/modular_got_ocr2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gpt2/configuration_gpt2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gpt2/convert_gpt2_original_tf_checkpoint_to_pytorch.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gpt2/modeling_gpt2.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gpt2/tokenization_gpt2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gpt_neo/modeling_gpt_neo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gpt_neox/modular_gpt_neox.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gpt_neox_japanese/modeling_gpt_neox_japanese.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gpt_oss/configuration_gpt_oss.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gpt_oss/convert_gpt_oss_weights_to_hf.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gpt_oss/modeling_gpt_oss.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gpt_oss/modular_gpt_oss.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/gptj/modeling_gptj.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/granite/modeling_granite.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/granite/modular_granite.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/granite_speech/processing_granite_speech.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/granitemoe/modeling_granitemoe.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/granitemoe/modular_granitemoe.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/granitemoehybrid/modeling_granitemoehybrid.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/granitemoeshared/modeling_granitemoeshared.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/groupvit/convert_groupvit_nvlab_to_hf.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/groupvit/modeling_groupvit.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/helium/modular_helium.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/hunyuan_v1_dense/modeling_hunyuan_v1_dense.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/hunyuan_v1_dense/modular_hunyuan_v1_dense.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/hunyuan_v1_moe/modeling_hunyuan_v1_moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/hunyuan_v1_moe/modular_hunyuan_v1_moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/idefics/modeling_idefics.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/idefics/processing_idefics.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/idefics/vision.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/idefics2/configuration_idefics2.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/idefics2/convert_idefics2_weights_to_hf.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/idefics2/modeling_idefics2.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/idefics2/processing_idefics2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/idefics3/configuration_idefics3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/idefics3/convert_idefics3_weights_to_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/idefics3/modeling_idefics3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/idefics3/processing_idefics3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/imagegpt/configuration_imagegpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/imagegpt/convert_imagegpt_original_tf2_to_pytorch.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/imagegpt/modeling_imagegpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/instructblip/convert_instructblip_original_to_pytorch.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/instructblip/processing_instructblip.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/instructblipvideo/convert_instructblipvideo_original_to_pytorch.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/instructblipvideo/processing_instructblipvideo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/instructblipvideo/video_processing_instructblipvideo.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/internvl/convert_internvl_weights_to_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/internvl/modular_internvl.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/internvl/video_processing_internvl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/jamba/modular_jamba.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/janus/configuration_janus.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/janus/convert_janus_weights_to_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/janus/image_processing_janus.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/janus/image_processing_janus_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/janus/modeling_janus.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/janus/modular_janus.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/janus/processing_janus.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/jetmoe/modeling_jetmoe.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/jetmoe/modular_jetmoe.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/kosmos2_5/modeling_kosmos2_5.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/kyutai_speech_to_text/modular_kyutai_speech_to_text.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/lasr/configuration_lasr.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/lasr/modular_lasr.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/lfm2/configuration_lfm2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/lfm2/modular_lfm2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/lfm2_moe/configuration_lfm2_moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/lfm2_moe/modular_lfm2_moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/lightglue/modeling_lightglue.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/lightglue/modular_lightglue.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llama/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llama/configuration_llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llama/convert_llama_weights_to_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llama/modeling_llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llama/tokenization_llama.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llama4/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llama4/configuration_llama4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llama4/convert_llama4_weights_to_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llama4/image_processing_llama4_fast.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llama4/modeling_llama4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llama4/processing_llama4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava/configuration_llava.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava/convert_llava_weights_to_hf.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava/image_processing_llava.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava/image_processing_llava_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava/processing_llava.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_next/configuration_llava_next.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_next/convert_llava_next_weights_to_hf.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_next/image_processing_llava_next.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_next/image_processing_llava_next_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_next/modeling_llava_next.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_next/processing_llava_next.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_next_video/configuration_llava_next_video.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_next_video/convert_llava_next_video_weights_to_hf.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_next_video/modeling_llava_next_video.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_next_video/modular_llava_next_video.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_next_video/processing_llava_next_video.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_next_video/video_processing_llava_next_video.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_onevision/configuration_llava_onevision.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_onevision/image_processing_llava_onevision.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_onevision/image_processing_llava_onevision_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_onevision/modeling_llava_onevision.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_onevision/modular_llava_onevision.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_onevision/processing_llava_onevision.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/llava_onevision/video_processing_llava_onevision.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/lxmert/modeling_lxmert.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mamba/modeling_mamba.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mamba2/convert_mamba2_ssm_checkpoint_to_pytorch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mamba2/modeling_mamba2.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/megatron_gpt2/convert_megatron_gpt2_checkpoint.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/metaclip_2/configuration_metaclip_2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mgp_str/processing_mgp_str.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mimi/modeling_mimi.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/minimax/modeling_minimax.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/ministral/__init__.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/ministral/configuration_ministral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/ministral/modeling_ministral.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/ministral/modular_ministral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/ministral3/__init__.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/ministral3/configuration_ministral3.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/ministral3/convert_ministral3_weights_to_hf.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/ministral3/modeling_ministral3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/ministral3/modular_ministral3.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mistral/__init__.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mistral/configuration_mistral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mistral/convert_mistral_weights_to_hf.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mistral/modeling_mistral.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mistral/modular_mistral.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mistral3/__init__.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mistral3/configuration_mistral3.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mistral3/convert_mistral3_weights_to_hf.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mistral3/modeling_mistral3.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mistral3/modular_mistral3.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mixtral/convert_mixtral_weights_to_hf.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mixtral/modeling_mixtral.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mixtral/modular_mixtral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mlcd/modular_mlcd.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mllama/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mllama/configuration_mllama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mllama/convert_mllama_weights_to_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mllama/image_processing_mllama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mllama/image_processing_mllama_fast.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mllama/modeling_mllama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/mllama/processing_mllama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/moonshine/modular_moonshine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/moshi/modeling_moshi.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/nanochat/modular_nanochat.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/nemotron/convert_nemotron_nemo_to_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/nemotron/modeling_nemotron.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/olmo/modular_olmo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/olmo2/modular_olmo2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/olmoe/modeling_olmoe.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/olmoe/modular_olmoe.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/omdet_turbo/convert_omdet_turbo_to_hf.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/openai/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/openai/configuration_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/openai/convert_openai_original_tf_checkpoint_to_pytorch.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/openai/modeling_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/openai/tokenization_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/ovis2/image_processing_ovis2.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/ovis2/image_processing_ovis2_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/ovis2/modular_ovis2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/owlv2/convert_owlv2_to_hf.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/owlv2/image_processing_owlv2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/owlv2/image_processing_owlv2_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/owlv2/modeling_owlv2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/owlv2/modular_owlv2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/owlvit/convert_owlvit_original_flax_to_hf.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/owlvit/image_processing_owlvit.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/owlvit/image_processing_owlvit_fast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/owlvit/modeling_owlvit.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/paligemma/configuration_paligemma.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/parakeet/configuration_parakeet.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/parakeet/modular_parakeet.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/perception_lm/configuration_perception_lm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/perception_lm/convert_perception_lm_weights_to_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/perception_lm/image_processing_perception_lm_fast.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/perception_lm/processing_perception_lm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/persimmon/convert_persimmon_weights_to_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/persimmon/modeling_persimmon.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/phi/modeling_phi.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/phi/modular_phi.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/phi3/modeling_phi3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/phi3/modular_phi3.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/phi4_multimodal/modeling_phi4_multimodal.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/phimoe/modeling_phimoe.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/phimoe/modular_phimoe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/pixtral/convert_pixtral_weights_to_hf.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/pixtral/modeling_pixtral.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/pixtral/processing_pixtral.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen2/modeling_qwen2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen2/modular_qwen2.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen2_5_omni/configuration_qwen2_5_omni.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen2_5_omni/modular_qwen2_5_omni.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen2_audio/configuration_qwen2_audio.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen2_moe/modeling_qwen2_moe.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen2_moe/modular_qwen2_moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen2_vl/image_processing_qwen2_vl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen2_vl/image_processing_qwen2_vl_fast.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen2_vl/video_processing_qwen2_vl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen3/modeling_qwen3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen3/modular_qwen3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen3_moe/modeling_qwen3_moe.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen3_moe/modular_qwen3_moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen3_next/modeling_qwen3_next.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen3_next/modular_qwen3_next.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen3_omni_moe/configuration_qwen3_omni_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen3_omni_moe/modeling_qwen3_omni_moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen3_omni_moe/modular_qwen3_omni_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen3_vl/modular_qwen3_vl.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/qwen3_vl/processing_qwen3_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/rwkv/configuration_rwkv.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/sam2_video/modeling_sam2_video.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/sam2_video/modular_sam2_video.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/sam3/convert_sam3_to_hf.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/sam3/modeling_sam3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/sam3_tracker_video/modeling_sam3_tracker_video.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/sam3_video/convert_sam3_video_to_hf.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/seamless_m4t/convert_fairseq2_to_hf.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/seamless_m4t_v2/convert_fairseq2_to_hf.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/seed_oss/modular_seed_oss.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/shieldgemma2/convert_shieldgemma2_weights_orbax_to_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/siglip/configuration_siglip.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/siglip/convert_siglip_to_hf.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/siglip2/configuration_siglip2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/smollm3/modular_smollm3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/smolvlm/configuration_smolvlm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/smolvlm/modeling_smolvlm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/smolvlm/modular_smolvlm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/smolvlm/processing_smolvlm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/stablelm/modeling_stablelm.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/starcoder2/modeling_starcoder2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/starcoder2/modular_starcoder2.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/t5gemma/modeling_t5gemma.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/t5gemma2/modeling_t5gemma2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/timesfm/modular_timesfm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/vaultgemma/modeling_vaultgemma.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/video_llama_3/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/video_llama_3/configuration_video_llama_3.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/video_llama_3/image_processing_video_llama_3.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/video_llama_3/image_processing_video_llama_3_fast.py",
        "providers": [
          "llama",
          "ollama",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/video_llama_3/modeling_video_llama_3.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/video_llama_3/modular_video_llama_3.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/video_llama_3/processing_video_llama_3.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/video_llama_3/video_processing_video_llama_3.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/video_llava/configuration_video_llava.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/video_llava/convert_video_llava_weights_to_hf.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/video_llava/image_processing_video_llava.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/video_llava/processing_video_llava.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/video_llava/video_processing_video_llava.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/vipllava/configuration_vipllava.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/vipllava/convert_vipllava_weights_to_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/voxtral/configuration_voxtral.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/voxtral/convert_voxtral_weights_to_hf.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/voxtral/modeling_voxtral.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/voxtral/modular_voxtral.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/voxtral/processing_voxtral.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/whisper/configuration_whisper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/whisper/convert_openai_to_hf.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/whisper/english_normalizer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/whisper/generation_whisper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/whisper/modeling_whisper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/whisper/tokenization_whisper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/x_clip/convert_x_clip_original_pytorch_to_hf.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/x_clip/modeling_x_clip.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/xlm/convert_xlm_original_pytorch_checkpoint_to_pytorch.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/zamba/modeling_zamba.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/zamba2/modeling_zamba2.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/models/zamba2/modular_zamba2.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/pipelines/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/pipelines/any_to_any.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/pipelines/automatic_speech_recognition.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/pipelines/text_generation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/processing_utils.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/pytorch_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/quantizers/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/quantizers/quantizer_awq.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/quantizers/quantizer_fbgemm_fp8.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/testing_utils.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/tokenization_mistral_common.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/tokenization_utils_base.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/tokenization_utils_tokenizers.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/trainer_pt_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/training_args.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/utils/__init__.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/utils/auto_docstring.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/utils/chat_template_utils.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/utils/constants.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/utils/dummy_mistral_common_objects.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/utils/hub.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/utils/import_utils.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/utils/kernel_config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/src/transformers/utils/quantization_config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/cli/test_serve.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/deepspeed/test_alst_ulysses_sp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/deepspeed/test_model_zoo.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/fsdp/test_context_parallel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/fsdp/test_fsdp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/generation/test_candidate_generator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/generation/test_configuration_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/generation/test_continuous_batching.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/generation/test_flash_attention_parity.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/generation/test_paged_attention.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/generation/test_stopping_criteria.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/generation/test_utils.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/kernels/test_kernels.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/apertus/test_modeling_apertus.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/aria/test_modeling_aria.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/aria/test_processing_aria.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/auto/test_image_processing_auto.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/auto/test_modeling_auto.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/auto/test_processor_auto.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/auto/test_tokenization_auto.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/aya_vision/test_modeling_aya_vision.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/aya_vision/test_processing_aya_vision.py",
        "providers": [
          "cohere",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/chameleon/test_processing_chameleon.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/clip/test_modeling_clip.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/clip/test_processing_clip.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/clip/test_tokenization_clip.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/clipseg/test_modeling_clipseg.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/code_llama/test_tokenization_code_llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/cohere/test_modeling_cohere.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/cohere/test_tokenization_cohere.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/cohere2/test_modeling_cohere2.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/cohere2_vision/test_image_processing_cohere2_vision.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/cohere2_vision/test_modeling_cohere2_vision.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/cohere2_vision/test_processing_cohere2_vision.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/colpali/test_processing_colpali.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/colqwen2/test_processing_colqwen2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/cwm/test_configuration_cwm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/cwm/test_modeling_cwm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/deepseek_v3/test_modeling_deepseek_v3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/diffllama/test_modeling_diffllama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/dots1/test_modeling_dots1.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/emu3/test_processing_emu3.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/encoder_decoder/test_modeling_encoder_decoder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/evolla/test_modeling_evolla.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/evolla/test_processing_evolla.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/fuyu/test_processing_fuyu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/gemma/test_modeling_gemma.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/gemma2/test_modeling_gemma2.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/gemma3/test_modeling_gemma3.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/gemma3/test_processing_gemma3.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/gemma3n/test_modeling_gemma3n.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/glm4_moe/test_modeling_glm4_moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/gpt2/test_modeling_gpt2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/gpt2/test_tokenization_gpt2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/gpt_oss/test_modeling_gpt_oss.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/idefics2/test_modeling_idefics2.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/idefics3/test_modeling_idefics3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/idefics3/test_processing_idefics3.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/imagegpt/test_image_processing_imagegpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/imagegpt/test_modeling_imagegpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/instructblipvideo/test_video_processing_instructblipvideo.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/internvl/test_modeling_internvl.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/internvl/test_processing_internvl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/internvl/test_video_processing_internvl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/janus/test_modeling_janus.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/kyutai_speech_to_text/test_modeling_kyutai_speech_to_text.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/lfm2/test_modeling_lfm2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/lfm2_moe/test_modeling_lfm2_moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/llama/test_modeling_llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/llama/test_tokenization_llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/llama4/test_image_processing_llama4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/llama4/test_modeling_llama4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/llama4/test_processing_llama4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/llava/test_configuration_llava.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/llava/test_modeling_llava.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/llava/test_processing_llava.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/llava_next/test_image_processing_llava_next.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/llava_next/test_modeling_llava_next.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/llava_next/test_processing_llava_next.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/llava_next_video/test_modeling_llava_next_video.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/llava_next_video/test_processing_llava_next_video.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/llava_next_video/test_video_processing_llava_next_video.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/llava_onevision/test_image_processing_llava_onevision.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/llava_onevision/test_processing_llava_onevision.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/llava_onevision/test_video_processing_llava_onevision.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/mamba2/test_modeling_mamba2.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/ministral/test_modeling_ministral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/ministral3/test_modeling_ministral3.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/mistral/test_modeling_mistral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/mistral3/test_modeling_mistral3.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/mistral3/test_processing_mistral3.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/mllama/test_image_processing_mllama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/mllama/test_modeling_mllama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/mllama/test_processing_mllama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/omdet_turbo/test_processing_omdet_turbo.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/openai/test_modeling_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/openai/test_tokenization_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/paligemma/test_processing_paligemma.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/perception_lm/test_modeling_perception_lm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/pixtral/test_processing_pixtral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/qwen2_5_vl/test_processing_qwen2_5_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/qwen2_vl/test_image_processing_qwen2_vl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/qwen2_vl/test_processing_qwen2_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/qwen2_vl/test_video_processing_qwen2_vl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/qwen3_vl/test_processing_qwen3_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/reformer/test_modeling_reformer.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/t5/test_modeling_t5.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/t5gemma/test_modeling_t5gemma.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/t5gemma2/test_modeling_t5gemma2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/vaultgemma/test_modeling_vaultgemma.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/video_llama_3/test_image_processing_video_llama_3.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/video_llama_3/test_modeling_video_llama_3.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/video_llama_3/test_processing_video_llama_3.py",
        "providers": [
          "llama",
          "ollama",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/video_llama_3/test_video_processing_video_llama_3.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/video_llava/test_modeling_video_llava.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/video_llava/test_video_processing_video_llava.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/vipllava/test_modeling_vipllava.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/voxtral/test_modeling_voxtral.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/wav2vec2_with_lm/test_processing_wav2vec2_with_lm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/whisper/test_modeling_whisper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/whisper/test_processing_whisper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/models/whisper/test_tokenization_whisper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/pipelines/test_pipelines_automatic_speech_recognition.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/pipelines/test_pipelines_common.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/pipelines/test_pipelines_text_generation.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/pipelines/test_pipelines_text_to_audio.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/pipelines/test_pipelines_zero_shot_image_classification.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/aqlm_integration/test_aqlm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/autoawq/test_awq.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/bitnet_integration/test_bitnet.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/bnb/test_4bit.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/bnb/test_mixed_int8.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/compressed_tensors_integration/test_compressed_models.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/compressed_tensors_integration/test_compressed_tensors.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/fbgemm_fp8/test_fbgemm_fp8.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/finegrained_fp8/test_fp8.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/fp_quant_integration/test_fp_quant.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/ggml/test_ggml.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/gptq/test_gptq.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/higgs/test_higgs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/hqq/test_hqq.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/mxfp4/test_mxfp4.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/quanto_integration/test_quanto.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/quark_integration/test_quark.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/spqr_integration/test_spqr.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/torchao_integration/test_torchao.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/quantization/vptq_integration/test_vptq.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/repo_utils/modular/test_conversion_order.py",
        "providers": [
          "cohere",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/tensor_parallel/test_tensor_parallel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/test_executorch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/test_modeling_common.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/test_sentencepiece_backend_mixin.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/test_tokenization_mistral_common.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/tokenization/test_tokenization_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/trainer/test_trainer.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/trainer/test_trainer_distributed_loss.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/trainer/test_trainer_seq2seq.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/utils/test_add_new_model_like.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/utils/test_attention_visualizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/utils/test_auto_docstring.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/utils/test_cache_utils.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/utils/test_chat_parsing_utils.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/utils/test_configuration_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/utils/test_import_structure.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/utils/test_masking_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/utils/test_modeling_rope_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/utils/test_modeling_utils.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/tests/utils/test_tokenization_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/utils/check_config_attributes.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/utils/check_config_docstrings.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/utils/check_copies.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/utils/check_docstrings.py",
        "providers": [
          "cohere",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/utils/check_modular_conversion.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/utils/check_repo.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/utils/create_dependency_mapping.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/utils/fetch_hub_objects_for_ci.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/utils/important_files.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/utils/models_to_deprecate.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/utils/modular_model_converter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/utils/modular_model_detector.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/utils/set_cuda_devices_for_ci.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "huggingface-transformers-2db992d/utils/tests_fetcher.py",
        "providers": [
          "mistral",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "jadore801120/attention-is-all-you-need-pytorch": {
    "owner": "jadore801120",
    "repo": "attention-is-all-you-need-pytorch",
    "ref": "master",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "hzg0601/langchain-ChatGLM-annotation": {
    "owner": "hzg0601",
    "repo": "langchain-ChatGLM-annotation",
    "ref": "da8085ba5fcb89a2e665cd3fde28cdafa38b9c29",
    "num_llm_files": 34,
    "providers": [
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/agent/bing_search.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/agent/custom_agent.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/api.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/chains/dialogue_answering/__main__.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/chains/dialogue_answering/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/chains/dialogue_answering/prompts.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/chains/local_doc_qa.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/chains/modules/embeddings.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/chains/modules/vectorstores.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/chains/text_load.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/cli.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/cli_demo.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/configs/model_config.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/loader/RSS_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/loader/dialogue.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/loader/image_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/loader/pdf_loader.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/models/__init__.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/models/chatglm_llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/models/fastchat_openai_llm.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/models/llama_llm.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/models/loader/args.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/models/loader/loader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/models/moss_llm.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/models/shared.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/startpu.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/test/models/test_vicuna_chain_agent.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/test/textsplitter/test_zh_title_enhance.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/textsplitter/ali_text_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/textsplitter/chinese_text_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/textsplitter/zh_title_enhance.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/vectorstores/MyFAISS.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/webui.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "hzg0601-langchain-ChatGLM-annotation-da8085b/webui_st.py",
        "providers": [
          "langchain"
        ]
      }
    ],
    "error": null
  },
  "jessevig/bertviz": {
    "owner": "jessevig",
    "repo": "bertviz",
    "ref": "master",
    "num_llm_files": 11,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "jessevig-bertviz-0fe6892/bertviz/transformers_neuron_view/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jessevig-bertviz-0fe6892/bertviz/transformers_neuron_view/modeling_bert.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jessevig-bertviz-0fe6892/bertviz/transformers_neuron_view/modeling_gpt2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jessevig-bertviz-0fe6892/bertviz/transformers_neuron_view/modeling_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jessevig-bertviz-0fe6892/bertviz/transformers_neuron_view/modeling_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jessevig-bertviz-0fe6892/bertviz/transformers_neuron_view/modeling_xlm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jessevig-bertviz-0fe6892/bertviz/transformers_neuron_view/modeling_xlnet.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jessevig-bertviz-0fe6892/bertviz/transformers_neuron_view/tokenization_gpt2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jessevig-bertviz-0fe6892/bertviz/transformers_neuron_view/tokenization_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jessevig-bertviz-0fe6892/bertviz/transformers_neuron_view/tokenization_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jessevig-bertviz-0fe6892/bertviz/transformers_neuron_view/tokenization_xlm.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "jina-ai/clip-as-service": {
    "owner": "jina-ai",
    "repo": "clip-as-service",
    "ref": "main",
    "num_llm_files": 17,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "jina-ai-clip-as-service-0341057/client/clip_client/client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jina-ai-clip-as-service-0341057/client/setup.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jina-ai-clip-as-service-0341057/scripts/setup.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jina-ai-clip-as-service-0341057/server/clip_server/executors/clip_onnx.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jina-ai-clip-as-service-0341057/server/clip_server/executors/clip_tensorrt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jina-ai-clip-as-service-0341057/server/clip_server/executors/clip_torch.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jina-ai-clip-as-service-0341057/server/clip_server/model/clip.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jina-ai-clip-as-service-0341057/server/clip_server/model/clip_onnx.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jina-ai-clip-as-service-0341057/server/clip_server/model/clip_trt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jina-ai-clip-as-service-0341057/server/clip_server/model/mclip_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jina-ai-clip-as-service-0341057/server/clip_server/model/model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jina-ai-clip-as-service-0341057/server/clip_server/model/openclip_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jina-ai-clip-as-service-0341057/server/clip_server/model/pretrained_models.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jina-ai-clip-as-service-0341057/server/clip_server/model/simple_tokenizer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jina-ai-clip-as-service-0341057/server/setup.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jina-ai-clip-as-service-0341057/tests/conftest.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "jina-ai-clip-as-service-0341057/tests/test_model.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "joaocarlosleme/chat-langchain": {
    "owner": "joaocarlosleme",
    "repo": "chat-langchain",
    "ref": "362e71c016d70022a6b1d067e0cddbe1a6ef496e",
    "num_llm_files": 8,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "joaocarlosleme-chat-langchain-362e71c/archive/app.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "joaocarlosleme-chat-langchain-362e71c/archive/chain.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "joaocarlosleme-chat-langchain-362e71c/archive/ingest.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "joaocarlosleme-chat-langchain-362e71c/archive/ingest_examples.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "joaocarlosleme-chat-langchain-362e71c/callback.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "joaocarlosleme-chat-langchain-362e71c/ingest.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "joaocarlosleme-chat-langchain-362e71c/main.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "joaocarlosleme-chat-langchain-362e71c/query_data.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "jzhang38/TinyLlama": {
    "owner": "jzhang38",
    "repo": "TinyLlama",
    "ref": "main",
    "num_llm_files": 16,
    "providers": [
      "anthropic",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "jzhang38-TinyLlama-bf12224/chat_gradio/app.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "jzhang38-TinyLlama-bf12224/lit_gpt/adapter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "jzhang38-TinyLlama-bf12224/lit_gpt/adapter_v2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "jzhang38-TinyLlama-bf12224/lit_gpt/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "jzhang38-TinyLlama-bf12224/lit_gpt/lora.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "jzhang38-TinyLlama-bf12224/lit_gpt/model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "jzhang38-TinyLlama-bf12224/pretrain/tinyllama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "jzhang38-TinyLlama-bf12224/pretrain/tinyllama_code.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "jzhang38-TinyLlama-bf12224/scripts/convert_hf_checkpoint.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "jzhang38-TinyLlama-bf12224/scripts/convert_lit_checkpoint.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "jzhang38-TinyLlama-bf12224/scripts/prepare_slimpajama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "jzhang38-TinyLlama-bf12224/scripts/prepare_starcoder.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "jzhang38-TinyLlama-bf12224/sft/finetune.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "jzhang38-TinyLlama-bf12224/sft/simple_inference.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "jzhang38-TinyLlama-bf12224/sft/simple_inference2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "jzhang38-TinyLlama-bf12224/speculative_decoding/instruct_hf_assisted_decoding.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "karpathy/minGPT": {
    "owner": "karpathy",
    "repo": "minGPT",
    "ref": "master",
    "num_llm_files": 2,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "karpathy-minGPT-37baab7/mingpt/bpe.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "karpathy-minGPT-37baab7/mingpt/model.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "jacobgil/pytorch-grad-cam": {
    "owner": "jacobgil",
    "repo": "pytorch-grad-cam",
    "ref": "master",
    "num_llm_files": 1,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "jacobgil-pytorch-grad-cam-781dbc0/usage_examples/clip_example.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "kroll-software/babyagi4all": {
    "owner": "kroll-software",
    "repo": "babyagi4all",
    "ref": "3dc42659eb5cb51dbea71b565ce09f61a130cc20",
    "num_llm_files": 1,
    "providers": [
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "kroll-software-babyagi4all-3dc4265/babyagi.py",
        "providers": [
          "llama",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "comet-ml/opik": {
    "owner": "comet-ml",
    "repo": "opik",
    "ref": "main",
    "num_llm_files": 366,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "groq",
      "langchain",
      "litellm",
      "llama",
      "mistral",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/EvaluationExamples/evaluation-scripts/EvaluatePrompts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/ADK.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/Agno.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/Anthropic.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/AutoGen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/Bedrock.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/DSPy.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/DeepSeek.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/FunctionDecorators.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/Gemini.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/Groq.py",
        "providers": [
          "groq",
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/GuardrailsAI.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/Haystack.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/LangChain.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/LangGraph.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/LiteLLM.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/LlamaIndex.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/Ollama.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/OpenAI.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/OpenAIAgents.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/OpenRouter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/Predibase.py",
        "providers": [
          "langchain",
          "mistral"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/PydanticAI.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/Ragas.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/Smolagents.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/StrandsAgents.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/VercelAI.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-frontend/src/components/pages-shared/onboarding/FrameworkIntegrations/integration-scripts/WatsonX.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-python-backend/src/opik_backend/demo_data.py",
        "providers": [
          "anthropic",
          "langchain",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-python-backend/src/opik_backend/demo_data_generator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-python-backend/src/opik_backend/jobs/optimizer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-python-backend/src/opik_backend/studio/config.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-python-backend/tests/test_metrics_factory.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/apps/opik-python-backend/tests/test_rq_contract.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/benchmarks/check_results.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/benchmarks/core/benchmark_config.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/benchmarks/metrics/hover.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/benchmarks/metrics/ifbench.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/benchmarks/metrics/pupa.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/benchmarks/metrics/utils.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/benchmarks/run_benchmark_modal.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/benchmarks/runners/benchmark_worker.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/benchmarks/runners/run_benchmark.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/benchmarks/runners/run_benchmark_modal.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/benchmarks/utils/modal_helper.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/archive/langgraph_fewshot_hotpot_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/archive/langgraph_metaprompt_hotpot_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/archive/litellm_evolutionary_context7_mcp_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/archive/litellm_gepa_tiny_test_example.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/archive/litellm_metaprompt_context7_mcp_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/archive/pydantic_ai_fewshot_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/archive/pydantic_ai_metaprompt_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/generate_fern_docs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/llm_frameworks/adk/adk_agent.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/llm_frameworks/adk/adk_evolutionary_hotpot_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/llm_frameworks/adk/adk_fewshot_hotpot_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/llm_frameworks/adk/adk_gepa_hotpot_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/llm_frameworks/adk/adk_hierarchical_hotpot_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/llm_frameworks/adk/adk_metaprompt_hotpot_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/llm_frameworks/adk/adk_parameter_hotpot_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/llm_frameworks/crewai/crewai_agent.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/llm_frameworks/crewai/crewai_evolutionary_example.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/llm_frameworks/langgraph/langgraph_agent.py",
        "providers": [
          "langchain",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/llm_frameworks/langgraph/langgraph_evolutionary_hotpot_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/llm_frameworks/mcp/mcp_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/llm_frameworks/mcp/mcp_fewshot_hotpot_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/llm_frameworks/microsoft_agent_framework/microsoft_agent_framework_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/llm_frameworks/microsoft_agent_framework/microsoft_agent_framework_evolutionary_hotpot_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/llm_frameworks/pydantic/pydantic_ai_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/llm_frameworks/pydantic/pydantic_ai_evolutionary_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/multi_metric_objective_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/multimodal_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/optimizer_algorithms/evolutionary_hotpot_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/optimizer_algorithms/fewshot_hotpot_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/optimizer_algorithms/gepa_hotpot_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/optimizer_algorithms/hierarchical_hotpot_example.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/optimizer_algorithms/metaprompt_hotpot_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/optimizer_algorithms/parameter_hotpot_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/optimizer_algorithms/utils/metrics.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/scripts/validation_dataset.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/setup.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/_llm_calls.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/algorithms/evolutionary_optimizer/evolutionary_optimizer.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/algorithms/evolutionary_optimizer/prompts.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/algorithms/few_shot_bayesian_optimizer/few_shot_bayesian_optimizer.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/algorithms/gepa_optimizer/adapter.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/algorithms/gepa_optimizer/gepa_optimizer.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/algorithms/hierarchical_reflective_optimizer/hierarchical_reflective_optimizer.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/algorithms/meta_prompt_optimizer/meta_prompt_optimizer.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/algorithms/meta_prompt_optimizer/ops/candidate_ops.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/algorithms/meta_prompt_optimizer/ops/context_ops.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/algorithms/parameter_optimizer/parameter_optimizer.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/api_objects/chat_prompt.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/api_objects/types.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/base_optimizer.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/datasets/driving_hazard.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/datasets/election_questions.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/logging_config.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/metrics/answer_correctness.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/metrics/task_span/total_span_cost.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/optimizable_agent.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/utils/core.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/src/opik_optimizer/utils/llm_logger.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/e2e/benchmarks/test_benchmark_dual_optimizers_live.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/e2e/benchmarks/test_benchmark_fewshot_live.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/e2e/optimizers/test_evolutionary.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/e2e/optimizers/test_few_shot.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/e2e/optimizers/test_gepa.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/e2e/optimizers/test_hierarchical_reflective.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/e2e/optimizers/test_meta_prompt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/e2e/optimizers/test_multimodal.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/e2e/optimizers/test_parameter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/benchmarks/test_task_runner.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/mcp/test_mcp_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/metrics/test_total_span_cost.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/optimizers/evolutionary/test_mutation_ops.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/optimizers/few_shot/test_columnar_search_space.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/optimizers/few_shot/test_sampling_determinism.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/optimizers/gepa_optimizer/test_gepa_adapter.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/optimizers/gepa_optimizer/test_gepa_optimizer_basic.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/optimizers/gepa_optimizer/test_gepa_optimizer_validation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/optimizers/hierarchical/test_hierarchical_reflective_optimizer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/optimizers/parameter/test_parameter_optimizer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/optimizers/parameter/test_parameter_search_space.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/optimizers/test_counter_functionality.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/optimizers/test_imports.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/test_agent_factory.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/test_base_optimizer_agent_binding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/test_meta_prompt_optimizer_tokens.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/opik_optimizer/tests/unit/test_optimizable_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/examples/demo_data.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "langchain",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/examples/demo_data_generator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/examples/dynamic_tracing_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/examples/evaluate_prompt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/examples/evaluation_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/examples/langchain_integration_example.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/examples/metrics.py",
        "providers": [
          "gemini",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/examples/openai_integration_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/examples/trajectory_accuracy_evaluation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/setup.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/api_objects/opik_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/api_objects/prompt/chat/chat_prompt_template.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/api_objects/span/span_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/api_objects/trace/trace_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/cli/proxy.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/config.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/configurator/configure.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/error_tracking/environment_details.py",
        "providers": [
          "anthropic",
          "gemini",
          "langchain",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/engine/exception_analyzer.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/evaluator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/__init__.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/conversation/__init__.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/conversation/g_eval_wrappers.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/conversation/llm_judges/__init__.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/conversation/llm_judges/conversational_coherence/metric.py",
        "providers": [
          "cohere",
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/conversation/llm_judges/conversational_coherence/schema.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/conversation/llm_judges/g_eval_wrappers.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/conversation/llm_judges/user_frustration/metric.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/context_precision/metric.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/context_recall/metric.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/factuality/metric.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/g_eval/metric.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/g_eval/parser.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/g_eval/presets.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/g_eval_presets/__init__.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/g_eval_presets/agent_assessment.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/g_eval_presets/bias_classifier.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/g_eval_presets/compliance_risk.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/g_eval_presets/prompt_uncertainty.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/g_eval_presets/qa_suite.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/hallucination/metric.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/llm_juries/metric.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/moderation/metric.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/syc_eval/metric.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/trajectory_accuracy/metric.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/llm_judges/usefulness/metric.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/metrics/ragas_metric.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/models/__init__.py",
        "providers": [
          "langchain",
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/models/base_model.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/models/langchain/__init__.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/models/langchain/langchain_chat_model.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/models/langchain/message_converters.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/models/langchain/opik_monitoring.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/models/litellm/litellm_chat_model.py",
        "providers": [
          "anthropic",
          "groq",
          "litellm",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/models/litellm/opik_monitor.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/models/litellm/util.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/models/litellm/warning_filters.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/models/model_capabilities.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/models/models_factory.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/evaluation/threads/evaluator.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/forwarding_server/app.py",
        "providers": [
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/adk/helpers.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/adk/legacy_opik_tracer.py",
        "providers": [
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/adk/opik_tracer.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/adk/patchers/litellm_wrappers.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/adk/patchers/llm_response_wrapper.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/adk/patchers/patchers.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/aisuite/aisuite_decorator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/anthropic/__init__.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/anthropic/messages_create_decorator.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/anthropic/opik_tracker.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/anthropic/stream_patchers.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/bedrock/converse/chunks_aggregator.py",
        "providers": [
          "anthropic",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/bedrock/converse/converse_decorator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/bedrock/invoke_model/chunks_aggregator/__init__.py",
        "providers": [
          "anthropic",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/bedrock/invoke_model/chunks_aggregator/base.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/bedrock/invoke_model/chunks_aggregator/claude.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/bedrock/invoke_model/chunks_aggregator/format_detector.py",
        "providers": [
          "anthropic",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/bedrock/invoke_model/chunks_aggregator/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/bedrock/invoke_model/chunks_aggregator/mistral.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/bedrock/invoke_model/usage_converters.py",
        "providers": [
          "anthropic",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/bedrock/invoke_model/usage_extraction.py",
        "providers": [
          "anthropic",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/bedrock/opik_tracker.py",
        "providers": [
          "anthropic",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/crewai/opik_tracker.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/crewai/patchers/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/crewai/patchers/litellm_completion.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/crewai/patchers/llm_client.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/genai/__init__.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/genai/encoder_extension.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/genai/generate_content_decorator.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/genai/generations_aggregators.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/genai/opik_tracker.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/genai/stream_wrappers.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/haystack/constants.py",
        "providers": [
          "anthropic",
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/haystack/converters.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/haystack/opik_connector.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/haystack/opik_span_bridge.py",
        "providers": [
          "anthropic",
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/langchain/base_llm_patcher.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/langchain/helpers.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/langchain/langgraph_async_context_bridge.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/langchain/opik_encoder_extension.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/langchain/opik_tracer.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/langchain/provider_usage_extractors/anthropic_usage_extractor.py",
        "providers": [
          "anthropic",
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/langchain/provider_usage_extractors/anthropic_vertexai_usage_extractor.py",
        "providers": [
          "anthropic",
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/langchain/provider_usage_extractors/bedrock_usage_extractor.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/langchain/provider_usage_extractors/google_generative_ai_usage_extractor.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/langchain/provider_usage_extractors/groq_usage_extractor.py",
        "providers": [
          "groq",
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/langchain/provider_usage_extractors/langchain_run_helpers/helpers.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/langchain/provider_usage_extractors/langchain_run_helpers/langchain_usage.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/langchain/provider_usage_extractors/openai_usage_extractor.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/langchain/provider_usage_extractors/provider_usage_extractor_protocol.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/langchain/provider_usage_extractors/usage_extractor.py",
        "providers": [
          "anthropic",
          "groq",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/langchain/provider_usage_extractors/vertexai_usage_extractor.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/litellm/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/litellm/completion_chunks_aggregator.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/litellm/litellm_completion_decorator.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/litellm/opik_tracker.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/litellm/stream_patchers.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/llama_index/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/llama_index/callback.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/llama_index/event_parsing_utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/openai/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/openai/agents/opik_tracing_processor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/openai/agents/span_data_parsers.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/openai/chat_completion_chunks_aggregator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/openai/openai_chat_completions_decorator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/openai/openai_responses_decorator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/openai/opik_tracker.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/openai/response_events_aggregator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/integrations/openai/stream_patchers.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/llm_usage/anthropic_usage.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/llm_usage/google_usage.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/llm_usage/openai_chat_completions_usage.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/llm_usage/openai_responses_usage.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/llm_usage/opik_usage.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/llm_usage/opik_usage_factory.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/logging_messages.py",
        "providers": [
          "groq",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/opik_context.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/rest_api/datasets/client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/rest_api/llm_provider_key/client.py",
        "providers": [
          "anthropic",
          "llama",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/rest_api/llm_provider_key/raw_client.py",
        "providers": [
          "anthropic",
          "llama",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/rest_api/llm_provider_key/types/provider_api_key_write_provider.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/rest_api/types/provider_api_key.py",
        "providers": [
          "anthropic",
          "llama",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/rest_api/types/provider_api_key_provider.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/rest_api/types/provider_api_key_public.py",
        "providers": [
          "anthropic",
          "llama",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/rest_api/types/provider_api_key_public_provider.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/simulation/simulated_user.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/src/opik/types.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/conftest.py",
        "providers": [
          "anthropic",
          "groq",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/e2e/evaluation/test_multimodal.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/e2e/evaluation/test_threads_evaluate.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/e2e_library_integration/adk/sample_agent/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/e2e_library_integration/adk/sample_agent_anthropic/agent.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/e2e_library_integration/adk/sample_agent_openai/agent.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/e2e_library_integration/adk/sample_agent_sse/agent.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/e2e_library_integration/adk/test_opik_tracer.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/e2e_library_integration/litellm/constants.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/e2e_library_integration/litellm/test_opik_logging.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/integration/simulation/test_simulation_integration.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/adk/constants.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/adk/test_adk_async.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/adk/test_adk_graph_builder.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/adk/test_adk_sync.py",
        "providers": [
          "gemini",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/adk/test_helpers.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/aisuite/test_aisuite.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/anthropic/test_anthropic.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/bedrock/constants.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/bedrock/test_converse.py",
        "providers": [
          "anthropic",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/bedrock/test_invoke_model.py",
        "providers": [
          "anthropic",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/crewai/constants.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/crewai/test_crewai.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/crewai/test_crewai_flows.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/dspy/test_dspy.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/genai/test_genai.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/genai/test_genai_encoder_extension.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/guardrails/test_guardrails.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/haystack/test_haystack.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/langchain/constants.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/langchain/test_langchain.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/langchain/test_langchain_anthropic.py",
        "providers": [
          "anthropic",
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/langchain/test_langchain_bedrock.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/langchain/test_langchain_google_genai.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/langchain/test_langchain_groq.py",
        "providers": [
          "groq",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/langchain/test_langchain_openai.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/langchain/test_langchain_vertexai.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/langchain/test_langgraph.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/langchain/test_message_converters.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/langchain/test_opik_langchain_chat_model.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/langchain/test_opik_tracer.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/litellm/__init__.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/litellm/constants.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/litellm/test_litellm_chat_model.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/litellm/test_litellm_completion.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/litellm/test_litellm_streaming.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/llama_index/test_llama_index.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/metrics_with_llm_judge/conftest.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/metrics_with_llm_judge/test_conversation_coherence_metric.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/metrics_with_llm_judge/test_evaluation_metrics.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/metrics_with_llm_judge/test_session_completeness_metric.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/openai/agents_tests/test_opik_tracing_processor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/openai/constants.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/openai/test_openai_chat_completions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/openai/test_openai_chat_completions_beta_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/library_integration/openai/test_openai_responses.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/testlib/environment.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/testlib/fake_message_factory.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/api_objects/test_opik_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/api_objects/test_opik_query_language.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/decorator/test_span_context_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/decorator/test_tracker_outputs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/evaluation/metrics/conversation_common/test_public_api.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/evaluation/metrics/llm_judges/conversation/conversational_coherence/test_metric.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/evaluation/metrics/llm_judges/structure_output_compliance/test_metric.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/evaluation/metrics/llm_judges/trajectory_accuracy/test_metric.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/evaluation/metrics/test_g_eval_presets.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/evaluation/models/test_litellm_chat_model.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/evaluation/models/test_model_capabilities.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/evaluation/test_evaluate.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/evaluation/test_evaluate_experiment_name.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/llm_usage/test_anthropic_usage.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/llm_usage/test_client_with_usage_logged.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/llm_usage/test_google_usage.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/llm_usage/test_openai_chat_completions_usage.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/llm_usage/test_opik_usage.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/llm_usage/test_opik_usage_factory.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/message_processing/emulation/test_local_emulator_message_processor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/simulation/test_simulated_user.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/sdks/python/tests/unit/test_cli.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/tests_end_to_end/page_objects/AIProvidersConfigPage.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/tests_end_to_end/page_objects/PlaygroundPage.py",
        "providers": [
          "anthropic",
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/tests_end_to_end/page_objects/helpers/AIProviderSetupHelper.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/tests_end_to_end/tests/QuickstartGuide/test_quickstart_guide.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "langchain",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/tests_end_to_end/tests/conftest.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "comet-ml-opik-28440d1/tests_load/tests/test_image_inference.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "khoj-ai/khoj": {
    "owner": "khoj-ai",
    "repo": "khoj",
    "ref": "master",
    "num_llm_files": 59,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "groq",
      "langchain",
      "litellm",
      "llama",
      "mistral",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/configure.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/adapters/__init__.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/migrations/0010_chatmodeloptions_and_more.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/migrations/0021_speechtotextmodeloptions_and_more.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/migrations/0022_texttoimagemodelconfig.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/migrations/0034_alter_chatmodeloptions_chat_model.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/migrations/0037_chatmodeloptions_openai_config_and_more.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/migrations/0038_merge_20240425_0857.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/migrations/0043_alter_chatmodeloptions_model_type.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/migrations/0049_texttoimagemodelconfig_api_key_and_more.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/migrations/0058_alter_chatmodeloptions_chat_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/migrations/0061_alter_chatmodeloptions_model_type.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/migrations/0061_alter_texttoimagemodelconfig_model_type.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/migrations/0076_rename_openaiprocessorconversationconfig_aimodelapi_and_more.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/migrations/0077_chatmodel_alter_agent_chat_model_and_more.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/migrations/0079_searchmodelconfig_embeddings_inference_endpoint_type.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/migrations/0086_alter_texttoimagemodelconfig_model_type.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/migrations/0092_alter_chatmodel_model_type_alter_chatmodel_name_and_more.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/migrations/0098_alter_texttoimagemodelconfig_model_type.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/database/models/__init__.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/content/docx/docx_to_entries.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/content/pdf/pdf_to_entries.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/content/text_to_entries.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/conversation/anthropic/anthropic_chat.py",
        "providers": [
          "anthropic",
          "langchain"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/conversation/anthropic/utils.py",
        "providers": [
          "anthropic",
          "langchain"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/conversation/google/gemini_chat.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/conversation/google/utils.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/conversation/openai/gpt.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/conversation/openai/utils.py",
        "providers": [
          "groq",
          "langchain",
          "litellm",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/conversation/openai/whisper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/conversation/prompts.py",
        "providers": [
          "gemini",
          "langchain"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/conversation/utils.py",
        "providers": [
          "anthropic",
          "gemini",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/embeddings.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/image/generate.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/operator/__init__.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/operator/grounding_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/operator/grounding_agent_uitars.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/operator/operator_agent_anthropic.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/operator/operator_agent_binary.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/operator/operator_agent_openai.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/operator/operator_environment_browser.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/processor/tools/run_code.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/routers/api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/routers/api_chat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/routers/helpers.py",
        "providers": [
          "anthropic",
          "gemini",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/utils/constants.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/utils/helpers.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/utils/initialization.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/utils/models.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/src/khoj/utils/state.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/tests/conftest.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/tests/evals/eval.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/tests/helpers.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/tests/test_agents.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/tests/test_api_automation.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/tests/test_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/tests/test_conversation_utils.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/tests/test_online_chat_actors.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "khoj-ai-khoj-f4c519a/tests/test_online_chat_director.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "langchain-ai/chat-langchain": {
    "owner": "langchain-ai",
    "repo": "chat-langchain",
    "ref": "a875a649109ad7c3d68d7e9b75508f687e627ca4",
    "num_llm_files": 9,
    "providers": [
      "anthropic",
      "cohere",
      "langchain",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "langchain-ai-chat-langchain-a875a64/_scripts/clear_index.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "langchain-ai-chat-langchain-a875a64/_scripts/evaluate_chains.py",
        "providers": [
          "anthropic",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "langchain-ai-chat-langchain-a875a64/_scripts/evaluate_chains_agent.py",
        "providers": [
          "langchain",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "langchain-ai-chat-langchain-a875a64/_scripts/evaluate_chains_improved_chain.py",
        "providers": [
          "anthropic",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "langchain-ai-chat-langchain-a875a64/_scripts/evaluate_chat_langchain.py",
        "providers": [
          "anthropic",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "langchain-ai-chat-langchain-a875a64/constants.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "langchain-ai-chat-langchain-a875a64/ingest.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "langchain-ai-chat-langchain-a875a64/main.py",
        "providers": [
          "cohere",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "langchain-ai-chat-langchain-a875a64/parser.py",
        "providers": [
          "langchain"
        ]
      }
    ],
    "error": null
  },
  "junruxiong/IncarnaMind": {
    "owner": "junruxiong",
    "repo": "IncarnaMind",
    "ref": "75564a3bf08d0006387889cdc9a76fc509ededd8",
    "num_llm_files": 8,
    "providers": [
      "anthropic",
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "junruxiong-IncarnaMind-75564a3/convo_qa_chain.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "junruxiong-IncarnaMind-75564a3/docs2db.py",
        "providers": [
          "anthropic",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "junruxiong-IncarnaMind-75564a3/main.py",
        "providers": [
          "anthropic",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "junruxiong-IncarnaMind-75564a3/toolkit/local_llm.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "junruxiong-IncarnaMind-75564a3/toolkit/prompts.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "junruxiong-IncarnaMind-75564a3/toolkit/retrivers.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "junruxiong-IncarnaMind-75564a3/toolkit/together_api_llm.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "junruxiong-IncarnaMind-75564a3/toolkit/utils.py",
        "providers": [
          "anthropic",
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "lucidrains/DALLE2-pytorch": {
    "owner": "lucidrains",
    "repo": "DALLE2-pytorch",
    "ref": "main",
    "num_llm_files": 4,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "lucidrains-DALLE2-pytorch-680dfc4/dalle2_pytorch/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lucidrains-DALLE2-pytorch-680dfc4/dalle2_pytorch/dalle2_pytorch.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lucidrains-DALLE2-pytorch-680dfc4/dalle2_pytorch/tokenizer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lucidrains-DALLE2-pytorch-680dfc4/dalle2_pytorch/train_configs.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "lss233/kirara-ai": {
    "owner": "lss233",
    "repo": "kirara-ai",
    "ref": "master",
    "num_llm_files": 30,
    "providers": [
      "anthropic",
      "gemini",
      "llama",
      "mistral",
      "ollama",
      "openai"
    ],
    "files": [
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/config/global_config.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/llm/format/tool.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/plugins/llm_preset_adapters/__init__.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/plugins/llm_preset_adapters/alibabacloud_adapter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/plugins/llm_preset_adapters/claude_adapter.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/plugins/llm_preset_adapters/deepseek_adapter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/plugins/llm_preset_adapters/gemini_adapter.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/plugins/llm_preset_adapters/minimax_adapter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/plugins/llm_preset_adapters/mistral_adapter.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/plugins/llm_preset_adapters/moonshot_adapter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/plugins/llm_preset_adapters/ollama_adapter.py",
        "providers": [
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/plugins/llm_preset_adapters/openai_adapter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/plugins/llm_preset_adapters/openrouter_adapter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/plugins/llm_preset_adapters/siliconflow_adapter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/plugins/llm_preset_adapters/tencentcloud_adapter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/plugins/llm_preset_adapters/tests/test_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/plugins/llm_preset_adapters/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/kirara_ai/plugins/llm_preset_adapters/volcengine_adapter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/tests/llm_adapters/mock_app/__init__.py",
        "providers": [
          "gemini",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/tests/llm_adapters/mock_app/app.py",
        "providers": [
          "gemini",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/tests/llm_adapters/mock_app/gemini.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/tests/llm_adapters/mock_app/models/gemini.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/tests/llm_adapters/mock_app/ollama.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/tests/llm_adapters/mock_app/openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/tests/llm_adapters/test_gemini_adapter.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/tests/llm_adapters/test_ollama_adapter.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/tests/llm_adapters/test_openai_adapter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/tests/system_blocks/llm/test_basic.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/tests/system_blocks/llm/test_chat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "lss233-kirara-ai-8295a5d/tests/system_blocks/memory/test_chat_memory.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "lucidrains/vit-pytorch": {
    "owner": "lucidrains",
    "repo": "vit-pytorch",
    "ref": "main",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "ludwig-ai/ludwig": {
    "owner": "ludwig-ai",
    "repo": "ludwig",
    "ref": "master",
    "num_llm_files": 21,
    "providers": [
      "llama",
      "mistral",
      "openai"
    ],
    "files": [
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/examples/llama2_7b_finetuning_4bit/train_alpaca.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/ludwig/collect.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/ludwig/config_validation/checks.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/ludwig/data/batcher/test_batcher.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/ludwig/encoders/text_encoders.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/ludwig/models/llm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/ludwig/schema/encoders/text_encoders.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/ludwig/schema/llms/base_model.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/ludwig/schema/llms/model_parameters.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/ludwig/schema/llms/peft.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/ludwig/schema/model_types/utils.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/ludwig/utils/tokenizers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/tests/integration_tests/test_cli.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/tests/integration_tests/test_llm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/tests/ludwig/config_validation/test_checks.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/tests/ludwig/encoders/test_llm_encoders.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/tests/ludwig/evaluation/test_evaluation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/tests/ludwig/schema/test_model_config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/tests/ludwig/utils/test_config_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/tests/ludwig/utils/test_llm_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ludwig-ai-ludwig-00c51e0/tests/ludwig/utils/test_model_utils.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "marella/chatdocs": {
    "owner": "marella",
    "repo": "chatdocs",
    "ref": "ff0f962972ba65f0bccbf2e81875a95bae7473b5",
    "num_llm_files": 6,
    "providers": [
      "langchain"
    ],
    "files": [
      {
        "file_path": "marella-chatdocs-ff0f962/chatdocs/add.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "marella-chatdocs-ff0f962/chatdocs/chains.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "marella-chatdocs-ff0f962/chatdocs/embeddings.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "marella-chatdocs-ff0f962/chatdocs/llms.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "marella-chatdocs-ff0f962/chatdocs/vectorstores.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "marella-chatdocs-ff0f962/setup.py",
        "providers": [
          "langchain"
        ]
      }
    ],
    "error": null
  },
  "matigumma/bb.agi": {
    "owner": "matigumma",
    "repo": "bb.agi",
    "ref": "9af4396c1c97b0de3fc47ceb35ff8e4489be6254",
    "num_llm_files": 5,
    "providers": [
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "matigumma-bb.agi-9af4396/babyagi.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "matigumma-bb.agi-9af4396/extensions/argparseext.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "matigumma-bb.agi-9af4396/langChain-llama.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "matigumma-bb.agi-9af4396/tools/results.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "matigumma-bb.agi-9af4396/tools/results_browser.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "mattzcarey/code-review-gpt": {
    "owner": "mattzcarey",
    "repo": "code-review-gpt",
    "ref": "87bce4d443c869eb3da09e5a2c11b1a79c5e5d6a",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "mayooear/gpt4-pdf-chatbot-langchain": {
    "owner": "mayooear",
    "repo": "gpt4-pdf-chatbot-langchain",
    "ref": "66d183f6b207fa1d92153a430c620c58b01e9b1c",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "mayooear/private-chatbot-mpt30b-langchain": {
    "owner": "mayooear",
    "repo": "private-chatbot-mpt30b-langchain",
    "ref": "dbb888a2d5f1eaf6256ffab53e4ec0b766a86a3f",
    "num_llm_files": 3,
    "providers": [
      "langchain"
    ],
    "files": [
      {
        "file_path": "mayooear-private-chatbot-mpt30b-langchain-dbb888a/chat.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "mayooear-private-chatbot-mpt30b-langchain-dbb888a/ingest.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "mayooear-private-chatbot-mpt30b-langchain-dbb888a/question_answer_docs.py",
        "providers": [
          "langchain"
        ]
      }
    ],
    "error": null
  },
  "mckaywrigley/chatbot-ui": {
    "owner": "mckaywrigley",
    "repo": "chatbot-ui",
    "ref": "f4ec4df77f650fa650535c6b934d4a1775cf491a",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "menloparklab/privateGPT-app": {
    "owner": "menloparklab",
    "repo": "privateGPT-app",
    "ref": "028c81038dec2f923477812f7c7f7d48706fa7a9",
    "num_llm_files": 3,
    "providers": [
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "menloparklab-privateGPT-app-028c810/app.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "menloparklab-privateGPT-app-028c810/ingest.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "menloparklab-privateGPT-app-028c810/privateGPT.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "meta-llama/llama": {
    "owner": "meta-llama",
    "repo": "llama",
    "ref": "main",
    "num_llm_files": 7,
    "providers": [
      "cohere",
      "llama"
    ],
    "files": [
      {
        "file_path": "meta-llama-llama-689c7f2/example_chat_completion.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-689c7f2/example_text_completion.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-689c7f2/llama/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-689c7f2/llama/generation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-689c7f2/llama/model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-689c7f2/llama/tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-689c7f2/setup.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "meta-llama/llama-models": {
    "owner": "meta-llama",
    "repo": "llama-models",
    "ref": "main",
    "num_llm_files": 33,
    "providers": [
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/cli/describe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/cli/download.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/cli/list.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/cli/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/cli/prompt_format.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/cli/remove.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/cli/safety_models.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/cli/subcommand.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/cli/verify_download.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/datatypes.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama3/generation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama3/model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama3/multimodal/model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama3/scripts/chat_completion.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama3/scripts/completion.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama3/tests/api/test_generation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama3/tests/api/test_tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama3/tests/api/test_tool_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama3/tokenizer.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama4/args.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama4/chat_format.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama4/datatypes.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama4/generation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama4/model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama4/scripts/chat_completion.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama4/scripts/completion.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama4/scripts/quantize.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama4/tests/api/test_chat_format.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama4/tokenizer.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/llama4/vision/encoder.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/sku_list.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/sku_types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama-models-0e0b8c5/models/utils/config.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "lucidrains/PaLM-rlhf-pytorch": {
    "owner": "lucidrains",
    "repo": "PaLM-rlhf-pytorch",
    "ref": "main",
    "num_llm_files": 1,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "lucidrains-PaLM-rlhf-pytorch-f736bae/palm_rlhf_pytorch/implicit_process_reward.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "labring/FastGPT": {
    "owner": "labring",
    "repo": "FastGPT",
    "ref": "05bf1b22653f8699b85098db3e86a7f29bdc2895",
    "num_llm_files": 1,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "labring-FastGPT-05bf1b2/files/models/Baichuan2/openai_api.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "meta-llama/llama3": {
    "owner": "meta-llama",
    "repo": "llama3",
    "ref": "main",
    "num_llm_files": 8,
    "providers": [
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "meta-llama-llama3-a0940f9/example_chat_completion.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama3-a0940f9/example_text_completion.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama3-a0940f9/llama/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama3-a0940f9/llama/generation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama3-a0940f9/llama/model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama3-a0940f9/llama/test_tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "meta-llama-llama3-a0940f9/llama/tokenizer.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "meta-llama-llama3-a0940f9/setup.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "microsoft/Swin-Transformer": {
    "owner": "microsoft",
    "repo": "Swin-Transformer",
    "ref": "main",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "miurla/babyagi-ui": {
    "owner": "miurla",
    "repo": "babyagi-ui",
    "ref": "3f71b1bd4edea6eb2a063d2ccf540fa309114925",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": "failed to download zip zip not found"
  },
  "microsoft/markitdown": {
    "owner": "microsoft",
    "repo": "markitdown",
    "ref": "main",
    "num_llm_files": 4,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "microsoft-markitdown-dde250a/packages/markitdown/src/markitdown/converters/_image_converter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "microsoft-markitdown-dde250a/packages/markitdown/src/markitdown/converters/_llm_caption.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "microsoft-markitdown-dde250a/packages/markitdown/tests/_test_vectors.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "microsoft-markitdown-dde250a/packages/markitdown/tests/test_module_misc.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "mouredev/Hello-Python": {
    "owner": "mouredev",
    "repo": "Hello-Python",
    "ref": "main",
    "num_llm_files": 1,
    "providers": [
      "llama"
    ],
    "files": [
      {
        "file_path": "mouredev-Hello-Python-55e1bb4/Intermediate/07_regular_expressions.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "modelscope/ms-swift": {
    "owner": "modelscope",
    "repo": "ms-swift",
    "ref": "main",
    "num_llm_files": 175,
    "providers": [
      "cohere",
      "llama",
      "mistral",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/app/base_url/demo.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/custom/my_qwen2_5_omni/my_register.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/deploy/agent/client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/deploy/client/llm/base/openai_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/deploy/client/llm/chat/openai_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/deploy/client/llm/chat/swift_client.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/deploy/client/mllm/openai_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/deploy/client/mllm/swift_client.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/deploy/embedding/client.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/deploy/reranker/client.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/deploy/reranker/client_generative.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/deploy/seq_cls/client.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/eval/eval_url/demo.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/infer/demo.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/infer/demo_agent.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/infer/demo_lora.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/infer/demo_mllm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/infer/demo_reward_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/infer/demo_vllm_reasoning_parser.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/train/grpo/plugin/deepeyes/deepeyes_plugin.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/train/grpo/plugin/treepo/tree_rollout.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/train/grpo/plugin/treepo/tree_rollout_plugin.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/examples/train/rft/rft.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/scripts/benchmark/generate_report.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/__init__.py",
        "providers": [
          "llama",
          "ollama",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/argument/base_args/base_args.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/argument/deploy_args.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/argument/export_args.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/argument/infer_args.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/argument/merge_args.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/argument/rlhf_args.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/argument/sampling_args.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/argument/tuner_args.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/dataset/dataset/llm.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/dataset/dataset/mllm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/dataset/media.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/eval/eval.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/eval/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/export/__init__.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/export/export.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/export/ollama.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/infer/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/infer/deploy.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/infer/infer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/infer/infer_engine/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/infer/infer_engine/grpo_vllm_engine.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/infer/infer_engine/utils.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/infer/infer_engine/vllm_engine.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/infer/protocol.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/infer/rollout.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/constant.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/__init__.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/codefuse.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/deepseek.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/gemma.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/glm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/internlm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/llama.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/llava.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/llm.py",
        "providers": [
          "cohere",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/microsoft.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/minicpm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/mistral.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/mllm.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/mplug.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/openbuddy.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/qwen.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/skywork.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/stepfun.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model/yi.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/model_arch.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/register.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/model/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/sampling/distill_sampler.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/sampling/vanilla_sampler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/template/base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/template/constant.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/template/template/__init__.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/template/template/baidu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/template/template/gemma.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/template/template/glm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/template/template/internvl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/template/template/llama.py",
        "providers": [
          "cohere",
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/template/template/llava.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/template/template/llm.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/template/template/microsoft.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/template/template/minicpm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/template/template/mistral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/template/template/openbuddy.py",
        "providers": [
          "cohere",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/template/template/qwen.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/template/template/seed.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/template/template_meta.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/train/rlhf.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/llm/train/tuner.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/megatron/argument/megatron_args.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/megatron/init.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/megatron/model/constant.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/megatron/model/gpt/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/megatron/model/mm_gpt/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/megatron/model/mm_gpt/llama4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/megatron/train/rlhf.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/megatron/trainers/base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/megatron/trainers/grpo_trainer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/megatron/utils/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/plugin/agent_template/__init__.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/plugin/agent_template/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/plugin/agent_template/mistral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/plugin/env.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/plugin/multi_turn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/plugin/prm.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/trainers/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/trainers/arguments.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/trainers/rlhf_arguments.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/trainers/rlhf_trainer/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/trainers/rlhf_trainer/gkd_trainer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/trainers/rlhf_trainer/grpo_trainer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/trainers/rlhf_trainer/rollout_mixin.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/trainers/rlhf_trainer/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/trainers/rlhf_trainer/vllm_client.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/tuners/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/tuners/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/tuners/llamapro.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/tuners/longlora/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/tuners/longlora/longlora.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/tuners/mapping.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/ui/llm_eval/eval.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/ui/llm_grpo/grpo_advanced.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/ui/llm_grpo/llm_grpo.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/ui/llm_grpo/rollout.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/ui/llm_grpo/tuner.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/ui/llm_rlhf/tuner.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/ui/llm_sample/sample.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/ui/llm_train/llm_train.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/ui/llm_train/tuner.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/utils/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/swift/utils/import_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/deploy/test_dataset.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/deploy/test_logprobs.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/export/test_quant.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/general/test_dataset.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/general/test_template.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/infer/test_infer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/infer/test_logprobs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/infer/test_main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/infer/test_mllm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/infer/test_sglang.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/llm/test_ollama_export.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/llm/test_run.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/llm/test_run3.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/llm/test_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/megatron/test_align/test_llm.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/megatron/test_align/test_mllm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/megatron/test_lora.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/megatron/test_rlhf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/megatron/test_train.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/models/test_llm.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/models/test_mllm.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/sample/test_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/test_align/test_template/test_agent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/test_align/test_template/test_llm.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/test_align/test_template/test_vision.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/test_align/test_vllm_vlm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/train/test_freeze.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/train/test_gkd.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/train/test_grpo.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/train/test_packing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/train/test_ppo.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/train/test_pt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/train/test_resume_from_checkpoint.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/train/test_rlhf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/train/test_sample.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/train/test_sft.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/train/test_train_eval.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/train/test_vllm_importance_sampling_basic.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "modelscope-ms-swift-57c294e/tests/tuners/test_swift_device_map.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "meta-llama/llama-stack": {
    "owner": "meta-llama",
    "repo": "llama-stack",
    "ref": "main",
    "num_llm_files": 526,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "groq",
      "litellm",
      "llama",
      "mistral",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "llamastack-llama-stack-d82a2cd/benchmarking/k8s-benchmark/openai-mock-server.py",
        "providers": [
          "cohere",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/benchmarking/k8s-benchmark/scripts/generate_charts.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/docs/docs/getting_started/demo_script.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/docs/notebooks/nvidia/beginner_e2e/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/docs/notebooks/nvidia/tool_calling/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/diagnose_recordings.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/distro_codegen.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/gen-ci-docs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/generate_ci_matrix.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/generate_prompt_format.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/get_setup_env.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/normalize_recordings.py",
        "providers": [
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/openapi_generator/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/openapi_generator/_legacy_order.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/openapi_generator/app.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/openapi_generator/endpoints.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/openapi_generator/main.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/openapi_generator/schema_collection.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/openapi_generator/schema_filtering.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/openapi_generator/schema_transforms.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/openapi_generator/stainless_config/generate_config.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/openapi_generator/state.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/scripts/provider_codegen.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/cli/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/cli/stack/_list_deps.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/cli/stack/list_apis.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/cli/stack/list_deps.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/cli/stack/list_providers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/cli/stack/list_stacks.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/cli/stack/remove.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/cli/stack/run.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/cli/stack/stack.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/cli/stack/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/cli/subcommand.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/cli/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/access_control/access_control.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/build.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/configure.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/conversations/conversations.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/datatypes.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/distribution.py",
        "providers": [
          "llama",
          "ollama",
          "vllm"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/external.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/inspect.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/library_client.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/prompts/prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/providers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/request_headers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/resolver.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/routers/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/routers/datasets.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/routers/eval_scoring.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/routers/inference.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/routers/safety.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/routers/tool_runtime.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/routers/vector_io.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/routing_tables/benchmarks.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/routing_tables/common.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/routing_tables/datasets.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/routing_tables/models.py",
        "providers": [
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/routing_tables/scoring_functions.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/routing_tables/shields.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/routing_tables/toolgroups.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/routing_tables/vector_stores.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/server/auth.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/server/auth_providers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/server/fastapi_router_registry.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/server/quota.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/server/routes.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/server/server.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/stack.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/storage/datatypes.py",
        "providers": [
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/storage/kvstore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/storage/kvstore/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/storage/kvstore/kvstore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/storage/kvstore/mongodb/mongodb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/storage/kvstore/postgres/postgres.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/storage/kvstore/redis/redis.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/storage/kvstore/sqlite/sqlite.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/storage/sqlstore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/storage/sqlstore/authorized_sqlstore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/storage/sqlstore/sqlalchemy_sqlstore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/storage/sqlstore/sqlstore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/store/registry.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/testing_context.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/utils/config_dirs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/utils/config_resolution.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/utils/exec.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/utils/image_types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/core/utils/prompt_for_config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/distributions/ci-tests/ci_tests.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/distributions/dell/dell.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/distributions/meta-reference-gpu/meta_reference.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/distributions/nvidia/nvidia.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/distributions/oci/oci.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/distributions/open-benchmark/open_benchmark.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/distributions/starter-gpu/starter_gpu.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/distributions/starter/starter.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "llama",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/distributions/template.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/distributions/watsonx/watsonx.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/log.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/datatypes.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama3/generation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama3/interface.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama3/model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama3/multimodal/encoder_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama3/multimodal/image_transform.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama3/multimodal/model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama3/prompt_templates/system_prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama3/tokenizer.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama3/tool_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama3_1/prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama3_2/prompts_text.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama3_2/prompts_vision.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama3_3/prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama4/args.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama4/chat_format.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama4/datatypes.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama4/generation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama4/model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama4/prompt_templates/system_prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama4/prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama4/quantization/loader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama4/tokenizer.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/llama4/vision/encoder.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/prompt_format.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/quantize_impls.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/sku_list.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/sku_types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/models/llama/tokenizer_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/agents/meta_reference/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/agents/meta_reference/agents.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/agents/meta_reference/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/agents/meta_reference/responses/openai_responses.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/agents/meta_reference/responses/streaming.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/agents/meta_reference/responses/tool_executor.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/agents/meta_reference/responses/types.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/agents/meta_reference/responses/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/agents/meta_reference/safety.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/batches/reference/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/batches/reference/batches.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/batches/reference/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/datasetio/localfs/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/datasetio/localfs/datasetio.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/eval/meta_reference/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/eval/meta_reference/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/eval/meta_reference/eval.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/files/localfs/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/files/localfs/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/files/localfs/files.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/inference/meta_reference/common.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/inference/meta_reference/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/inference/meta_reference/generators.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/inference/meta_reference/inference.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/inference/meta_reference/model_parallel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/inference/meta_reference/parallel_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/inference/sentence_transformers/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/inference/sentence_transformers/sentence_transformers.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/post_training/common/validator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/post_training/huggingface/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/post_training/huggingface/post_training.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/post_training/huggingface/recipes/finetune_single_device.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/post_training/huggingface/recipes/finetune_single_device_dpo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/post_training/huggingface/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/post_training/torchtune/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/post_training/torchtune/common/checkpointer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/post_training/torchtune/common/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/post_training/torchtune/datasets/format_adapter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/post_training/torchtune/datasets/sft.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/post_training/torchtune/post_training.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/post_training/torchtune/recipes/lora_finetuning_single_device.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/safety/code_scanner/code_scanner.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/safety/llama_guard/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/safety/llama_guard/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/safety/llama_guard/llama_guard.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/safety/prompt_guard/prompt_guard.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/basic/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/basic/scoring.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/basic/scoring_fn/docvqa_scoring_fn.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/basic/scoring_fn/equality_scoring_fn.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/basic/scoring_fn/fn_defs/docvqa.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/basic/scoring_fn/fn_defs/equality.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/basic/scoring_fn/fn_defs/ifeval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/basic/scoring_fn/fn_defs/regex_parser_math_response.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/basic/scoring_fn/fn_defs/regex_parser_multiple_choice_answer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/basic/scoring_fn/fn_defs/subset_of.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/basic/scoring_fn/ifeval_scoring_fn.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/basic/scoring_fn/regex_parser_math_response_scoring_fn.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/basic/scoring_fn/regex_parser_scoring_fn.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/basic/scoring_fn/subset_of_scoring_fn.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/basic/utils/ifeval_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/basic/utils/math_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/braintrust/__init__.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/braintrust/braintrust.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/braintrust/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/braintrust/scoring_fn/fn_defs/answer_correctness.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/braintrust/scoring_fn/fn_defs/answer_relevancy.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/braintrust/scoring_fn/fn_defs/answer_similarity.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/braintrust/scoring_fn/fn_defs/context_entity_recall.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/braintrust/scoring_fn/fn_defs/context_precision.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/braintrust/scoring_fn/fn_defs/context_recall.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/braintrust/scoring_fn/fn_defs/context_relevancy.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/braintrust/scoring_fn/fn_defs/factuality.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/braintrust/scoring_fn/fn_defs/faithfulness.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/llm_as_judge/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/llm_as_judge/scoring.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/llm_as_judge/scoring_fn/fn_defs/llm_as_judge_405b_simpleqa.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/llm_as_judge/scoring_fn/fn_defs/llm_as_judge_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/scoring/llm_as_judge/scoring_fn/llm_as_judge_scoring_fn.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/tool_runtime/rag/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/tool_runtime/rag/context_retriever.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/tool_runtime/rag/memory.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/vector_io/chroma/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/vector_io/chroma/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/vector_io/faiss/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/vector_io/faiss/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/vector_io/faiss/faiss.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/vector_io/milvus/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/vector_io/milvus/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/vector_io/qdrant/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/vector_io/qdrant/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/vector_io/sqlite_vec/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/vector_io/sqlite_vec/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/inline/vector_io/sqlite_vec/sqlite_vec.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/registry/agents.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/registry/batches.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/registry/datasetio.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/registry/eval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/registry/files.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/registry/inference.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/registry/post_training.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/registry/safety.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/registry/scoring.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/registry/tool_runtime.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/registry/vector_io.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/datasetio/huggingface/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/datasetio/huggingface/huggingface.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/datasetio/nvidia/datasetio.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/eval/nvidia/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/eval/nvidia/eval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/files/openai/__init__.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/files/openai/config.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/files/openai/files.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/files/s3/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/files/s3/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/files/s3/files.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/anthropic/__init__.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/anthropic/anthropic.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/anthropic/config.py",
        "providers": [
          "anthropic",
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/azure/azure.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/azure/config.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/bedrock/bedrock.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/bedrock/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/cerebras/cerebras.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/cerebras/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/databricks/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/databricks/databricks.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/fireworks/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/fireworks/fireworks.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/gemini/__init__.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/gemini/config.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/gemini/gemini.py",
        "providers": [
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/groq/__init__.py",
        "providers": [
          "groq"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/groq/config.py",
        "providers": [
          "groq",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/groq/groq.py",
        "providers": [
          "groq",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/llama_openai_compat/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/llama_openai_compat/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/llama_openai_compat/llama.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/nvidia/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/nvidia/config.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/nvidia/nvidia.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/oci/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/oci/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/oci/oci.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/ollama/__init__.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/ollama/config.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/ollama/ollama.py",
        "providers": [
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/openai/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/openai/config.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/openai/openai.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/passthrough/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/passthrough/passthrough.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/runpod/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/runpod/runpod.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/sambanova/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/sambanova/sambanova.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/tgi/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/tgi/tgi.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/together/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/together/together.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/vertexai/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/vertexai/vertexai.py",
        "providers": [
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/vllm/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/vllm/config.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/vllm/vllm.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/watsonx/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/inference/watsonx/watsonx.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/post_training/nvidia/models.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/post_training/nvidia/post_training.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/post_training/nvidia/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/safety/bedrock/bedrock.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/safety/bedrock/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/safety/nvidia/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/safety/nvidia/nvidia.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/safety/sambanova/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/safety/sambanova/sambanova.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/tool_runtime/bing_search/bing_search.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/tool_runtime/brave_search/brave_search.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/tool_runtime/model_context_protocol/model_context_protocol.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/tool_runtime/tavily_search/tavily_search.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/tool_runtime/wolfram_alpha/wolfram_alpha.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/vector_io/chroma/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/vector_io/chroma/chroma.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/vector_io/chroma/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/vector_io/milvus/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/vector_io/milvus/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/vector_io/milvus/milvus.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/vector_io/pgvector/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/vector_io/pgvector/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/vector_io/pgvector/pgvector.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/vector_io/qdrant/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/vector_io/qdrant/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/vector_io/qdrant/qdrant.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/vector_io/weaviate/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/vector_io/weaviate/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/remote/vector_io/weaviate/weaviate.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/bedrock/client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/bedrock/config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/common/data_schema_validator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/datasetio/url_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/files/form_data.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/inference/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/inference/embedding_mixin.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/inference/inference_store.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/inference/litellm_openai_mixin.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/inference/model_registry.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/inference/openai_compat.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/inference/openai_mixin.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/inference/prompt_adapter.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/memory/file_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/memory/openai_vector_store_mixin.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/memory/vector_store.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/pagination.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/responses/responses_store.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/scheduler.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/scoring/aggregation_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/scoring/base_scoring_fn.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/providers/utils/tools/mcp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/telemetry/constants.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/telemetry/helpers.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack/testing/api_recorder.py",
        "providers": [
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/__init__.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/agents.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/batches/__init__.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/batches/api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/batches/fastapi_routes.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/batches/models.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/benchmarks.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/common/content_types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/common/errors.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/common/job_types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/common/responses.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/common/training_types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/common/type_system.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/conversations.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/datasetio.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/datasets.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/datatypes.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/eval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/files.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/inference.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/inspect_api.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/internal/sqlstore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/models.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/openai_responses.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/post_training.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/prompts.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/providers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/rag_tool.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/resource.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/safety.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/schema_utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/scoring.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/scoring_functions.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/shields.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/tools.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/vector_io.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/vector_stores.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/src/llama_stack_api/version.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/backward_compat/test_run_config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/common/mcp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/external/llama-stack-api-weather/src/llama_stack_api_weather/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/external/llama-stack-api-weather/src/llama_stack_api_weather/weather.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/external/llama-stack-provider-kaze/src/llama_stack_provider_kaze/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/external/llama-stack-provider-kaze/src/llama_stack_provider_kaze/kaze.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/agents/test_openai_responses.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/batches/conftest.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/batches/test_batches.py",
        "providers": [
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/batches/test_batches_errors.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/batches/test_batches_idempotency.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/conftest.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/conversations/test_openai_conversations.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/datasets/test_datasets.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/eval/test_eval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/files/test_files.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/fixtures/common.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/inference/test_openai_completion.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "llama",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/inference/test_openai_embeddings.py",
        "providers": [
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/inference/test_openai_vision_inference.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/inference/test_provider_data_routing.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/inference/test_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/inference/test_tools_with_schemas.py",
        "providers": [
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/inference/test_vision_inference.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/inspect/test_inspect.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/post_training/test_post_training.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/providers/nvidia/test_datastore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/providers/test_providers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/providers/utils/sqlstore/test_authorized_sqlstore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/responses/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/responses/fixtures/fixtures.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/responses/fixtures/test_cases.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/responses/helpers.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/responses/test_conversation_responses.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/responses/test_tool_responses.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/safety/test_llama_guard.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/safety/test_safety.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/safety/test_vision_safety.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/scoring/test_scoring.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/suites.py",
        "providers": [
          "anthropic",
          "groq",
          "llama",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/telemetry/collectors/otlp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/telemetry/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/telemetry/test_completions.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/test_persistence_integration.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/tool_runtime/test_builtin_tools.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/tool_runtime/test_mcp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/tool_runtime/test_mcp_json_schema.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/tool_runtime/test_registration.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/tools/test_tools.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/vector_io/test_openai_vector_stores.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/integration/vector_io/test_vector_io.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/cli/test_stack_config.py",
        "providers": [
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/conversations/test_api_models.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/conversations/test_conversations.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/core/routers/test_safety_router.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/core/routers/test_vector_io.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/core/test_provider_data_context.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/core/test_stack_validation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/core/test_storage_references.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/distribution/routers/test_routing_tables.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/distribution/test_api_recordings.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/distribution/test_context.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/distribution/test_distribution.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/distribution/test_library_client_initialization.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/distribution/test_stack_list.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/distribution/test_stack_list_deps.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/files/test_files.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/fixtures.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/models/llama/llama3/test_tool_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/models/llama/test_tokenizer_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/models/test_system_prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/prompts/prompts/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/agents/meta_reference/fixtures/__init__.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/agents/meta_reference/test_openai_responses.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/agents/meta_reference/test_openai_responses_conversations.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/agents/meta_reference/test_response_conversion_utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/agents/meta_reference/test_response_tool_context.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/agents/meta_reference/test_responses_safety_utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/agents/meta_reference/test_safety_optional.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/batches/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/batches/test_reference.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/batches/test_reference_idempotency.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/files/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/files/test_s3_files.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/files/test_s3_files_auth.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/inference/bedrock/test_config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/inference/test_bedrock_adapter.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/inference/test_bedrock_config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/inference/test_inference_client_caching.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/inference/test_litellm_openai_mixin.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/inference/test_openai_base_url_config.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/inference/test_remote_vllm.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/inline/agents/meta_reference/responses/test_streaming.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/inline/inference/test_meta_reference.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/nvidia/test_datastore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/nvidia/test_eval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/nvidia/test_parameters.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/nvidia/test_rerank_inference.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/nvidia/test_safety.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/nvidia/test_supervised_fine_tuning.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/test_bedrock.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/test_configs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/utils/inference/test_openai_mixin.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/utils/inference/test_prompt_adapter.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/utils/inference/test_remote_inference_provider_config.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "llama",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/utils/memory/test_reranking.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/utils/memory/test_vector_store.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/utils/test_form_data.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/utils/test_model_registry.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/utils/test_openai_compat_conversion.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/utils/test_scheduler.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/vector_io/conftest.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/vector_io/test_faiss.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/vector_io/test_sqlite_vec.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/vector_io/test_vector_io_openai_vector_stores.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/providers/vector_io/test_vector_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/rag/test_rag_query.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/rag/test_vector_store.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/registry/test_registry.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/registry/test_registry_acl.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/server/test_access_control.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/server/test_auth.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/server/test_auth_github.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/server/test_cors.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/server/test_quota.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/server/test_replace_env_vars.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/server/test_resolver.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/server/test_schema_registry.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/server/test_server.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/server/test_sse.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/tools/test_tools_json_schema.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/utils/inference/test_inference_store.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/utils/kvstore/test_sqlite_memory.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/utils/responses/test_responses_store.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/utils/sqlstore/test_sqlstore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "llamastack-llama-stack-d82a2cd/tests/unit/utils/test_authorized_sqlstore.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "openai/openai-agents-python": {
    "owner": "openai",
    "repo": "openai-agents-python",
    "ref": "main",
    "num_llm_files": 173,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "litellm",
      "llama",
      "mistral",
      "ollama",
      "openai"
    ],
    "files": [
      {
        "file_path": "openai-openai-agents-python-df020d1/docs/scripts/translate_docs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/agent_patterns/routing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/agent_patterns/streaming_guardrails.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/basic/agent_lifecycle_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/basic/hello_world_gpt_5.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/basic/hello_world_gpt_oss.py",
        "providers": [
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/basic/lifecycle_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/basic/non_strict_output_type.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/basic/previous_response_id.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/basic/prompt_template.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/basic/stream_function_call_args.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/basic/stream_text.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/financial_research_agent/agents/search_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/financial_research_agent/agents/verifier_agent.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/financial_research_agent/agents/writer_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/financial_research_agent/manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/hosted_mcp/approvals.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/hosted_mcp/connectors.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/hosted_mcp/simple.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/mcp/filesystem_example/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/mcp/prompt_server/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/mcp/sse_example/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/mcp/streamablehttp_custom_client_example/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/mcp/streamablehttp_example/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/memory/dapr_session_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/memory/openai_session_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/model_providers/custom_example_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/model_providers/custom_example_global.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/model_providers/custom_example_provider.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/model_providers/litellm_auto.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/model_providers/litellm_provider.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/realtime/cli/demo.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/realtime/twilio/twilio_handler.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/realtime/twilio_sip/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/realtime/twilio_sip/server.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/reasoning_content/gpt_oss_stream.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/reasoning_content/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/reasoning_content/runner_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/research_bot/agents/planner_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/research_bot/agents/search_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/research_bot/agents/writer_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/research_bot/manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/tools/code_interpreter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/tools/computer_use.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/tools/file_search.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/tools/web_search_filters.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/examples/voice/streamed/my_workflow.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/_debug.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/_run_impl.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/agent_output.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/extensions/memory/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/extensions/models/litellm_model.py",
        "providers": [
          "anthropic",
          "gemini",
          "litellm",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/extensions/models/litellm_provider.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/function_schema.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/items.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/logger.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/mcp/util.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/memory/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/memory/openai_conversations_session.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/model_settings.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/models/_openai_shared.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/models/chatcmpl_converter.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/models/chatcmpl_helpers.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/models/chatcmpl_stream_handler.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/models/default_models.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/models/fake_id.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/models/interface.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/models/multi_provider.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/models/openai_chatcompletions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/models/openai_provider.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/models/openai_responses.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/prompts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/realtime/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/realtime/agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/realtime/audio_formats.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/realtime/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/realtime/model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/realtime/openai_realtime.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/realtime/runner.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/repl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/result.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/strict_schema.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/tool.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/tool_context.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/tracing/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/tracing/create.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/tracing/logger.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/tracing/processor_interface.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/tracing/processors.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/tracing/provider.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/tracing/span_data.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/usage.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/version.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/voice/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/voice/imports.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/voice/models/openai_model_provider.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/voice/models/openai_stt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/voice/models/openai_tts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/voice/pipeline.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/src/agents/voice/pipeline_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/conftest.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/extensions/memory/test_advanced_sqlite_session.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/extensions/memory/test_sqlalchemy_session.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/fake_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/model_settings/test_serialization.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/models/test_default_models.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/models/test_kwargs_functionality.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/models/test_litellm_chatcompletions_stream.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/models/test_litellm_extra_body.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/models/test_litellm_user_agent.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/models/test_map.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/realtime/test_audio_formats_unit.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/realtime/test_conversion_helpers.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/realtime/test_ga_session_update_normalization.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/realtime/test_item_parsing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/realtime/test_openai_realtime.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/realtime/test_openai_realtime_conversions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/realtime/test_openai_realtime_sip_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/realtime/test_playback_tracker.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/realtime/test_runner.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/realtime/test_session.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/realtime/test_session_payload_and_formats.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/realtime/test_tracing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/realtime/test_twilio_sip_server.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_agent_as_tool.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_agent_memory_leak.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_agent_prompt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_agents_logging.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_anthropic_thinking_blocks.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_call_model_input_filter_unit.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_computer_action.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_debug.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_extended_thinking_message_order.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_extension_filters.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_extra_headers.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_handoff_tool.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_items_helpers.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_local_shell_tool.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_logprobs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_model_payload_iterators.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_openai_chatcompletions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_openai_chatcompletions_converter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_openai_chatcompletions_stream.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_openai_conversations_session.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_openai_responses.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_openai_responses_converter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_reasoning_content.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_responses.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_responses_tracing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_result_cast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_run_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_run_step_processing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_session.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_stream_events.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_stream_input_guardrail_timing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_streaming_tool_call_arguments.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_tool_converter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_tool_metadata.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_tool_output_conversion.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_tool_use_behavior.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_trace_processor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/test_usage.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/tracing/test_processor_api_key.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/tracing/test_set_api_key_fix.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/utils/test_json.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/voice/test_openai_stt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/voice/test_openai_tts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-agents-python-df020d1/tests/voice/test_workflow.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "openai/openai-python": {
    "owner": "openai",
    "repo": "openai-python",
    "ref": "main",
    "num_llm_files": 308,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "openai-openai-python-dc76021/examples/async_demo.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/audio.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/azure.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/azure_ad.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/demo.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/image_stream.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/module_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/parsing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/parsing_stream.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/parsing_tools.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/parsing_tools_stream.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/picture.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/realtime/audio_util.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/realtime/azure_realtime.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/realtime/push_to_talk_app.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/realtime/realtime.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/responses/background.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/responses/background_async.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/responses/background_streaming.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/responses/background_streaming_async.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/responses/streaming.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/responses/streaming_tools.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/responses/structured_outputs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/responses/structured_outputs_tools.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/responses_input_tokens.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/speech_to_text.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/streaming.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/text_to_speech.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/uploads.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/examples/video.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/scripts/detect-breaking-changes.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/_base_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/_exceptions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/_extras/_common.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/_files.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/_legacy_response.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/_models.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/_resource.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/_response.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/_streaming.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/_types.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/_utils/_logs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/_utils/_resources_proxy.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/_utils/_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/_version.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/cli/_api/completions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/cli/_api/files.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/cli/_cli.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/cli/_errors.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/cli/_tools/migrate.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/cli/_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/lib/_old_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/lib/_parsing/_completions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/lib/_realtime.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/lib/_validators.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/lib/azure.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/lib/streaming/chat/_completions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/audio/audio.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/audio/speech.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/audio/transcriptions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/audio/translations.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/batches.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/beta/assistants.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/beta/beta.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/beta/chatkit/chatkit.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/beta/chatkit/sessions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/beta/chatkit/threads.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/beta/realtime/realtime.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/beta/realtime/sessions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/beta/realtime/transcription_sessions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/beta/threads/messages.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/beta/threads/runs/runs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/beta/threads/runs/steps.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/beta/threads/threads.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/chat/chat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/chat/completions/completions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/chat/completions/messages.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/completions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/containers/containers.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/containers/files/content.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/containers/files/files.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/conversations/conversations.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/conversations/items.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/embeddings.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/evals/evals.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/evals/runs/output_items.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/evals/runs/runs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/files.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/fine_tuning/alpha/alpha.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/fine_tuning/alpha/graders.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/fine_tuning/checkpoints/checkpoints.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/fine_tuning/checkpoints/permissions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/fine_tuning/fine_tuning.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/fine_tuning/jobs/checkpoints.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/fine_tuning/jobs/jobs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/images.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/models.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/moderations.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/realtime/calls.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/realtime/client_secrets.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/realtime/realtime.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/responses/input_items.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/responses/input_tokens.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/responses/responses.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/uploads/parts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/uploads/uploads.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/vector_stores/file_batches.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/vector_stores/files.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/vector_stores/vector_stores.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/videos.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/resources/webhooks.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/audio/speech_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/audio/speech_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/audio/transcription.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/audio/transcription_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/audio/transcription_text_delta_event.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/audio/transcription_text_done_event.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/audio/translation_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/audio_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/batch.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/batch_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/batch_usage.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/assistant.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/assistant_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/assistant_stream_event.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/assistant_update_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/file_search_tool.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/file_search_tool_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/realtime/session.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/realtime/session_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/realtime/session_update_event.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/realtime/session_update_event_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/realtime/transcription_session.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/realtime/transcription_session_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/realtime/transcription_session_update.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/realtime/transcription_session_update_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/thread.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/thread_create_and_run_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/thread_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/thread_update_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/threads/image_file.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/threads/image_file_delta.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/threads/image_file_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/threads/message.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/threads/required_action_function_tool_call.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/threads/run.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/threads/run_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/threads/runs/code_interpreter_output_image.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/threads/runs/code_interpreter_tool_call.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/threads/runs/function_tool_call.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/threads/runs/function_tool_call_delta.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/threads/runs/run_step.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/threads/runs/step_list_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/beta/threads/runs/step_retrieve_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/chat/chat_completion.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/chat/chat_completion_assistant_message_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/chat/chat_completion_chunk.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/chat/chat_completion_content_part_image.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/chat/chat_completion_content_part_image_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/chat/chat_completion_message.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/chat/chat_completion_stream_options_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/chat/completion_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/chat/parsed_function_tool_call.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/completion_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/conversations/item_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/conversations/item_retrieve_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/embedding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/embedding_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/evals/create_eval_completions_run_data_source.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/evals/create_eval_completions_run_data_source_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/evals/run_cancel_response.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/evals/run_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/evals/run_create_response.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/evals/run_list_response.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/evals/run_retrieve_response.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/fine_tuning/alpha/grader_run_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/fine_tuning/fine_tuning_job.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/fine_tuning/fine_tuning_job_wandb_integration.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/fine_tuning/job_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/graders/score_model_grader.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/graders/score_model_grader_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/image_create_variation_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/image_edit_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/image_generate_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/moderation_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/realtime/audio_transcription.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/realtime/audio_transcription_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/realtime/call_accept_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/realtime/realtime_audio_config_input.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/realtime/realtime_audio_config_input_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/realtime/realtime_response_create_mcp_tool.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/realtime/realtime_response_create_mcp_tool_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/realtime/realtime_response_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/realtime/realtime_response_create_params_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/realtime/realtime_session_create_request.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/realtime/realtime_session_create_request_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/realtime/realtime_session_create_response.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/realtime/realtime_tools_config_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/realtime/realtime_tools_config_union.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/realtime/realtime_tools_config_union_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/realtime/realtime_transcription_session_audio_input.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/realtime/realtime_transcription_session_audio_input_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/input_token_count_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/response.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/response_compact_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/response_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/response_custom_tool_call.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/response_custom_tool_call_output.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/response_custom_tool_call_output_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/response_custom_tool_call_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/response_format_text_json_schema_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/response_format_text_json_schema_config_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/response_retrieve_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/response_text_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/response_text_config_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/response_usage.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/tool.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/tool_choice_types.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/tool_choice_types_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/responses/tool_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/shared/chat_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/shared/function_definition.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/shared/reasoning.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/shared/response_format_json_schema.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/shared_params/chat_model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/shared_params/function_definition.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/shared_params/reasoning.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/shared_params/response_format_json_schema.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/upload.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/upload_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/vector_store_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/vector_stores/file_batch_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/vector_stores/file_create_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/vector_stores/vector_store_file.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/src/openai/types/vector_stores/vector_store_file_batch.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/audio/test_speech.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/audio/test_transcriptions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/audio/test_translations.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/beta/chatkit/test_sessions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/beta/chatkit/test_threads.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/beta/test_assistants.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/beta/test_threads.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/beta/threads/runs/test_steps.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/beta/threads/test_messages.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/beta/threads/test_runs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/chat/completions/test_messages.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/chat/test_completions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/containers/files/test_content.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/containers/test_files.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/conversations/test_items.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/evals/runs/test_output_items.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/evals/test_runs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/fine_tuning/alpha/test_graders.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/fine_tuning/checkpoints/test_permissions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/fine_tuning/jobs/test_checkpoints.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/fine_tuning/test_jobs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/realtime/test_calls.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/realtime/test_client_secrets.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/responses/test_input_items.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/responses/test_input_tokens.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/test_batches.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/test_completions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/test_containers.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/test_conversations.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/test_embeddings.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/test_evals.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/test_files.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/test_images.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/test_models.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/test_moderations.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/test_responses.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/test_uploads.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/test_vector_stores.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/test_videos.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/test_webhooks.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/uploads/test_parts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/vector_stores/test_file_batches.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/api_resources/vector_stores/test_files.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/compat/test_tool_param.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/conftest.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/lib/chat/test_completions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/lib/chat/test_completions_streaming.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/lib/responses/test_responses.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/lib/snapshots.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/lib/test_assistants.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/lib/test_audio.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/lib/test_azure.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/lib/test_old_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/lib/test_pydantic.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/test_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/test_deepcopy.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/test_extract_files.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/test_files.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/test_legacy_response.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/test_models.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/test_module_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/test_qs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/test_required_args.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/test_response.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/test_streaming.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/test_transform.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/test_utils/test_datetime_parse.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/test_utils/test_logging.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/test_utils/test_proxy.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/test_utils/test_typing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-openai-python-dc76021/tests/utils.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "openai/baselines": {
    "owner": "openai",
    "repo": "baselines",
    "ref": "master",
    "num_llm_files": 10,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "openai-baselines-ea25b9e/baselines/common/tests/test_fixed_sequence.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-baselines-ea25b9e/baselines/common/tests/test_mnist.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-baselines-ea25b9e/baselines/common/tests/test_serialization.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-baselines-ea25b9e/baselines/common/tests/util.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-baselines-ea25b9e/baselines/gail/adversary.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-baselines-ea25b9e/baselines/gail/run_mujoco.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-baselines-ea25b9e/baselines/gail/trpo_mpi.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-baselines-ea25b9e/baselines/her/her.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-baselines-ea25b9e/baselines/logger.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-baselines-ea25b9e/setup.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "openai/swarm": {
    "owner": "openai",
    "repo": "swarm",
    "ref": "main",
    "num_llm_files": 14,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "openai-swarm-0c82d7d/examples/customer_service_streaming/configs/tools/query_docs/handler.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-swarm-0c82d7d/examples/customer_service_streaming/prep_data.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-swarm-0c82d7d/examples/customer_service_streaming/src/evals/eval_function.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-swarm-0c82d7d/examples/customer_service_streaming/src/swarm/engines/assistants_engine.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-swarm-0c82d7d/examples/customer_service_streaming/src/swarm/swarm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-swarm-0c82d7d/examples/customer_service_streaming/src/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-swarm-0c82d7d/examples/support_bot/customer_service.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-swarm-0c82d7d/examples/support_bot/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-swarm-0c82d7d/examples/support_bot/prep_data.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-swarm-0c82d7d/examples/triage_agent/evals_util.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-swarm-0c82d7d/swarm/core.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-swarm-0c82d7d/swarm/types.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-swarm-0c82d7d/tests/mock_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-swarm-0c82d7d/tests/test_core.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "openai/tiktoken": {
    "owner": "openai",
    "repo": "tiktoken",
    "ref": "main",
    "num_llm_files": 5,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "openai-tiktoken-97e49cb/tests/test_misc.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-tiktoken-97e49cb/tests/test_simple_public.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-tiktoken-97e49cb/tiktoken/core.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-tiktoken-97e49cb/tiktoken/model.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "openai-tiktoken-97e49cb/tiktoken_ext/openai_public.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "oshoura/IslamAI": {
    "owner": "oshoura",
    "repo": "IslamAI",
    "ref": "d39fad996040c1fe7917b330996620380b9028af",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "qodo-ai/pr-agent": {
    "owner": "qodo-ai",
    "repo": "pr-agent",
    "ref": "main",
    "num_llm_files": 30,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "groq",
      "langchain",
      "litellm",
      "llama",
      "mistral",
      "ollama",
      "openai"
    ],
    "files": [
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/agent/pr_agent.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/algo/__init__.py",
        "providers": [
          "anthropic",
          "gemini",
          "groq",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/algo/ai_handlers/langchain_ai_handler.py",
        "providers": [
          "gemini",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/algo/ai_handlers/litellm_ai_handler.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "litellm",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/algo/ai_handlers/litellm_helpers.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/algo/ai_handlers/openai_ai_handler.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/algo/cli_args.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/algo/pr_processing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/algo/token_handler.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/cli.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/cli_pip.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/config_loader.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/git_providers/utils.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/servers/github_action_runner.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/tools/pr_add_docs.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/tools/pr_code_suggestions.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/tools/pr_description.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/tools/pr_generate_labels.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/tools/pr_help_docs.py",
        "providers": [
          "anthropic",
          "litellm"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/tools/pr_help_message.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/tools/pr_line_questions.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/tools/pr_questions.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/tools/pr_reviewer.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/tools/pr_similar_issue.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/pr_agent/tools/pr_update_changelog.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/tests/e2e_tests/e2e_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/tests/e2e_tests/langchain_ai_handler.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/tests/unittest/test_aws_secrets_manager_provider.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/tests/unittest/test_config_loader_secrets.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "qodo-ai-pr-agent-ede3f82/tests/unittest/test_get_max_tokens.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "oumi-ai/oumi": {
    "owner": "oumi-ai",
    "repo": "oumi",
    "ref": "main",
    "num_llm_files": 122,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "llama",
      "mistral",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "oumi-ai-oumi-6569f02/configs/projects/dcvlr/synthesize_images_vllm.py",
        "providers": [
          "anthropic",
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/scripts/benchmarks/minimal_multimodal_training.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/scripts/demo.py",
        "providers": [
          "anthropic",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/scripts/examples/batch_inference/bulk_infer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/scripts/inference/gcp_inference.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/scripts/llama_e2e.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/scripts/memcalc.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/scripts/polaris/jobs/python/vllm_inference.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/scripts/polaris/jobs/python/vllm_parallel_inference.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/builders/collators.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/builders/inference_engines.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/cli/alias.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/cli/cache.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/cli/env.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/cli/infer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/collators/vision_language_sft_collator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/configs/analyze_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/configs/inference_config.py",
        "providers": [
          "anthropic",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/configs/inference_engine_type.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/configs/internal/supported_models.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/configs/judge_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/configs/params/deepspeed_params.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/configs/params/evaluation_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/configs/params/generation_params.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/configs/params/grpo_params.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/configs/params/model_params.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/configs/params/synthesis_params.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/configs/quantization_config.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/datasets/base_map_dataset.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/evaluation/backends/alpaca_eval.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/evaluation/backends/lm_harness.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/tokenizers/special_tokens.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/core/trainers/verl_grpo_trainer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/datasets/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/datasets/grpo/gsm8k.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/datasets/preference_tuning/orpo_dpo_mix.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/datasets/pretraining/fineweb_edu.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/datasets/pretraining/red_pajama_v1.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/datasets/pretraining/tiny_stories.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/datasets/pretraining/tiny_textbooks.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/datasets/sft/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/datasets/sft/aya.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/datasets/sft/magpie.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/inference/__init__.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/inference/anthropic_inference_engine.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/inference/bedrock_inference_engine.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/inference/gcp_inference_engine.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/inference/gemini_inference_engine.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/inference/llama_cpp_inference_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/inference/openai_inference_engine.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/inference/remote_inference_engine.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/inference/remote_vllm_inference_engine.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/inference/vllm_inference_engine.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/judge.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/train.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/utils/analysis_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/utils/model_caching.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/utils/str_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/src/oumi/utils/verl_model_merger.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/e2e/test_eval_e2e.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/e2e/test_notebooks.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/e2e/test_sambanova_inference.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/e2e/test_simple_judge.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/e2e/test_train_e2e.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/integration/cli/test_judge_e2e.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/integration/datasets/test_preference_tuning_datasets_full_epoch.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/integration/datasets/test_pretraining_datasets_full_epoch.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/integration/datasets/test_sft_datasets_full_epoch.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/integration/evaluate/test_evaluate_async.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/integration/evaluate/test_evaluate_lm_harness.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/integration/infer/test_infer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/integration/infer/test_native_text_inference_engine.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/integration/infer/test_vllm_inference_engine.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/integration/train/test_custom_models.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/integration/train/test_train.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/integration/tune/test_tune.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/builders/test_build_data.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/builders/test_collators.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/builders/test_data_mixtures.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/builders/test_models.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/builders/test_processors.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/cli/test_cli_alias.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/cli/test_cli_evaluate.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/cli/test_cli_infer.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/cli/test_cli_launch.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/cli/test_cli_synth.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/cli/test_cli_train.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/core/analyze/test_dataset_analyzer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/core/collators/test_text_collator_with_padding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/core/collators/test_text_completions_collator_with_padding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/core/collators/test_vision_language_collator_with_padding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/core/configs/internal/test_supported_models.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/core/datasets/test_base_sft_dataset.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/core/datasets/test_pretraining_dataset.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/core/evaluation/test_backend_alpaca_eval.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/core/evaluation/test_backend_lm_harness.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/core/evaluation/test_evaluator.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/core/evaluation/test_save_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/core/synthesis/test_document_ingestion.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/core/test_distributed.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/datasets/test_chat_templates.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/inference/test_anthropic_inference_engine.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/inference/test_bedrock_inference_engine.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/inference/test_gemini_inference_engine.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/inference/test_generation_params.py",
        "providers": [
          "anthropic",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/inference/test_inference_engine_init.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/inference/test_llama_cpp_inference_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/inference/test_openai_inference_engine.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/inference/test_remote_inference_engine.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/inference/test_sambanova_inference_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/inference/test_sglang_inference_engine.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/inference/test_vllm_inference_engine.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/inference/test_vllm_inference_engine_quantization.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/quantize/test_bnb_quantizer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/quantize/test_quantize_module.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/test_train.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/utils/test_cache_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/utils/test_conversation_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/utils/test_peft_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/utils/test_str_utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "oumi-ai-oumi-6569f02/tests/unit/utils/test_torch_naming_heuristics.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "ranfysvalle02/chatdocs-mdb": {
    "owner": "ranfysvalle02",
    "repo": "chatdocs-mdb",
    "ref": "6322d0ea03d2a3a14fbfaa7ca9f12104e733a72f",
    "num_llm_files": 6,
    "providers": [
      "langchain"
    ],
    "files": [
      {
        "file_path": "ranfysvalle02-chatdocs-mdb-6322d0e/chatdocs/add.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ranfysvalle02-chatdocs-mdb-6322d0e/chatdocs/chains.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ranfysvalle02-chatdocs-mdb-6322d0e/chatdocs/embeddings.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ranfysvalle02-chatdocs-mdb-6322d0e/chatdocs/llms.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ranfysvalle02-chatdocs-mdb-6322d0e/chatdocs/vectorstores.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ranfysvalle02-chatdocs-mdb-6322d0e/setup.py",
        "providers": [
          "langchain"
        ]
      }
    ],
    "error": null
  },
  "realminchoi/babyagi-langchain": {
    "owner": "realminchoi",
    "repo": "babyagi-langchain",
    "ref": "8173232f8abd09f9b9f8942f0b1cd44327cf66b7",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": "failed to download zip zip not found"
  },
  "realrasengan/AIQA": {
    "owner": "realrasengan",
    "repo": "AIQA",
    "ref": "fb86f8c48978bd218df62f6bf034463f0034b426",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "qubvel-org/segmentation_models.pytorch": {
    "owner": "qubvel-org",
    "repo": "segmentation_models.pytorch",
    "ref": "main",
    "num_llm_files": 1,
    "providers": [
      "cohere"
    ],
    "files": [
      {
        "file_path": "qubvel-org-segmentation_models.pytorch-e848409/segmentation_models_pytorch/decoders/dpt/model.py",
        "providers": [
          "cohere"
        ]
      }
    ],
    "error": null
  },
  "neuml/txtai": {
    "owner": "neuml",
    "repo": "txtai",
    "ref": "master",
    "num_llm_files": 24,
    "providers": [
      "anthropic",
      "gemini",
      "litellm",
      "llama",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "neuml-txtai-b5b3922/examples/agent_quickstart.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/examples/images.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/examples/rag_quickstart.py",
        "providers": [
          "llama",
          "ollama",
          "vllm"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/setup.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/src/python/txtai/api/routers/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/src/python/txtai/api/routers/openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/src/python/txtai/pipeline/llm/__init__.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/src/python/txtai/pipeline/llm/factory.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/src/python/txtai/pipeline/llm/litellm.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/src/python/txtai/pipeline/llm/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/src/python/txtai/pipeline/llm/llm.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/src/python/txtai/vectors/dense/__init__.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/src/python/txtai/vectors/dense/factory.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/src/python/txtai/vectors/dense/litellm.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/src/python/txtai/vectors/dense/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/test/python/testagent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/test/python/testapi/testapiagent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/test/python/testapi/testopenai.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/test/python/testoptional.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/test/python/testpipeline/testllm/testlitellm.py",
        "providers": [
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/test/python/testpipeline/testllm/testllama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/test/python/testpipeline/testllm/testllm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/test/python/testvectors/testdense/testlitellm.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "neuml-txtai-b5b3922/test/python/testvectors/testdense/testllama.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "run-llama/rags": {
    "owner": "run-llama",
    "repo": "rags",
    "ref": "main",
    "num_llm_files": 11,
    "providers": [
      "anthropic",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "run-llama-rags-4bec270/1__Home.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-rags-4bec270/core/agent_builder/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-rags-4bec270/core/agent_builder/loader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-rags-4bec270/core/agent_builder/multimodal.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-rags-4bec270/core/builder_config.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-rags-4bec270/core/callback_manager.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-rags-4bec270/core/param_cache.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-rags-4bec270/core/utils.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-rags-4bec270/pages/2__RAG_Config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "run-llama-rags-4bec270/pages/3__Generated_RAG_Agent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-rags-4bec270/st_utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "robiwan303/babyagi": {
    "owner": "robiwan303",
    "repo": "babyagi",
    "ref": "9c22f053675710094576bfc4e6527f59a50e6ac2",
    "num_llm_files": 15,
    "providers": [
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "robiwan303-babyagi-9c22f05/babyagi.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "robiwan303-babyagi-9c22f05/babycoder/babycoder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "robiwan303-babyagi-9c22f05/babycoder/embeddings.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "robiwan303-babyagi-9c22f05/classic/BabyCatAGI.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "robiwan303-babyagi-9c22f05/classic/babyagi.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "robiwan303-babyagi-9c22f05/extensions/argparseext.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "robiwan303-babyagi-9c22f05/extensions/doc_embedding.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "robiwan303-babyagi-9c22f05/extensions/pinecone_storage.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "robiwan303-babyagi-9c22f05/extensions/smart_search.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "robiwan303-babyagi-9c22f05/extensions/weaviate_storage.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "robiwan303-babyagi-9c22f05/ingest.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "robiwan303-babyagi-9c22f05/qa_retrieval.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "robiwan303-babyagi-9c22f05/scraper.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "robiwan303-babyagi-9c22f05/tools/results.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "robiwan303-babyagi-9c22f05/tools/results_browser.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "sagarsaija/gpt4-pdf-chatbot-langchain-chroma": {
    "owner": "sagarsaija",
    "repo": "gpt4-pdf-chatbot-langchain-chroma",
    "ref": "259d5cb6510b0c06b93389810671d73482f9a37c",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "saten-private/BabyCommandAGI": {
    "owner": "saten-private",
    "repo": "BabyCommandAGI",
    "ref": "993f7075479d4d89948410bfec0c4c18d4a06b0c",
    "num_llm_files": 11,
    "providers": [
      "gemini",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "saten-private-BabyCommandAGI-993f707/babyagi.py",
        "providers": [
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "saten-private-BabyCommandAGI-993f707/babycoder/babycoder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "saten-private-BabyCommandAGI-993f707/babycoder/embeddings.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "saten-private-BabyCommandAGI-993f707/classic/BabyCatAGI.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "saten-private-BabyCommandAGI-993f707/classic/babyagi.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "saten-private-BabyCommandAGI-993f707/extensions/argparseext.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "saten-private-BabyCommandAGI-993f707/extensions/pinecone_storage.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "saten-private-BabyCommandAGI-993f707/extensions/ray_tasks.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "saten-private-BabyCommandAGI-993f707/extensions/weaviate_storage.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "saten-private-BabyCommandAGI-993f707/tools/results.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "saten-private-BabyCommandAGI-993f707/tools/results_browser.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "labmlai/annotated_deep_learning_paper_implementations": {
    "owner": "labmlai",
    "repo": "annotated_deep_learning_paper_implementations",
    "ref": "master",
    "num_llm_files": 7,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "labmlai-annotated_deep_learning_paper_implementations-25e1698/labml_nn/diffusion/stable_diffusion/model/clip_embedder.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "labmlai-annotated_deep_learning_paper_implementations-25e1698/labml_nn/lora/experiment.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "labmlai-annotated_deep_learning_paper_implementations-25e1698/labml_nn/rl/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "labmlai-annotated_deep_learning_paper_implementations-25e1698/labml_nn/rl/dqn/experiment.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "labmlai-annotated_deep_learning_paper_implementations-25e1698/labml_nn/rl/game.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "labmlai-annotated_deep_learning_paper_implementations-25e1698/labml_nn/rl/ppo/experiment.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "labmlai-annotated_deep_learning_paper_implementations-25e1698/labml_nn/transformers/gpt/__init__.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "simonw/llm": {
    "owner": "simonw",
    "repo": "llm",
    "ref": "main",
    "num_llm_files": 17,
    "providers": [
      "gemini",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "simonw-llm-14c2e2a/llm/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "simonw-llm-14c2e2a/llm/cli.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "simonw-llm-14c2e2a/llm/default_plugins/openai_models.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "simonw-llm-14c2e2a/llm/migrations.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "simonw-llm-14c2e2a/llm/plugins.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "simonw-llm-14c2e2a/tests/conftest.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "simonw-llm-14c2e2a/tests/test_aliases.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "simonw-llm-14c2e2a/tests/test_cli_openai_models.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "simonw-llm-14c2e2a/tests/test_cli_options.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "simonw-llm-14c2e2a/tests/test_fragments_cli.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "simonw-llm-14c2e2a/tests/test_keys.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "simonw-llm-14c2e2a/tests/test_llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "simonw-llm-14c2e2a/tests/test_llm_logs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "simonw-llm-14c2e2a/tests/test_templates.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "simonw-llm-14c2e2a/tests/test_tools.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "simonw-llm-14c2e2a/tests/test_tools_streaming.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "simonw-llm-14c2e2a/tests/test_utils.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "sgl-project/sglang": {
    "owner": "sgl-project",
    "repo": "sglang",
    "ref": "main",
    "num_llm_files": 583,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "litellm",
      "llama",
      "mistral",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/bench_in_batch_prefix/bench_in_batch_prefix.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/benchmark_batch/benchmark_batch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/benchmark_batch/benchmark_tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/dspy/bench_dspy_intro.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/gsm8k/bench_other.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/gsm8k/bench_sglang.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/hicache/bench_multiturn.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/hicache/bench_serving.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/hicache/data_processing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/json_decode_regex/build_dataset.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/json_jump_forward/bench_other.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/json_jump_forward/build_dataset.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/kernels/deepseek/benchmark_deepgemm_fp8_gemm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/kernels/deepseek/benchmark_deepgemm_fp8_group_gemm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/kernels/flashinfer_allreduce_fusion/benchmark_fused_collective.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/kernels/fused_moe_triton/benchmark_sglang_fused_moe_triton.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/kernels/fused_moe_triton/benchmark_torch_compile_fused_moe.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/kernels/fused_moe_triton/benchmark_vllm_vs_sglang_fused_moe_triton.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/kernels/fused_moe_triton/common_utils.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/kernels/fused_moe_triton/tuning_client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/kernels/fused_moe_triton/tuning_fused_moe_triton.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/kernels/fused_moe_triton/tuning_fused_moe_triton_sep.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/kernels/quantization/bench_int8_quant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/llm_judge/bench_other.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/llm_judge/bench_sglang.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/long_json_decode/build_dataset.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/lora/launch_server.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/lora/lora_bench.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/mmlu/bench_other.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/mmlu/bench_sglang.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/mmmu/bench_sglang.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/mtbench/bench_other.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/mtbench/bench_sglang_eagle.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/multi_document_qa/build_dataset.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/multi_turn_chat/bench_other.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/multi_turn_chat/bench_sglang.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/benchmark/multi_turn_chat/long_prompt_multi_turn.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/quick_start/anthropic_example_chat.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/quick_start/anthropic_example_complete.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/quick_start/azure_openai_example_chat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/quick_start/gemini_example_chat.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/quick_start/gemini_example_complete.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/quick_start/gemini_example_multimodal_chat.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/quick_start/local_example_chat.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/quick_start/local_example_complete.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/quick_start/local_example_llava_next.py",
        "providers": [
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/quick_start/openai_example_chat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/quick_start/openai_example_complete.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/quick_start/openai_example_n.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/quick_start/openai_example_o1.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/quick_start/openrouter_example_chat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/quick_start/together_example_chat.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/quick_start/together_example_complete.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/usage/choices_logprob.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/usage/json_decode.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/usage/json_logprobs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/usage/openai_chat_speculative.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/usage/openai_speculative.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/usage/parallel_sample.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/usage/readme_examples.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/usage/sgl_gen_min_tokens.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/frontend_language/usage/streaming.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/profiler/nsys_profile_tools/gputrc2graph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/runtime/engine/custom_server.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/runtime/engine/launch_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/runtime/engine/offline_batch_inference.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/runtime/engine/offline_batch_inference_eagle.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/runtime/lora.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/runtime/multimodal/llama3_llava_server.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/runtime/multimodal/llava_onevision_server.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/runtime/multimodal/pixtral_server.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/runtime/openai_chat_with_response_prefill.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/runtime/reward_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/runtime/token_in_token_out/token_in_token_out_llm_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/runtime/token_in_token_out/token_in_token_out_llm_server.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/runtime/vertex_predict.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/examples/usage/modelopt_quantize_and_export.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/__init__.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/bench_offline_throughput.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/bench_one_batch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/bench_one_batch_server.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/bench_serving.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/check_env.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/eval/llama3_eval.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/eval/loogle_eval.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/lang/backend/anthropic.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/lang/backend/litellm.py",
        "providers": [
          "litellm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/lang/backend/openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/lang/backend/vertexai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/lang/chat_template.py",
        "providers": [
          "anthropic",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/lang/interpreter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/lang/ir.py",
        "providers": [
          "anthropic",
          "litellm",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/configs/models/encoders/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/configs/models/encoders/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/configs/pipeline_configs/flux.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/configs/pipeline_configs/hunyuan.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/envs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/distributed/communication_op.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/distributed/device_communicators/base_device_communicator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/distributed/device_communicators/cpu_communicator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/distributed/device_communicators/cuda_communicator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/distributed/device_communicators/pynccl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/distributed/device_communicators/pynccl_wrapper.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/distributed/group_coordinator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/distributed/parallel_state.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/distributed/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/entrypoints/cli/cli_types.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/entrypoints/cli/generate.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/entrypoints/cli/main.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/entrypoints/diffusion_generator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/entrypoints/http_server.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/entrypoints/openai/common_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/entrypoints/openai/image_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/entrypoints/openai/stores.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/entrypoints/openai/video_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/layers/activation.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/layers/attention/backends/attention_backend.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/layers/attention/selector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/layers/custom_op.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/layers/layernorm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/layers/linear.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/layers/lora/linear.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/layers/quantization/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/layers/quantization/base_config.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/layers/rotary_embedding.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/layers/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/layers/vocab_parallel_embedding.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/loader/weight_utils.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/managers/forward_context.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/managers/scheduler.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/models/encoders/clip.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/models/encoders/llama.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/models/encoders/mistral_3.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/models/encoders/qwen2_5vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/models/encoders/stepllm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/models/encoders/vision.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/models/parameter.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/models/registry.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/models/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/platforms/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/platforms/cpu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/platforms/cuda.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/platforms/interface.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/platforms/rocm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/utils/hf_diffusers_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/runtime/utils/logging_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/test/cli/test_serve.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/test/server/test_server_common.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/test/server/test_server_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/test/test_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/multimodal_gen/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/batch_invariant_ops/batch_invariant_ops.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/compilation/backend.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/compilation/compilation_config.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/compilation/compilation_counter.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/compilation/compiler_interface.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/compilation/cuda_piecewise_backend.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/compilation/fix_functionalization.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/compilation/fx_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/compilation/inductor_pass.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/compilation/pass_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/configs/chatglm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/configs/dbrx.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/configs/deepseek_ocr.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/configs/deepseekvl2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/configs/dots_vlm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/configs/exaone.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/configs/internvl.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/configs/janus_pro.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/configs/kimi_linear.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/configs/load_config.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/configs/model_config.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/configs/nemotron_h.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/configs/qwen3_next.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/configs/qwen3_omni.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/configs/qwen3_vl.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/configs/radio.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/constrained/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/distributed/communication_op.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/distributed/device_communicators/cuda_wrapper.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/distributed/device_communicators/custom_all_reduce.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/distributed/device_communicators/custom_all_reduce_ops.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/distributed/device_communicators/custom_all_reduce_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/distributed/device_communicators/hpu_communicator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/distributed/device_communicators/pynccl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/distributed/device_communicators/pynccl_wrapper.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/distributed/device_communicators/shm_broadcast.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/distributed/device_communicators/torch_symm_mem.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/distributed/device_communicators/xpu_communicator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/distributed/parallel_state.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/distributed/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/entrypoints/context.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/entrypoints/harmony_utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/entrypoints/http_server.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/entrypoints/openai/encoding_dsv32.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/entrypoints/openai/protocol.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/entrypoints/openai/serving_base.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/entrypoints/openai/serving_chat.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/entrypoints/openai/serving_classify.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/entrypoints/openai/serving_completions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/entrypoints/openai/serving_embedding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/entrypoints/openai/serving_rerank.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/entrypoints/openai/serving_responses.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/entrypoints/openai/serving_score.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/entrypoints/openai/serving_tokenize.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/entrypoints/openai/tool_server.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/entrypoints/openai/usage_processor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/entrypoints/openai/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/environ.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/function_call/base_format_detector.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/function_call/deepseekv31_detector.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/function_call/deepseekv32_detector.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/function_call/deepseekv3_detector.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/function_call/function_call_parser.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/function_call/glm4_moe_detector.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/function_call/gpt_oss_detector.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/function_call/json_array_parser.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/function_call/kimik2_detector.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/function_call/llama32_detector.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/function_call/minimax_m2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/function_call/mistral_detector.py",
        "providers": [
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/function_call/pythonic_detector.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/function_call/qwen25_detector.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/function_call/qwen3_coder_detector.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/function_call/step3_detector.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/function_call/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/hardware_backend/npu/quantization/modelslim.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/activation.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/fla/kda.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/fla/layernorm_gated.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/flashattention_backend.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/flashinfer_backend.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/flashmla_backend.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/mamba/causal_conv1d.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/mamba/causal_conv1d_triton.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/mamba/mamba2_metadata.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/mamba/ops/layernorm_gated.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/mamba/ops/mamba_ssm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/mamba/ops/ssd_bmm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/mamba/ops/ssd_chunk_scan.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/mamba/ops/ssd_chunk_state.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/mamba/ops/ssd_combined.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/mamba/ops/ssd_state_passing.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/triton_ops/prefill_attention.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/trtllm_mla_backend.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/attention/xpu_backend.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/layernorm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/linear.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/moe/fused_moe_triton/fused_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/moe/fused_moe_triton/layer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/moe/fused_moe_triton/triton_kernels_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/moe/moe_runner/triton.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/moe/rocm_moe_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/moe/router.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/moe/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/parameter.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/pooler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/auto_round.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/awq.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/awq_triton.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/base_config.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/blockwise_int8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/compressed_tensors/compressed_tensors.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/compressed_tensors/compressed_tensors_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/compressed_tensors/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/fp8_kernel.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/fp8_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/gguf.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/gptq.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/kv_cache.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/marlin_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/modelopt_quant.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/moe_wna16.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/mxfp4.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/petit.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/quark/quark.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/quark/schemes/quark_w4a4_mxfp4.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/quark/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/quantization/w8a8_int8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/rotary_embedding.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/layers/vocab_parallel_embedding.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/lora/lora.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/lora/torch_ops/lora_ops.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/lora/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/managers/io_struct.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/managers/schedule_batch.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/managers/template_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/model_executor/forward_batch_info.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/model_executor/model_runner.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/model_loader/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/model_loader/loader.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/model_loader/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/model_loader/weight_utils.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/apertus.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/arcee.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/baichuan.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/commandr.py",
        "providers": [
          "cohere",
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/dbrx.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/deepseek.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/deepseek_janus_pro.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/deepseek_ocr.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/deepseek_v2.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/ernie4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/exaone.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/gemma.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/gemma2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/gemma3_causal.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/gemma3_mm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/gemma3n_causal.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/glm4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/glm4v.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/gpt2.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/gpt_bigcode.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/granite.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/hunyuan.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/internlm2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/internvl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/kimi_linear.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/kimi_vl_moonvit.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/llama.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/llama4.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/llama_classification.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/llama_eagle.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/llama_eagle3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/llama_embedding.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/llama_reward.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/llava.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/llavavid.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/mimo_mtp.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/mindspore.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/minicpmo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/minicpmv.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/ministral3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/mistral.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/mistral_large_3.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/mistral_large_3_eagle.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/mixtral.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/mixtral_quant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/mllama.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/mllama4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/nano_nemotron_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/nemotron_h.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/nemotron_nas.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/olmo.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/olmo2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/olmoe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/opt.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/orion.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/phi.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/phi4mm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/pixtral.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/qwen.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/qwen2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/qwen2_5_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/qwen2_audio.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/qwen2_eagle.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/qwen2_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/qwen2_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/radio.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/registry.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/roberta.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/sarashina2_vision.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/solar.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/stablelm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/starcoder2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/teleflm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/torch_native_llama.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/transformers.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/xverse.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/models/yivl.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/multimodal/mm_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/multimodal/processors/llava.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/multimodal/processors/mlama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/multimodal/processors/mllama4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/multimodal/processors/nano_nemotron_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/parser/code_completion_parser.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/parser/conversation.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/parser/jinja_template_utils.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/sampling/custom_logit_processor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/server_args.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/utils/common.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/utils/hf_transformers_utils.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/srt/utils/mistral_utils.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/few_shot_gsm8k.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/few_shot_gsm8k_engine.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/kits/json_constrained_kit.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/kits/matched_stop_kit.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/mmmu_vlm_mixin.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/run_eval.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/runners.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/simple_eval_common.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/simple_eval_gpqa.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/simple_eval_humaneval.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/simple_eval_longbench_v2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/simple_eval_math.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/simple_eval_mgsm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/simple_eval_mmlu.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/simple_eval_mmmu_vlm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/test_custom_ops.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/test_marlin_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/python/sglang/test/test_utils.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/scripts/playground/bench_speculative.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/scripts/playground/disaggregation/cli-so.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/scripts/playground/disaggregation/cli.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/scripts/playground/load_tokenizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/scripts/playground/long_context_example.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/scripts/playground/lora/lora_hf_play.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/scripts/playground/lora/lora_vllm_play.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/scripts/playground/reference_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/benchmark/bench_activation.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/benchmark/bench_awq_dequant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/benchmark/bench_fp8_blockwise_gemm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/benchmark/bench_fp8_gemm.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/benchmark/bench_int8_gemm.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/benchmark/bench_moe_align_block_size.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/benchmark/bench_moe_topk_sigmoid.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/benchmark/bench_moe_topk_softmax.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/benchmark/bench_mrope.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/benchmark/bench_nvfp4_scaled_gemm.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/benchmark/bench_per_tensor_quant_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/benchmark/bench_per_token_quant_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/benchmark/bench_qserve_w4a8_gemm.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/benchmark/bench_rmsnorm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/csrc/moe/marlin_moe_wna16/generate_kernels.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/python/sgl_kernel/elementwise.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/python/sgl_kernel/scalar_type.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/python/sgl_kernel/testing/rotary_embedding.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/tests/test_causal_conv1d.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-kernel/tests/test_norm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/bindings/python/sglang_router/router.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/bindings/python/sglang_router/router_args.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_grpc/basic/test_openai_server.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_grpc/features/test_enable_thinking.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_grpc/features/test_reasoning_content.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_grpc/fixtures.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_grpc/function_call/test_openai_function_calling.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_grpc/function_call/test_tool_choice.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_grpc/util.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_grpc/validation/test_large_max_new_tokens.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_grpc/validation/test_openai_server_ignore_eos.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_http/conftest.py",
        "providers": [
          "gemini",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_http/test_pd_router.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_http/test_regular_router.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_response_api/conftest.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_response_api/features/test_basic_crud.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_response_api/features/test_state_management.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_response_api/features/test_structured_output.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_response_api/features/test_tools_call.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/py_test/e2e_response_api/router_fixtures.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/sgl-model-gateway/scripts/generate_vision_golden.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/lora_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/ascend/test_ascend_w8a8_quantization.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/lang_frontend/test_openai_backend.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/lora/test_lora_cuda_graph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/lora/test_lora_llama4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/lora/test_lora_qwen3_vl.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/lora/test_lora_spec_decoding.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/models/test_clip_models.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/models/test_llama4_models.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/nightly/test_text_models_gsm8k_eval.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/nightly/test_text_models_perf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/nightly/test_vlms_mmmu_eval.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/nightly/test_vlms_piecewise_cuda_graph.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/openai_server/features/test_cache_report.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/openai_server/features/test_continuous_usage_stats.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/openai_server/features/test_structural_tag.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/quant/test_fp8_kvcache.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/test_deepseek_chat_templates.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/test_double_sparsity.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/test_fim_completion.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/test_health_check.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/test_modelopt_fp8kvcache.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/test_srt_engine_with_quant_args.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/test_torch_tp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/test_triton_moe_wna16.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/test_vlm_accuracy.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/manual/test_weight_version.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/llm_models/gsm8k_ascend_mixin.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/llm_models/test_ascend_afm_4_5b.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/llm_models/test_ascend_baichuan2_13b_chat.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/llm_models/test_ascend_c4ai_command_r_v01.py",
        "providers": [
          "cohere",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/llm_models/test_ascend_charglm2_6b.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/llm_models/test_ascend_exaone_3.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/llm_models/test_ascend_gemma_3_1b_it.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/llm_models/test_ascend_granite_3_0_3b_a800m.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/llm_models/test_ascend_granite_3_1_8b.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/llm_models/test_ascend_internlm2_7b.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/llm_models/test_ascend_ling_lite.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/llm_models/test_ascend_llama_2_7b.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/llm_models/test_ascend_mimo_7b_rl.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/llm_models/test_ascend_mistral_7b.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/llm_models/test_ascend_persimmon_8b_chat.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/llm_models/test_ascend_phi_4_multimodal.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/llm_models/test_ascend_smollm_1_7b.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/ascend/vlm_models/test_vlm_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/test_encoder_dp.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/test_gpt_oss_4gpu_perf.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/test_lora_openai_api.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/test_lora_openai_compatible.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/test_lora_radix_cache.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/test_mistral_large3_perf.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/test_text_models_gsm8k_eval.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/test_text_models_perf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/nightly/test_vlms_mmmu_eval.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/registered/function_call/test_function_call_parser.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/registered/function_call/test_json_schema_constraint.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/registered/function_call/test_unknown_tool_name.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/run_suite_nightly.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/ascend/test_ascend_deepep.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/ascend/test_ascend_deepseek_mtp.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/ascend/test_ascend_hicache_mla.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/ascend/test_ascend_mla_fia_w8a8int8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/ascend/test_ascend_mla_w8a8int8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/cpu/test_topk.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/experiment_runner.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/layers/attention/mamba/test_causal_conv1d.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/layers/attention/mamba/test_mamba2_mixer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/layers/attention/mamba/test_mamba_ssm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/layers/attention/mamba/test_mamba_ssm_ssd.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/lora/test_lora_eviction.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/lora/test_lora_update.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/lora/test_multi_lora_backend.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/models/test_compressed_tensors_models.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/models/test_embedding_models.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/models/test_generation_models.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/models/test_ministral3_models.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/models/test_nvidia_nemotron_nano_v2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/models/test_reward_models.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/nightly/test_gsm8k_eval_amd.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/openai_server/basic/test_openai_embedding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/openai_server/basic/test_openai_server.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/openai_server/basic/test_protocol.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/openai_server/basic/test_serving_chat.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/openai_server/basic/test_serving_completions.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/openai_server/basic/test_serving_embedding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/openai_server/features/test_enable_thinking.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/openai_server/features/test_json_mode.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/openai_server/features/test_openai_server_ebnf.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/openai_server/features/test_openai_server_hidden_states.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/openai_server/features/test_reasoning_content.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/openai_server/function_call/test_openai_function_calling.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/openai_server/function_call/test_tool_choice.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/openai_server/validation/test_large_max_new_tokens.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/openai_server/validation/test_openai_server_ignore_eos.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/openai_server/validation/test_request_length_validation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/quant/test_autoround.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/quant/test_awq_dequant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/quant/test_w8a8_quantization.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/run_suite.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_bench_one_batch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_bench_serving.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_bnb.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_constrained_decoding_spec_reasoning.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_disaggregation_basic.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_eagle_infer_a.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_eagle_infer_b.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_fa3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_gpt_oss_common.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_gptqmodel_dynamic.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_jinja_template_utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_llama31_fp4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_mistral_large3_basic.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_modelopt_export.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_modelopt_loader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_piecewise_cuda_graph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_quantization.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_rope_rocm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_server_args.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_srt_endpoint.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_vision_chunked_prefill.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_vision_openai_server_a.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_vision_openai_server_common.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sgl-project-sglang-9a327bd/test/srt/test_vlm_input_format.py",
        "providers": [
          "llama",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "starsnatched/MemGPT-multimodal": {
    "owner": "starsnatched",
    "repo": "MemGPT-multimodal",
    "ref": "82b9b74efa9ad2a04dc531b0ef77a9e229e86e00",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": "failed to download zip zip not found"
  },
  "sczhou/CodeFormer": {
    "owner": "sczhou",
    "repo": "CodeFormer",
    "ref": "master",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "stas00/ml-engineering": {
    "owner": "stas00",
    "repo": "ml-engineering",
    "ref": "master",
    "num_llm_files": 2,
    "providers": [
      "llama",
      "mistral",
      "openai"
    ],
    "files": [
      {
        "file_path": "stas00-ml-engineering-0099885/debug/tiny-scripts/openwebtext-10k.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "stas00-ml-engineering-0099885/training/performance/benchmarks/activation-memory-per-layer.py",
        "providers": [
          "llama",
          "mistral"
        ]
      }
    ],
    "error": null
  },
  "sw5park/LUISE": {
    "owner": "sw5park",
    "repo": "LUISE",
    "ref": "e88343c1e2d1c634a33838500e6cc72aa97fdeaa",
    "num_llm_files": 9,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "sw5park-LUISE-e88343c/scripts/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sw5park-LUISE-e88343c/src/agents/base_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sw5park-LUISE-e88343c/src/agents/task_creation_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sw5park-LUISE-e88343c/tests/test_agents_integration.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sw5park-LUISE-e88343c/tests/test_base_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sw5park-LUISE-e88343c/tests/test_context_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sw5park-LUISE-e88343c/tests/test_prioritization_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sw5park-LUISE-e88343c/tests/test_task_creation_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "sw5park-LUISE-e88343c/utils/embedding.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "szpnygo/VecTextSearch": {
    "owner": "szpnygo",
    "repo": "VecTextSearch",
    "ref": "ec6a1a2861b1399b3463026980c02507702d3508",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": null
  },
  "ushakrishnan/SearchWithOpenAI": {
    "owner": "ushakrishnan",
    "repo": "SearchWithOpenAI",
    "ref": "470a5d10f786efbac2feab18330c69365a937599",
    "num_llm_files": 2,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "ushakrishnan-SearchWithOpenAI-470a5d1/common/funs.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ushakrishnan-SearchWithOpenAI-470a5d1/pages/6_Q&A_with_Open_AI.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "unslothai/unsloth": {
    "owner": "unslothai",
    "repo": "unsloth",
    "ref": "main",
    "num_llm_files": 61,
    "providers": [
      "cohere",
      "gemini",
      "llama",
      "mistral",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "unslothai-unsloth-521e201/tests/qlora/test_hf_qlora_train_and_merge.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/qlora/test_unsloth_qlora_train_and_merge.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/saving/language_models/test_merge_4bit_validation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/saving/language_models/test_merge_model_perplexity_llama-3.2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/saving/language_models/test_merge_model_perplexity_mistral.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/saving/language_models/test_merged_model_perplexity_llama-3.1-8b.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/saving/language_models/test_merged_model_perplexity_qwen_2.5.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/saving/language_models/test_push_to_hub_merged.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/saving/language_models/test_push_to_hub_merged_sharded_index_file.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/saving/language_models/test_save_merged_grpo_model.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/saving/non_peft/test_mistral_non_peft.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/saving/non_peft/test_whisper_non_peft.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/saving/test_unsloth_save.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/saving/text_to_speech_models/test_lasa.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/saving/text_to_speech_models/test_orpheus.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/saving/text_to_speech_models/test_whisper.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/test_model_registry.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/utils/aime_eval.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/tests/utils/hf_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth-cli.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/chat_templates.py",
        "providers": [
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/dataprep/synthetic.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/dataprep/synthetic_configs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/import_fixes.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/kernels/cross_entropy_loss.py",
        "providers": [
          "cohere",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/kernels/flex_attention.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/kernels/moe/benchmark/benchmark_fused_moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/kernels/moe/grouped_gemm/interface.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/kernels/moe/grouped_gemm/reference/layers/llama4_moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/kernels/moe/grouped_gemm/reference/moe_ops.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/kernels/moe/tests/common.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/kernels/moe/tests/test_grouped_gemm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/kernels/moe/tests/test_llama4_moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/kernels/rms_layernorm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/__init__.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/_utils.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/cohere.py",
        "providers": [
          "cohere",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/falcon_h1.py",
        "providers": [
          "cohere",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/gemma.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/gemma2.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/granite.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/llama.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/llama4.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/loader.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/loader_utils.py",
        "providers": [
          "gemini",
          "vllm"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/mapper.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/mistral.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/qwen2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/qwen3.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/qwen3_moe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/rl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/rl_replacements.py",
        "providers": [
          "cohere",
          "vllm"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/models/vision.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/ollama_template_mappers.py",
        "providers": [
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/registry/__init__.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/registry/_deepseek.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/registry/_llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/registry/_mistral.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/save.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "unslothai-unsloth-521e201/unsloth/tokenizer_utils.py",
        "providers": [
          "llama",
          "mistral"
        ]
      }
    ],
    "error": null
  },
  "speechbrain/speechbrain": {
    "owner": "speechbrain",
    "repo": "speechbrain",
    "ref": "develop",
    "num_llm_files": 12,
    "providers": [
      "cohere",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "speechbrain-speechbrain-1e32ef8/recipes/CoVoST/AST/train_w2v2_llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "speechbrain-speechbrain-1e32ef8/recipes/CommonVoice/ASR/transformer/train_with_whisper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "speechbrain-speechbrain-1e32ef8/recipes/LibriSpeech/ASR/CTC/train_with_whisper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "speechbrain-speechbrain-1e32ef8/recipes/LibriSpeech/ASR/transformer/train_with_whisper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "speechbrain-speechbrain-1e32ef8/recipes/LibriTTS/focalcodec/metrics/dwer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "speechbrain-speechbrain-1e32ef8/speechbrain/decoders/seq2seq.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "speechbrain-speechbrain-1e32ef8/speechbrain/inference/text.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "speechbrain-speechbrain-1e32ef8/speechbrain/integrations/huggingface/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "speechbrain-speechbrain-1e32ef8/speechbrain/integrations/huggingface/whisper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "speechbrain-speechbrain-1e32ef8/speechbrain/nnet/unet.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "speechbrain-speechbrain-1e32ef8/speechbrain/processing/multi_mic.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "speechbrain-speechbrain-1e32ef8/tests/consistency/test_recipe.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "vllm-project/vllm": {
    "owner": "vllm-project",
    "repo": "vllm",
    "ref": "main",
    "num_llm_files": 2021,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "langchain",
      "llama",
      "mistral",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "vllm-project-vllm-67312ca/.buildkite/check-wheel-size.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/.buildkite/lm-eval-harness/conftest.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/.buildkite/lm-eval-harness/test_lm_eval_correctness.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/.buildkite/performance-benchmarks/scripts/compare-json-results.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/.buildkite/performance-benchmarks/scripts/convert-results-json-to-markdown.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/.buildkite/scripts/generate-nightly-index.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/backend_request_func.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/benchmark_batch_invariance.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/benchmark_block_pool.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/benchmark_hash.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/benchmark_latency.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/benchmark_long_document_qa_throughput.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/benchmark_ngram_proposer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/benchmark_prefix_block_hash.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/benchmark_prefix_caching.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/benchmark_prioritization.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/benchmark_serving.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/benchmark_serving_structured_output.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/benchmark_throughput.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/benchmark_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/cutlass_benchmarks/sparse_benchmarks.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/cutlass_benchmarks/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/cutlass_benchmarks/w8a8_benchmarks.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/cutlass_benchmarks/weight_shapes.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/disagg_benchmarks/disagg_prefill_proxy_server.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/disagg_benchmarks/rate_limiter.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/disagg_benchmarks/request_queue.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/disagg_benchmarks/round_robin_proxy.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/disagg_benchmarks/visualize_benchmark_results.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/fused_kernels/layernorm_rms_benchmarks.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/bench_block_fp8_gemm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/bench_fp8_gemm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/bench_int8_gemm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/bench_mxfp4_qutlass.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/bench_nvfp4_gemm.py",
        "providers": [
          "gemini",
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/bench_nvfp4_qutlass.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/bench_per_token_quant_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_2d_silu_mul_fp8_quant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_activation.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_bitblas.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_cutlass_fp4_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_cutlass_moe_fp8.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_device_communicators.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_fused_collective.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_grouped_gemm_cutlass.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_layernorm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_lora.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_machete.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_marlin.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_moe.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_moe_align_block_size.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_moe_permute_unpermute.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_mrope.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_paged_attention.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_per_token_group_quant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_quant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_reshape_and_cache.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_reshape_and_cache_flash.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_rmsnorm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_rope.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_shapes.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_silu_mul_fp8_quant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_trtllm_decode_attention.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_trtllm_prefill_attention.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/benchmark_w8a8_block_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/deepgemm/benchmark_fp8_block_dense_gemm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/graph_machete_bench.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/kernels/weight_shapes.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/multi_turn/bench_dataset.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/multi_turn/bench_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/multi_turn/benchmark_serving_multi_turn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/multi_turn/convert_sharegpt_to_openai.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/benchmarks/overheads/benchmark_hashing.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/cmake/hipify.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/csrc/cutlass_extensions/vllm_cutlass_library_extension.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/csrc/moe/marlin_moe_wna16/generate_kernels.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/csrc/quantization/gptq_marlin/generate_kernels.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/csrc/quantization/machete/generate.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/docs/mkdocs/hooks/generate_argparse.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/docs/mkdocs/hooks/generate_examples.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/docs/mkdocs/hooks/remove_announcement.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/docs/mkdocs/hooks/url_schemes.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/async_llm_streaming.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/audio_language.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/automatic_prefix_caching.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/basic/basic.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/basic/chat.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/basic/classify.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/basic/embed.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/basic/generate.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/basic/reward.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/basic/score.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/batch_llm_inference.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/chat_with_tools.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/context_extension.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/data_parallel.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/disaggregated-prefill-v1/decode_example.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/disaggregated-prefill-v1/prefill_example.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/disaggregated_prefill.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/encoder_decoder_multimodal.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/kv_load_failure_recovery/decode_example.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/kv_load_failure_recovery/prefill_example.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/kv_load_failure_recovery/rogue_shared_storage_connector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/llm_engine_example.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/llm_engine_reset_kv.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/load_sharded_state.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/logits_processor/custom.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/logits_processor/custom_req.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/logits_processor/custom_req_init.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/lora_with_quantization_inference.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/metrics.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/mistral-small.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/mlpspeculator.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/multilora_inference.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/prefix_caching.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/prompt_embed_inference.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/qwen2_5_omni/only_thinker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/qwen3_omni/only_thinker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/qwen_1m.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/reproducibility.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/rlhf.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/rlhf_colocate.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/rlhf_online_quant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/rlhf_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/save_sharded_state.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/simple_profiling.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/skip_loading_weights_in_engine_init.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/spec_decode.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/structured_outputs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/torchrun_dp_example.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/torchrun_example.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/vision_language.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/offline_inference/vision_language_multi_image.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/api_client.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/disaggregated_encoder/disagg_epd_proxy.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/disaggregated_serving/disagg_proxy_demo.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/disaggregated_serving_p2p_nccl_xpyd/disagg_proxy_p2p_nccl_xpyd.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/elastic_ep/scale.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/gradio_openai_chatbot_webserver.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/gradio_webserver.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/kv_events_subscriber.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/multi_instance_data_parallel.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/openai_chat_completion_client.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/openai_chat_completion_client_for_multimodal.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/openai_chat_completion_client_with_tools.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/openai_chat_completion_client_with_tools_required.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/openai_chat_completion_client_with_tools_xlam.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/openai_chat_completion_client_with_tools_xlam_streaming.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/openai_chat_completion_tool_calls_with_reasoning.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/openai_chat_completion_with_reasoning.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/openai_chat_completion_with_reasoning_streaming.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/openai_completion_client.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/openai_responses_client.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/openai_responses_client_with_mcp_tools.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/openai_responses_client_with_tools.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/openai_transcription_client.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/openai_translation_client.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/opentelemetry/dummy_client.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/prompt_embed_inference_with_openai_client.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/ray_serve_deepseek.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/retrieval_augmented_generation_with_langchain.py",
        "providers": [
          "langchain",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/retrieval_augmented_generation_with_llamaindex.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/streamlit_openai_chatbot_webserver.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/structured_outputs/structured_outputs.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/token_generation_client.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/online_serving/utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/others/lmcache/cpu_offload_lmcache.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/others/lmcache/disagg_prefill_lmcache_v0.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/others/lmcache/disagg_prefill_lmcache_v1/disagg_proxy_server.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/others/lmcache/kv_cache_sharing_lmcache_v1.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/others/tensorize_vllm_model.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/classify/openai_classification_client.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/embed/embed_jina_embeddings_v3.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/embed/embed_matryoshka_fy.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/embed/embedding_requests_base64_client.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/embed/embedding_requests_bytes_client.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/embed/openai_chat_embedding_client_for_multimodal.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/embed/openai_embedding_client.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/embed/openai_embedding_long_text/client.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/embed/openai_embedding_matryoshka_fy.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/plugin/prithvi_geospatial_mae_client.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/plugin/prithvi_geospatial_mae_io_processor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/plugin/prithvi_geospatial_mae_offline.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/pooling/openai_pooling_client.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/pooling/vision_language_pooling.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/score/cohere_rerank_client.py",
        "providers": [
          "cohere",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/score/convert_model_to_seq_cls.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/score/jinaai_rerank_client.py",
        "providers": [
          "cohere",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/score/openai_cross_encoder_score.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/score/openai_cross_encoder_score_for_multimodal.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/score/qwen3_reranker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/token_classify/ner.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/token_classify/ner_client.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/token_embed/jina_embeddings_v4.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/token_embed/multi_vector_retrieval.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/examples/pooling/token_embed/multi_vector_retrieval_client.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/setup.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/basic_correctness/test_basic_correctness.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/basic_correctness/test_cpu_offload.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/basic_correctness/test_cumem.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/benchmarks/test_latency_cli.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/benchmarks/test_param_sweep.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/benchmarks/test_plot_filters.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/benchmarks/test_random_dataset.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/benchmarks/test_random_multimodal_dataset_video.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/benchmarks/test_serve_cli.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/benchmarks/test_throughput_cli.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/ci_envs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/backend.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/distributed/test_async_tp.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/distributed/test_fusion_all_reduce.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/distributed/test_fusions_e2e.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/distributed/test_sequence_parallelism.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/fullgraph/test_basic_correctness.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/fullgraph/test_full_cudagraph.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/fullgraph/test_full_graph.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/fullgraph/test_multimodal_compile.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/fullgraph/test_multiple_graphs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/fullgraph/test_simple.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/fullgraph/test_toy_llama.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/silly_attention.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/test_aot_compile.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/test_compile_ranges.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/test_config.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/test_decorator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/test_dynamic_shapes_compilation.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/test_functionalization.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/test_fusion.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/test_fusion_attn.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/test_graph_partition.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/test_noop_elimination.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/test_pass_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/test_qk_norm_rope_fusion.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/test_silu_mul_quant_fusion.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/compile/test_wrapper.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/config/test_config_generation.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/config/test_config_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/config/test_mp_reducer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/config/test_multimodal_config.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/conftest.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/cuda/test_cuda_context.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/detokenizer/test_disable_detokenization.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/detokenizer/test_min_tokens.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/detokenizer/test_stop_reason.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/detokenizer/test_stop_string_while_stop_model_terminates.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/detokenizer/test_stop_strings.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/conftest.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/eplb_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_ca_buffer_sharing.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_comm_ops.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_context_parallel.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_custom_all_reduce.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_distributed_oot.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_eplb_algo.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_eplb_execute.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_eplb_fused_moe_layer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_eplb_spec_decode.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_events.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_expert_parallel.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_expert_placement.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_kvlayout.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_multi_node_assignment.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_multiproc_executor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_nccl_symm_mem_allreduce.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_node_count.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_pipeline_parallel.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_pipeline_partition.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_pp_cudagraph.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_pynccl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_quick_all_reduce.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_same_node.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_sequence_parallel.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_shm_broadcast.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_shm_buffer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_shm_storage.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_symm_mem_allreduce.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_torchrun_example.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_torchrun_example_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/distributed/test_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/engine/test_arg_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/engine/test_short_mm_context.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/conftest.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/llm/test_accuracy.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/llm/test_chat.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/llm/test_collective_rpc.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/llm/test_generate.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/llm/test_gpu_utilization.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/llm/test_mm_cache_stats.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/llm/test_prompt_validation.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/offline_mode/test_offline_mode.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/conftest.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/correctness/test_lmeval.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/correctness/test_transcription_api_correctness.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/parser/test_harmony_utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_async_tokenization.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_audio.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_basic.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_chat.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_chat_echo.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_chat_logit_bias_validation.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_chat_template.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_chat_with_tool_reasoning.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_chunked_prompt.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_cli_args.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_collective_rpc.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_completion_with_function_calling.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_completion_with_prompt_embeds.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_default_mm_loras.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_enable_force_include_usage.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_gptoss_structural_tags_integration.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_lora_adapters.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_lora_resolvers.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_messages.py",
        "providers": [
          "anthropic",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_metrics.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_models.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_oot_registration.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_openai_schema.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_optional_middleware.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_orca_metrics.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_prompt_validation.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_protocol.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_response_api_mcp_tools.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_response_api_parsable_context.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_response_api_simple.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_response_api_with_harmony.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_responses_function_call_parsing.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_return_token_ids.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_return_tokens_as_ids.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_root_path.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_run_batch.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_serving_chat.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_serving_engine.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_serving_models.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_serving_responses.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_serving_tokens.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_shutdown.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_sleep.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_tensorizer_entrypoint.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_token_in_token_out.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_tokenization.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_transcription_validation.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_transcription_validation_whisper.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_translation_validation.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_uds.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_video.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_vision.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/test_vision_embeds.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/tool_parsers/conftest.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/tool_parsers/test_gigachat3_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/tool_parsers/test_hermes_tool_parser.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/tool_parsers/test_hunyuan_a13b_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/tool_parsers/test_llama3_json_tool_parser.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/tool_parsers/test_llama4_pythonic_tool_parser.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/tool_parsers/test_olmo3_tool_parser.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/tool_parsers/test_openai_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/tool_parsers/test_pythonic_tool_parser.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/openai/tool_parsers/utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/pooling/basic/test_encode.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/pooling/basic/test_truncation.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/pooling/classify/test_offline.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/pooling/classify/test_online.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/pooling/classify/test_online_vision.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/pooling/embed/test_correctness_mteb.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/pooling/embed/test_offline.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/pooling/embed/test_online.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/pooling/embed/test_online_dimensions.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/pooling/embed/test_online_long_text.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/pooling/embed/test_online_vision.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/pooling/pooling/test_online.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/pooling/reward/test_offline.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/pooling/score/test_correctness_mteb.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/pooling/score/test_offline.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/pooling/score/test_online_rerank.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/pooling/score/test_online_score.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/sagemaker/conftest.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/sagemaker/test_sagemaker_handler_overrides.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/sagemaker/test_sagemaker_lora_adapters.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/sagemaker/test_sagemaker_middleware_integration.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/sagemaker/test_sagemaker_stateful_sessions.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/test_api_server_process_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/test_chat_utils.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/test_context.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/test_renderer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/test_responses_utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/entrypoints/test_ssl_cert_refresher.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/evals/gpt_oss/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/evals/gpt_oss/conftest.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/evals/gpt_oss/test_gpqa_correctness.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/evals/gsm8k/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/evals/gsm8k/conftest.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/evals/gsm8k/gsm8k_eval.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/evals/gsm8k/test_gsm8k_correctness.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/allclose_default.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/conftest.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_aiter_flash_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_attention.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_attention_selector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_cache.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_cascade_flash_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_cpu_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_cutlass_mla_decode.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_deepgemm_attention.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_flash_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_flashinfer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_flashinfer_mla_decode.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_flashinfer_trtllm_attention.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_flashmla.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_flashmla_sparse.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_lightning_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_merge_attn_states.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_mha_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_mla_decode_cpu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_pack_unpack_triton.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_prefix_prefill.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_rocm_attention_selector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_triton_decode_attention.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/attention/test_triton_unified_attention.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/core/test_activation.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/core/test_fused_qk_norm_rope.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/core/test_fused_quant_layernorm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/core/test_layernorm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/core/test_mrope.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/core/test_opcheck.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/core/test_permute_cols.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/core/test_pos_encoding.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/core/test_rotary_embedding.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/core/test_uva.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/mamba/test_causal_conv1d.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/mamba/test_mamba_mixer2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/mamba/test_mamba_ssm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/mamba/test_mamba_ssm_ssd.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/modular_kernel_tools/cli_args.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/modular_kernel_tools/common.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/modular_kernel_tools/make_feature_matrix.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/modular_kernel_tools/mk_objects.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/modular_kernel_tools/parallel_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/modular_kernel_tools/profile_modular_kernel.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/parallel_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_batched_deepgemm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_batched_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_block_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_block_int8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_count_expert_num_tokens.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_cutedsl_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_cutlass_grouped_gemm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_cutlass_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_deepep_deepgemm_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_deepep_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_deepgemm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_flashinfer.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_flashinfer_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_gpt_oss_triton_kernels.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_grouped_topk.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_modular_kernel_combinations.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_modular_oai_triton_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_moe_align_block_size.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_moe_permute_unpermute.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_nvfp4_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_ocp_mx_moe.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_pplx_cutlass_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_pplx_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_rocm_aiter_topk.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_silu_mul_fp8_quant_deep_gemm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_silu_mul_per_token_group_quant_fp8_colmajor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/test_triton_moe_ptpc_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/moe/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quant_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/nvfp4_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_allspark_gemm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_awq.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_awq_triton.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_block_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_block_int8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_cutlass_2of4_sparse.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_cutlass_scaled_mm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_cutlass_w4a8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_flashinfer_nvfp4_scaled_mm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_flashinfer_scaled_mm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_fp8_quant.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_fp8_quant_group.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_ggml.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_gguf.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_gptq.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_hadacore.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_int8_kernel.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_int8_quant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_machete_mm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_marlin_gemm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_mxfp4_qutlass.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_nvfp4_quant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_nvfp4_qutlass.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_nvfp4_scaled_mm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_per_token_group_quant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_rocm_skinny_gemms.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_silu_mul_nvfp4_quant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/quantization/test_triton_scaled_mm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/test_apply_repetition_penalties.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/test_cache_kernels.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/test_fla_layernorm_guard.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/test_flex_attention.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/test_fused_quant_activation.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/test_onednn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/test_shuffle_rows.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/test_top_k_per_row.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/kernels/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/conftest.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_add_lora.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_chatglm3_tp.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_deepseekv2_tp.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_default_mm_loras.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_fused_moe_lora_kernel.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_gptoss_tp.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_layers.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_llama_tp.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_llm_with_multi_loras.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_lora_checkpoints.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_lora_functions.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_lora_huggingface.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_lora_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_minicpmv_tp.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_mixtral.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_moe_lora_align_sum.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_olmoe_tp.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_peft_helper.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_punica_ops.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_quant_model.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_qwen2vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_qwen3moe_tp.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_resolver.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_transformers_model.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/test_worker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/lora/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/model_executor/model_loader/fastsafetensors_loader/test_fastsafetensors_loader.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/model_executor/model_loader/fastsafetensors_loader/test_weight_utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/model_executor/model_loader/runai_streamer_loader/conftest.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/model_executor/model_loader/runai_streamer_loader/test_runai_model_streamer_loader.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/model_executor/model_loader/runai_streamer_loader/test_runai_model_streamer_s3.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/model_executor/model_loader/runai_streamer_loader/test_runai_utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/model_executor/model_loader/runai_streamer_loader/test_weight_utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/model_executor/model_loader/tensorizer_loader/conftest.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/model_executor/model_loader/tensorizer_loader/test_tensorizer.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/model_executor/model_loader/test_registry.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/model_executor/model_loader/test_sharded_state_loader.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/model_executor/test_eagle_quantization.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/model_executor/test_enabled_custom_ops.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/model_executor/test_model_load_with_params.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/model_executor/test_qwen3_omni.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/model_executor/test_weight_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/generation/test_common.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/generation/test_gemma.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/generation/test_granite.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/generation/test_hybrid.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/generation/test_mistral.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/generation/test_phimoe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/generation_ppl_test/ppl_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/generation_ppl_test/test_gemma.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/generation_ppl_test/test_gpt.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/generation_ppl_test/test_qwen.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/embed_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/test_all_pooling_plus_chunked_prefill.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/test_auto_prefix_cache_support.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/test_classification.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/test_embedding.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/test_extract_hidden_states.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/test_gritlm.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/test_head_dtype.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/test_mm_classifier_conversion.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/test_multi_vector_retrieval.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/test_multilabel_classification_support.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/test_nomic_max_model_len.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/test_pooler_config_init_behaviour.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/test_reward.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/test_scoring.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/test_splade_sparse_pooler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/test_token_classification.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling/test_truncation_control.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling_mteb_test/mteb_utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling_mteb_test/test_baai.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling_mteb_test/test_bge_reranker_v2_gemma.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling_mteb_test/test_cross_encoder.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling_mteb_test/test_gte.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling_mteb_test/test_intfloat.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling_mteb_test/test_jina.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling_mteb_test/test_mxbai_rerank.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling_mteb_test/test_nomic.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling_mteb_test/test_qwen3_reranker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling_mteb_test/test_snowflake_arctic_embed.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/language/pooling_mteb_test/test_st_projector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/conftest.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/test_common.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/test_granite_speech.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/test_interleaved.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/test_keye.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/test_maverick.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/test_multimodal_gguf.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/test_phi4mm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/test_pixtral.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/test_qwen2_5_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/test_qwen2_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/test_ultravox.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/test_voxtral.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/test_whisper.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/vlm_utils/builders.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/vlm_utils/case_filtering.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/vlm_utils/core.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/vlm_utils/custom_inputs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/vlm_utils/model_utils.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/vlm_utils/runners.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/generation/vlm_utils/types.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/pooling/conftest.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/pooling/test_clip.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/pooling/test_dse_qwen2_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/pooling/test_intern_vit.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/pooling/test_jinavl_reranker.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/pooling/test_llava_next.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/pooling/test_phi3v.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/pooling/test_prithvi_mae.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/pooling/test_radio.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/pooling/test_siglip.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/processing/test_common.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/processing/test_glm4_1v.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/processing/test_h2ovl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/processing/test_idefics3.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/processing/test_internvl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/processing/test_llama4.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/processing/test_llava_next.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/processing/test_llava_onevision.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/processing/test_minimax_vl_01.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/processing/test_mllama4.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/processing/test_nemotron_vl.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/processing/test_phi3v.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/processing/test_phi4mm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/processing/test_qwen2_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/processing/test_smolvlm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/processing/test_tensor_schema.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/processing/test_transformers.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/multimodal/test_mapping.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/quantization/test_awq.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/quantization/test_bitblas.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/quantization/test_bitsandbytes.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/quantization/test_fp8.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/quantization/test_gguf.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/quantization/test_gpt_oss_attn_quantization.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/quantization/test_gptq_bitblas.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/quantization/test_gptq_marlin.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/quantization/test_gptq_marlin_24.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/quantization/test_modelopt.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/quantization/test_mxfp4.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/quantization/test_nvfp4.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/registry.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/test_gguf_download.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/test_initialization.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/test_oot_registration.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/test_registry.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/test_terratorch.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/test_transformers.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/test_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/test_vision.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/models/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/multimodal/test_audio.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/multimodal/test_cache.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/multimodal/test_hasher.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/multimodal/test_image.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/multimodal/test_processing.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/multimodal/test_registry.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/multimodal/test_utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/multimodal/test_video.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/multimodal/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins/lora_resolvers/test_filesystem_resolver.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins/prithvi_io_processor_plugin/prithvi_io_processor/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins/prithvi_io_processor_plugin/prithvi_io_processor/prithvi_processor.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins/prithvi_io_processor_plugin/prithvi_io_processor/types.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins/prithvi_io_processor_plugin/setup.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins/vllm_add_dummy_model/setup.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins/vllm_add_dummy_model/vllm_add_dummy_model/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins/vllm_add_dummy_model/vllm_add_dummy_model/my_gemma_embedding.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins/vllm_add_dummy_model/vllm_add_dummy_model/my_llava.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins/vllm_add_dummy_model/vllm_add_dummy_model/my_opt.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins/vllm_add_dummy_platform/setup.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins/vllm_add_dummy_platform/vllm_add_dummy_platform/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins/vllm_add_dummy_platform/vllm_add_dummy_platform/dummy_attention_backend.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins/vllm_add_dummy_platform/vllm_add_dummy_platform/dummy_custom_ops.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins/vllm_add_dummy_platform/vllm_add_dummy_platform/dummy_platform.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins/vllm_add_dummy_stat_logger/dummy_stat_logger/dummy_stat_logger.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins/vllm_add_dummy_stat_logger/setup.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins_tests/test_io_processor_plugins.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins_tests/test_platform_plugins.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins_tests/test_scheduler_plugins.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/plugins_tests/test_stats_logger_plugins.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/fp_quant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/reference_mxfp4.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_auto_round.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_blackwell_moe.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_compressed_tensors.py",
        "providers": [
          "cohere",
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_configs.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_cpu_offload.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_cpu_wna16.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_experts_int8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_fp8.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_gptq_dynamic.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_gptq_v2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_ipex_quant.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_lm_head.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_mixed_precision.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_modelopt.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_ptpc_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_quark.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_register_quantization_config.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_rtn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/test_torchao.py",
        "providers": [
          "gemini",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/quantization/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/reasoning/test_base_thinking_reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/reasoning/test_deepseekr1_reasoning_parser.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/reasoning/test_deepseekv3_reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/reasoning/test_ernie45_reasoning_parser.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/reasoning/test_glm4_moe_reasoning_parser.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/reasoning/test_gptoss_reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/reasoning/test_granite_reasoning_parser.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/reasoning/test_holo2_reasoning_parser.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/reasoning/test_hunyuan_reasoning_parser.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/reasoning/test_mistral_reasoning_parser.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/reasoning/test_olmo3_reasoning_parser.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/reasoning/test_qwen3_reasoning_parser.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/reasoning/test_seedoss_reasoning_parser.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/reasoning/utils.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/rocm/aiter/test_grouped_quant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/samplers/test_beam_search.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/samplers/test_ignore_eos.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/samplers/test_logprobs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/samplers/test_no_bad_words.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/standalone_tests/lazy_imports.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/test_config.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/test_embedded_commit.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/test_envs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/test_inputs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/test_logger.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/test_logprobs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/test_outputs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/test_pooling_params.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/test_regression.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/test_routing_simulator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/test_scalartype.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/test_seed_behavior.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/test_sequence.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/test_triton_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/test_version.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/test_vllm_port.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tokenizers_/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tokenizers_/test_basic.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tokenizers_/test_detokenize.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tokenizers_/test_hf.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tokenizers_/test_mistral.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tokenizers_/test_registry.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/conftest.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/mistral/conftest.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/mistral/test_mistral_tool_calls.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/mistral/utils.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/test_chat_completion_request_validations.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/test_chat_completions.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/test_deepseekv31_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/test_ernie45_moe_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/test_glm4_moe_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/test_jamba_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/test_kimi_k2_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/test_minimax_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/test_mistral_tool_parser.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/test_openai_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/test_parallel_tool_calls.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/test_qwen3coder_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/test_seed_oss_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/test_tool_calls.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/test_tool_choice_required.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/test_xlam_tool_parser.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tool_use/utils.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tools/test_config_validator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tpu/lora/test_lora.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tpu/test_compilation.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tpu/test_custom_dispatcher.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tpu/test_moe_pallas.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/tpu/test_quantization_accuracy.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/transformers_utils/test_config.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/transformers_utils/test_config_parser_registry.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/transformers_utils/test_processor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/transformers_utils/test_repo_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/transformers_utils/test_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/utils.py",
        "providers": [
          "anthropic",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/utils_/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/utils_/test_argparse_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/utils_/test_async_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/utils_/test_cache.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/utils_/test_collection_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/utils_/test_func_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/utils_/test_gc_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/utils_/test_hashing.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/utils_/test_import_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/utils_/test_jsontree.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/utils_/test_mem_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/utils_/test_network_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/utils_/test_serial_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/utils_/test_system_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/utils_/test_tensor_schema.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/utils_/test_torch_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/attention/test_attention_backends.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/attention/test_attention_backends_selection.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/attention/test_attention_splitting.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/attention/test_batch_reordering.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/attention/test_chunked_local_attention.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/attention/test_mla_backends.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/attention/test_rocm_attention_backends_selection.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/attention/test_sparse_mla_backends.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/attention/utils.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/core/test_async_scheduler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/core/test_encoder_cache_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/core/test_kv_cache_metrics.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/core/test_kv_cache_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/core/test_kv_sharing.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/core/test_output.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/core/test_prefix_caching.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/core/test_priority_scheduler_random.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/core/test_reset_prefix_cache_e2e.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/core/test_scheduler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/core/test_scheduler_e2e.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/core/test_single_type_kv_cache_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/core/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/cudagraph/test_cudagraph_dispatch.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/cudagraph/test_cudagraph_mode.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/determinism/conftest.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/determinism/test_batch_invariance.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/determinism/test_online_batch_invariance.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/determinism/test_rms_norm_batch_invariant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/determinism/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/distributed/test_async_llm_dp.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/distributed/test_dbo.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/distributed/test_eagle_dp.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/distributed/test_external_lb_dp.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/distributed/test_hybrid_lb_dp.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/distributed/test_internal_lb_dp.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/e2e/test_async_scheduling.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/e2e/test_cascade_attention.py",
        "providers": [
          "anthropic",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/e2e/test_context_length.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/e2e/test_correctness_sliding_window.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/e2e/test_kv_sharing_fast_prefill.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/e2e/test_lora_with_spec_decode.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/e2e/test_min_tokens.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/e2e/test_pooling_chunked_prefill.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/e2e/test_spec_decode.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/ec_connector/integration/test_epd_correctness.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/ec_connector/unit/test_ec_shared_storage_connector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/engine/conftest.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/engine/test_abort_final_step.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/engine/test_async_llm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/engine/test_engine_args.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/engine/test_engine_core.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/engine/test_engine_core_client.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/engine/test_fast_incdec_prefix_err.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/engine/test_llm_engine.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/engine/test_output_processor.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/engine/test_parallel_sampling.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/engine/test_process_multi_modal_uuids.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/engine/utils.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/entrypoints/conftest.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/entrypoints/llm/test_struct_output_generate.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/entrypoints/openai/serving_responses/conftest.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/entrypoints/openai/serving_responses/test_basic.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/entrypoints/openai/serving_responses/test_function_call.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/entrypoints/openai/serving_responses/test_image.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/entrypoints/openai/serving_responses/test_stateful.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/entrypoints/openai/serving_responses/test_structured_output.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/entrypoints/openai/test_chat_completion.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/entrypoints/openai/test_completion.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/entrypoints/openai/test_completion_with_image_embeds.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/entrypoints/openai/test_multi_api_servers.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/executor/test_executor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/nixl_integration/test_accuracy.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/nixl_integration/test_disagg_accuracy.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/nixl_integration/test_edge_cases.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/nixl_integration/toy_proxy_server.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/unit/test_backwards_compatibility.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/unit/test_config.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/unit/test_decode_bench_connector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/unit/test_kv_connector_lifecyle.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/unit/test_kv_load_failure_recovery.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/unit/test_lmcache_integration.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/unit/test_multi_connector.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/unit/test_nixl_connector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/unit/test_offloading_connector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/unit/test_output_aggregator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/unit/test_remote_decode_lifecycle.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/unit/test_remote_prefill_lifecycle.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/unit/test_shared_storage_connector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_connector/unit/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_offload/test_cpu_gpu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_offload/test_cpu_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_offload/test_cpu_offloading.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/kv_offload/test_worker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/logits_processors/test_correctness.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/logits_processors/test_custom_offline.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/logits_processors/test_custom_online.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/logits_processors/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/metrics/test_engine_logger_apis.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/metrics/test_metrics_reader.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/metrics/test_ray_metrics.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/metrics/test_stats.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/sample/test_logprobs.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/sample/test_logprobs_e2e.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/sample/test_rejection_sampler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/sample/test_sampler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/sample/test_sampling_params_e2e.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/sample/test_topk_topp_sampler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/sample/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/shutdown/test_delete.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/shutdown/test_forward_error.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/shutdown/test_processor_error.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/shutdown/test_startup_error.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/shutdown/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/spec_decode/test_eagle.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/spec_decode/test_max_len.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/spec_decode/test_mtp.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/spec_decode/test_ngram.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/spec_decode/test_speculators_eagle3.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/spec_decode/test_tree_attention.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/structured_output/test_backend_guidance.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/structured_output/test_gptoss_structural_tags.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/structured_output/test_reasoning_structured_output.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/structured_output/test_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/test_oracle.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/test_outputs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/test_request.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/test_serial_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/tpu/test_basic.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/tpu/test_kv_cache_update_kernel.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/tpu/test_mha_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/tpu/test_multimodal.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/tpu/test_pallas.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/tpu/test_perf.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/tpu/test_sampler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/tpu/test_spmd_model_weight_loading.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/tpu/test_topk_topp_sampler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/tpu/test_tpu_int8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/tpu/test_tpu_qkv_linear.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/tpu/worker/test_tpu_model_runner.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/tracing/test_tracing.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/worker/test_gpu_input_batch.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/worker/test_gpu_model_runner.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/worker/test_gpu_profiler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/worker/test_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/v1/worker/test_worker_memory_snapshot.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/vllm_test_utils/setup.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/vllm_test_utils/vllm_test_utils/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/vllm_test_utils/vllm_test_utils/blame.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/vllm_test_utils/vllm_test_utils/monitor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tests/weight_loading/test_weight_loading.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tools/generate_cmake_presets.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tools/install_nixl_from_source_ubuntu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tools/pre_commit/check_init_lazy_imports.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tools/pre_commit/check_pickle_imports.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tools/pre_commit/check_spdx_header.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tools/pre_commit/check_triton_import.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tools/pre_commit/enforce_regex_import.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tools/pre_commit/generate_nightly_torch_test.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tools/pre_commit/mypy.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tools/pre_commit/validate_config.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tools/profiler/nsys_profile_tools/gputrc2graph.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tools/profiler/print_layerwise_table.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tools/profiler/visualize_layerwise_profile.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/tools/report_build_time_ninja.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/use_existing_torch.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/_aiter_ops.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/_bc_linter.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/_custom_ops.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/_ipex_ops.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/assets/audio.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/assets/base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/assets/image.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/assets/video.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/backends/abstract.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/backends/registry.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/backends/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/layer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/layers/chunked_local_attention.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/layers/cross_attention.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/layers/encoder_only_attention.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/ops/chunked_prefill_paged_decode.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/ops/common.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/ops/flashmla.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/ops/merge_attn_states.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/ops/paged_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/ops/pallas_kv_cache_update.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/ops/prefix_prefill.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/ops/rocm_aiter_mla_sparse.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/ops/triton_decode_attention.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/ops/triton_merge_attn_states.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/ops/triton_reshape_and_cache_flash.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/ops/triton_unified_attention.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/ops/vit_attn_wrappers.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/selector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/utils/fa_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/utils/kv_sharing_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/attention/utils/kv_transfer_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/beam_search.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/benchmarks/datasets.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/benchmarks/latency.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/benchmarks/lib/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/benchmarks/lib/endpoint_request_func.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/benchmarks/lib/ready_checker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/benchmarks/lib/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/benchmarks/serve.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/benchmarks/sweep/cli.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/benchmarks/sweep/param_sweep.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/benchmarks/sweep/plot.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/benchmarks/sweep/plot_pareto.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/benchmarks/sweep/serve.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/benchmarks/sweep/serve_sla.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/benchmarks/sweep/server.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/benchmarks/sweep/sla_sweep.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/benchmarks/sweep/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/benchmarks/throughput.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/collect_env.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/activation_quant_fusion.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/backends.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/base_static_graph.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/caching.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/collective_fusion.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/compiler_interface.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/counter.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/cuda_graph.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/decorators.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/fix_functionalization.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/fusion.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/fusion_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/fx_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/inductor_pass.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/matcher_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/monitor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/noop_elimination.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/partition_rules.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/pass_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/piecewise_backend.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/post_cleanup.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/qk_norm_rope_fusion.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/sequence_parallelism.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/torch25_custom_graph_pass.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/vllm_inductor_pass.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/compilation/wrapper.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/attention.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/cache.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/compilation.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/device.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/ec_transfer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/kv_events.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/kv_transfer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/load.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/lora.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/model.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/multimodal.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/observability.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/parallel.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/pooler.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/scheduler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/speculative.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/speech_to_text.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/structured_outputs.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/config/vllm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/connections.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/device_allocator/cumem.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/communication_op.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/all2all.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/all_reduce_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/base_device_communicator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/cpu_communicator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/cuda_communicator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/cuda_wrapper.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/custom_all_reduce.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/mnnvl_compat.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/pynccl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/pynccl_allocator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/pynccl_wrapper.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/quick_all_reduce.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/ray_communicator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/shm_broadcast.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/shm_object_storage.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/symm_mem.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/tpu_communicator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/device_communicators/xpu_communicator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/ec_transfer/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/ec_transfer/ec_connector/base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/ec_transfer/ec_connector/factory.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/ec_transfer/ec_connector/shared_storage_connector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/ec_transfer/ec_transfer_state.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/eplb/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/eplb/async_worker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/eplb/eplb_state.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/eplb/policy/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/eplb/policy/abstract.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/eplb/policy/default.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/eplb/rebalance_execute.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_events.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/factory.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/decode_bench_connector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_connector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_integration/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_integration/multi_process_adapter.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_integration/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_integration/vllm_v1_adapter.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_mp_connector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/metrics.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/mooncake_connector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/multi_connector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/offloading_connector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_engine.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/p2p/tensor_memory_pool.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_connector/v1/shared_storage_connector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/kv_transfer/kv_transfer_state.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/parallel_state.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/tpu_distributed_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/distributed/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/engine/arg_utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/engine/async_llm_engine.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/engine/llm_engine.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/engine/protocol.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/anthropic/protocol.py",
        "providers": [
          "anthropic",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/anthropic/serving_messages.py",
        "providers": [
          "anthropic",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/api_server.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/chat_utils.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/cli/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/cli/benchmark/base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/cli/benchmark/latency.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/cli/benchmark/main.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/cli/benchmark/serve.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/cli/benchmark/sweep.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/cli/benchmark/throughput.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/cli/collect_env.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/cli/main.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/cli/openai.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/cli/run_batch.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/cli/serve.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/cli/types.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/constants.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/context.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/launcher.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/llm.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/logger.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/api_server.py",
        "providers": [
          "anthropic",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/cli_args.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/orca_metrics.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/parser/harmony_utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/parser/responses_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/protocol.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/run_batch.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/serving_chat.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/serving_completion.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/serving_engine.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/serving_models.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/serving_responses.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/serving_transcription.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/speech_to_text.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/__init__.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/deepseekv31_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/deepseekv32_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/deepseekv3_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/ernie45_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/gigachat3_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/glm4_moe_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/granite_20b_fc_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/granite_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/hunyuan_a13b_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/internlm2_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/jamba_tool_parser.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/kimi_k2_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/llama4_pythonic_tool_parser.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/llama_tool_parser.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/longcat_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/minimax_m2_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/minimax_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/mistral_tool_parser.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/olmo3_tool_parser.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/openai_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/phi4mini_tool_parser.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/pythonic_tool_parser.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/qwen3coder_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/qwen3xml_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/seed_oss_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/step3_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/tool_parsers/xlam_tool_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/openai/utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/pooling/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/pooling/classify/api_router.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/pooling/classify/protocol.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/pooling/classify/serving.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/pooling/embed/api_router.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/pooling/embed/protocol.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/pooling/embed/serving.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/pooling/pooling/api_router.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/pooling/pooling/protocol.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/pooling/pooling/serving.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/pooling/score/api_router.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/pooling/score/protocol.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/pooling/score/serving.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/renderer.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/responses_utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/sagemaker/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/sagemaker/routes.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/score_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/serve/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/serve/disagg/api_router.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/serve/disagg/protocol.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/serve/disagg/serving.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/serve/elastic_ep/api_router.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/serve/elastic_ep/middleware.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/serve/instrumentator/health.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/serve/instrumentator/metrics.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/serve/lora/api_router.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/serve/profile/api_router.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/serve/rlhf/api_router.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/serve/sleep/api_router.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/serve/tokenize/api_router.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/serve/tokenize/serving.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/ssl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/tool.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/tool_server.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/entrypoints/utils.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/env_override.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/envs.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/forward_context.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/inputs/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/inputs/data.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/inputs/parse.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/inputs/preprocess.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/logger.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/logging_utils/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/logging_utils/dump_input.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/logging_utils/formatter.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/logging_utils/lazy.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/logging_utils/log_time.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/logits_process.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/logprobs.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/layers/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/layers/base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/layers/base_linear.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/layers/column_parallel_linear.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/layers/fused_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/layers/logits_processor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/layers/replicated_linear.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/layers/row_parallel_linear.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/layers/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/layers/vocal_parallel_embedding.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/lora_model.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/lora_weights.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/model_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/ops/ipex_ops/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/ops/ipex_ops/lora_ops.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/ops/torch_ops/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/ops/torch_ops/lora_ops.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/ops/triton_ops/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/ops/triton_ops/fused_moe_lora_op.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/ops/triton_ops/kernel_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/ops/triton_ops/lora_expand_op.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/ops/triton_ops/lora_kernel_metadata.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/ops/triton_ops/lora_shrink_op.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/ops/triton_ops/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/ops/xla_ops/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/ops/xla_ops/lora_ops.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/peft_helper.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/punica_wrapper/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/punica_wrapper/punica_base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/punica_wrapper/punica_cpu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/punica_wrapper/punica_gpu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/punica_wrapper/punica_selector.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/punica_wrapper/punica_tpu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/punica_wrapper/punica_xpu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/punica_wrapper/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/request.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/resolver.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/lora/worker_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/custom_op.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/activation.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/attention_layer_base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/batch_invariant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/conv.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fla/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fla/ops/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fla/ops/chunk.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fla/ops/chunk_delta_h.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fla/ops/chunk_o.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fla/ops/chunk_scaled_dot_kkt.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fla/ops/cumsum.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fla/ops/fused_recurrent.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fla/ops/index.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fla/ops/kda.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fla/ops/l2norm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fla/ops/layernorm_guard.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fla/ops/op.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fla/ops/solve_tril.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fla/ops/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fla/ops/wy_fast.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/all2all_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/config.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/cpu_fused_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/cutlass_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/deep_gemm_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/deep_gemm_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/deepep_ll_prepare_finalize.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/flashinfer_cutedsl_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_prepare_finalize.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/flashinfer_trtllm_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/fused_batched_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/fused_marlin_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/fused_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/fused_moe_method_base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/fused_moe_modular_method.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/gpt_oss_triton_kernels_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/layer.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/modular_kernel.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/moe_align_block_size.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/moe_pallas.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/moe_permute_unpermute.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/moe_torch_iterative.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/prepare_finalize.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/rocm_aiter_fused_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/routing_simulator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/shared_fused_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/topk_weight_and_reduce.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/trtllm_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/fused_moe/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/kda.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/layernorm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/lightning_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/linear.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/logits_processor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/mamba/abstract.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/mamba/linear_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/mamba/mamba_mixer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/mamba/mamba_mixer2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/mamba/mamba_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/mamba/ops/causal_conv1d.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/mamba/ops/layernorm_gated.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/mamba/ops/mamba_ssm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/mamba/ops/ssd_bmm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/mamba/ops/ssd_chunk_scan.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/mamba/ops/ssd_chunk_state.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/mamba/ops/ssd_combined.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/mamba/ops/ssd_state_passing.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/mamba/short_conv.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/mla.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/pooler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/auto_round.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/awq.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/awq_marlin.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/awq_triton.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/base_config.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/bitblas.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/bitsandbytes.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_24.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_24.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_nvfp4.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a4_nvfp4.py",
        "providers": [
          "gemini",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a8_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a8_int.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/transform/linear.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/transform/module.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/transform/schemes/linear_qutlass_nvfp4.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/transform/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/compressed_tensors/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/cpu_wna16.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/deepspeedfp.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/experts_int8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/fbgemm_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/fp_quant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/gguf.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/gptq.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/gptq_bitblas.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/gptq_marlin.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/gptq_marlin_24.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/hqq_marlin.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/inc.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/input_quant_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/ipex_quant.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/mixed_precision/MPLinearKernel.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/mixed_precision/__init__.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/mixed_precision/allspark.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/mixed_precision/bitblas.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/mixed_precision/conch.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/mixed_precision/cutlass.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/mixed_precision/dynamic_4bit.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/mixed_precision/exllama.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/mixed_precision/machete.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/mixed_precision/marlin.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/mixed_precision/xpu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/scaled_mm/ScaledMMLinearKernel.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/scaled_mm/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/scaled_mm/aiter.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/scaled_mm/cpu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/scaled_mm/cutlass.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/scaled_mm/triton.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kernels/scaled_mm/xla.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/kv_cache.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/modelopt.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/moe_wna16.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/mxfp4.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/petit.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/ptpc_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/quark/quark.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/quark/quark_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/quark/schemes/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/quark/schemes/quark_ocp_mx.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_int8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/quark/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/qutlass_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/rtn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/schema.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/torchao.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/tpu_int8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/allspark_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/bitblas_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/flashinfer_fp4_moe.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/flashinfer_utils.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/fp8_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/gptq_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/int8_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/layer_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/machete_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/marlin_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/marlin_utils_fp4.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/marlin_utils_fp8.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/marlin_utils_test.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/marlin_utils_test_24.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/mxfp4_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/mxfp6_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/mxfp8_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/nvfp4_emulation_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/nvfp4_moe_support.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/ocp_mx_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/petit_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/quant_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/quantization/utils/w8a8_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/resampler.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/rotary_embedding/__init__.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/rotary_embedding/base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/rotary_embedding/common.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/rotary_embedding/deepseek_scaling_rope.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/rotary_embedding/dual_chunk_rope.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_alpha_rope.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_scaling_rope.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/rotary_embedding/ernie45_vl_rope.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/rotary_embedding/linear_scaling_rope.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/rotary_embedding/llama3_rope.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/rotary_embedding/llama4_vision_rope.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/rotary_embedding/mrope.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/rotary_embedding/ntk_scaling_rope.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/rotary_embedding/phi3_long_rope_scaled_rope.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/rotary_embedding/xdrope.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/rotary_embedding/yarn_scaling_rope.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/utils.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/layers/vocab_parallel_embedding.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/model_loader/__init__.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/model_loader/base_loader.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/model_loader/bitsandbytes_loader.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/model_loader/default_loader.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/model_loader/dummy_loader.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/model_loader/gguf_loader.py",
        "providers": [
          "cohere",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/model_loader/online_quantization.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/model_loader/runai_streamer_loader.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/model_loader/sharded_state_loader.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/model_loader/tensorizer.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/model_loader/tensorizer_loader.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/model_loader/tpu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/model_loader/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/model_loader/weight_utils.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/adapters.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/afmoe.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/aimv2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/apertus.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/arcee.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/arctic.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/aria.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/aya_vision.py",
        "providers": [
          "cohere",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/baichuan.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/bailing_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/bamba.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/bee.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/bert.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/bert_with_rope.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/blip.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/blip2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/bloom.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/chameleon.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/chatglm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/clip.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/cohere2_vision.py",
        "providers": [
          "cohere",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/commandr.py",
        "providers": [
          "cohere",
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/config.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/dbrx.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/deepencoder.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/deepseek_eagle.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/deepseek_mtp.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/deepseek_ocr.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/deepseek_v2.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/deepseek_vl2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/dots1.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/dots_ocr.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/ernie45.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/ernie45_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/ernie45_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/ernie45_vl_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/ernie_mtp.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/exaone.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/exaone4.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/fairseq2_llama.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/falcon.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/falcon_h1.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/flex_olmo.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/fuyu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/gemma.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/gemma2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/gemma3.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/gemma3_mm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/gemma3n.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/gemma3n_mm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/glm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/glm4.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/glm4_1v.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/glm4_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/glm4_moe_mtp.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/glm4v.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/gpt2.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/gpt_bigcode.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/gpt_j.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/gpt_neox.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/gpt_oss.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/granite.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/granite_speech.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/granitemoe.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/granitemoehybrid.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/granitemoeshared.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/gritlm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/grok1.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/h2ovl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/hunyuan_v1.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/hunyuan_vision.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/hyperclovax_vision.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/idefics2_vision_model.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/idefics3.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/interfaces.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/interfaces_base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/intern_vit.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/internlm2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/internlm2_ve.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/interns1.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/interns1_vit.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/internvl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/jais.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/jamba.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/jina_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/keye.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/keye_vl1_5.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/kimi_linear.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/kimi_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/lfm2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/lfm2_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/lightonocr.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/llama.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/llama4.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/llama4_eagle.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/llama_eagle.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/llama_eagle3.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/llava.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/llava_next.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/llava_next_video.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/llava_onevision.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/longcat_flash.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/longcat_flash_mtp.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/mamba.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/mamba2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/medusa.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/midashenglm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/mimo.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/mimo_mtp.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/minicpm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/minicpm3.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/minicpm_eagle.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/minicpmo.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/minicpmv.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/minimax_m2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/minimax_text_01.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/minimax_vl_01.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/mistral3.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/mistral_large_3.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/mistral_large_3_eagle.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/mixtral.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/mllama4.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/mlp_speculator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/modernbert.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/module_mapping.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/molmo.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/moonvit.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/mpt.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/nano_nemotron_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/nemotron.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/nemotron_h.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/nemotron_nas.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/nemotron_vl.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/nvlm_d.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/olmo.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/olmo2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/olmoe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/opencua.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/openpangu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/openpangu_mtp.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/opt.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/orion.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/ouro.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/ovis.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/ovis2_5.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/paddleocr_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/paligemma.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/persimmon.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/phi.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/phi3.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/phi3v.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/phi4mm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/phi4mm_audio.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/phi4mm_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/phimoe.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/pixtral.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/plamo2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/plamo3.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/qwen.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/qwen2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/qwen2_5_omni_thinker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/qwen2_5_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/qwen2_audio.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/qwen2_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/qwen2_rm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/qwen2_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/qwen3.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/qwen3_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/qwen3_next.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/qwen3_next_mtp.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/qwen3_omni_moe_thinker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/qwen3_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/qwen3_vl_moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/qwen_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/radio.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/registry.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/roberta.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/rvl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/seed_oss.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/siglip.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/siglip2navit.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/skyworkr1v.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/smolvlm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/solar.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/stablelm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/starcoder2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/step3_text.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/step3_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/swin.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/tarsier.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/telechat2.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/teleflm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/terratorch.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/transformers/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/transformers/base.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/transformers/causal.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/transformers/legacy.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/transformers/moe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/transformers/multimodal.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/transformers/pooling.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/transformers/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/ultravox.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/vision.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/voxtral.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/whisper.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/models/zamba2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/parameter.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/warmup/deep_gemm_warmup.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/model_executor/warmup/kernel_warmup.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/multimodal/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/multimodal/audio.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/multimodal/base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/multimodal/cache.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/multimodal/evs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/multimodal/hasher.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/multimodal/image.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/multimodal/inputs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/multimodal/parse.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/multimodal/processing.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/multimodal/profiling.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/multimodal/registry.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/multimodal/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/multimodal/video.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/outputs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/platforms/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/platforms/cpu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/platforms/cuda.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/platforms/interface.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/platforms/rocm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/platforms/tpu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/platforms/xpu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/plugins/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/plugins/io_processors/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/plugins/io_processors/interface.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/plugins/lora_resolvers/filesystem_resolver.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/pooling_params.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/profiler/gpu_profiler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/profiler/layerwise_profile.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/profiler/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/ray/lazy_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/ray/ray_env.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/__init__.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/abs_reasoning_parsers.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/basic_parsers.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/deepseek_r1_reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/deepseek_v3_reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/ernie45_reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/glm4_moe_reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/gptoss_reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/granite_reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/holo2_reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/hunyuan_a13b_reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/identity_reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/minimax_m2_reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/mistral_reasoning_parser.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/olmo3_reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/qwen3_reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/seedoss_reasoning_parser.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/reasoning/step3_reasoning_parser.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/sampling_params.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/scalar_type.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/scripts.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/sequence.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/tasks.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/third_party/pynvml.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/tokenizers/__init__.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/tokenizers/deepseek_v32_encoding.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/tokenizers/deepseekv32.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/tokenizers/detokenizer_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/tokenizers/hf.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/tokenizers/mistral.py",
        "providers": [
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/tokenizers/protocol.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/tokenizers/registry.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/tracing.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/chat_templates/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/chat_templates/registry.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/config.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/config_parser_base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/afmoe.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/arctic.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/chatglm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/deepseek_vl2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/dotsocr.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/eagle.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/falcon.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/flex_olmo.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/hunyuan_vl.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/jais.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/kimi_linear.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/kimi_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/lfm2_moe.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/medusa.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/midashenglm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/mistral.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/mlp_speculator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/moonvit.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/nemotron.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/nemotron_h.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/olmo3.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/ovis.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/qwen3_next.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/radio.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/speculators/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/speculators/algos.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/speculators/base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/step3_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/tarsier2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/configs/ultravox.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/dynamic_module.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/gguf_utils.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/processor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/processors/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/processors/deepseek_ocr.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/processors/deepseek_vl2.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/processors/hunyuan_vl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/processors/hunyuan_vl_image.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/processors/ovis.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/processors/ovis2_5.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/repo_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/runai_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/s3_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/tokenizer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/tokenizer_base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/transformers_utils/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/triton_utils/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/triton_utils/importing.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/usage/usage_lib.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/argparse_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/async_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/cache.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/collection_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/counter.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/deep_gemm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/flashinfer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/func_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/gc_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/hashing.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/import_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/jsontree.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/math_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/mem_constants.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/mem_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/nccl.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/network_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/nvtx_pytorch_hooks.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/platform_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/profiling.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/registry.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/serial_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/system_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/tensor_schema.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/utils/torch_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/cpu_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/flash_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/flashinfer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/flex_attention.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/gdn_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/linear_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/mamba1_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/mamba2_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/mamba_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/mla/aiter_triton_mla.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/mla/common.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/mla/cutlass_mla.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/mla/flashattn_mla.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/mla/flashinfer_mla.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/mla/flashmla.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/mla/flashmla_sparse.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/mla/indexer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/mla/rocm_aiter_mla.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/mla/rocm_aiter_mla_sparse.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/mla/triton_mla.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/pallas.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/rocm_aiter_fa.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/rocm_aiter_unified_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/rocm_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/short_conv_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/tree_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/triton_attn.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/attention/backends/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/core/block_pool.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/core/encoder_cache_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/core/kv_cache_coordinator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/core/kv_cache_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/core/kv_cache_metrics.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/core/kv_cache_utils.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/core/sched/async_scheduler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/core/sched/interface.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/core/sched/output.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/core/sched/request_queue.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/core/sched/scheduler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/core/sched/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/core/single_type_kv_cache_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/cudagraph_dispatcher.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/engine/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/engine/async_llm.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/engine/coordinator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/engine/core.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/engine/core_client.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/engine/detokenizer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/engine/exceptions.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/engine/input_processor.py",
        "providers": [
          "llama",
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/engine/llm_engine.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/engine/logprobs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/engine/output_processor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/engine/parallel_sampling.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/engine/processor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/engine/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/executor/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/executor/abstract.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/executor/multiproc_executor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/executor/ray_distributed_executor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/executor/ray_executor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/executor/ray_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/executor/uniproc_executor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/kv_cache_interface.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/kv_offload/abstract.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/kv_offload/arc_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/kv_offload/backend.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/kv_offload/backends/cpu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/kv_offload/cpu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/kv_offload/factory.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/kv_offload/lru_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/kv_offload/mediums.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/kv_offload/spec.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/kv_offload/worker/cpu_gpu.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/kv_offload/worker/worker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/metrics/loggers.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/metrics/prometheus.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/metrics/ray_wrappers.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/metrics/reader.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/metrics/stats.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/outputs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/pool/metadata.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/request.py",
        "providers": [
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/sample/logits_processor/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/sample/logits_processor/builtin.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/sample/logits_processor/interface.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/sample/logits_processor/state.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/sample/metadata.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/sample/ops/bad_words.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/sample/ops/logprobs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/sample/ops/penalties.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/sample/ops/topk_topp_sampler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/sample/rejection_sampler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/sample/sampler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/sample/tpu/metadata.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/sample/tpu/sampler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/serial_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/spec_decode/eagle.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/spec_decode/medusa.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/spec_decode/metadata.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/spec_decode/metrics.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/spec_decode/ngram_proposer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/spec_decode/suffix_decoding.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/spec_decode/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/structured_output/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/structured_output/backend_guidance.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/structured_output/backend_lm_format_enforcer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/structured_output/backend_outlines.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/structured_output/backend_types.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/structured_output/backend_xgrammar.py",
        "providers": [
          "mistral",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/structured_output/request.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/structured_output/utils.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/block_table.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/cpu_model_runner.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/cpu_worker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/dp_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/ec_connector_model_runner_mixin.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/async_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/attn_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/block_table.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/cudagraph_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/dp_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/input_batch.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/model_runner.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/sample/gumbel.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/sample/logprob.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/sample/metadata.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/sample/min_p.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/sample/penalties.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/sample/sampler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/spec_decode/__init__.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/spec_decode/eagle.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/spec_decode/eagle_cudagraph.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/spec_decode/rejection_sample.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/states.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu/structured_outputs.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu_input_batch.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu_model_runner.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu_ubatch_wrapper.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/gpu_worker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/kv_connector_model_runner_mixin.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/lora_model_runner_mixin.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/tpu_input_batch.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/tpu_model_runner.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/tpu_worker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/ubatch_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/ubatching.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/worker_base.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/xpu_model_runner.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/v1/worker/xpu_worker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "vllm-project-vllm-67312ca/vllm/version.py",
        "providers": [
          "vllm"
        ]
      }
    ],
    "error": null
  },
  "wzpan/wukong-robot": {
    "owner": "wzpan",
    "repo": "wukong-robot",
    "ref": "master",
    "num_llm_files": 3,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "wzpan-wukong-robot-3fd73e0/robot/AI.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "wzpan-wukong-robot-3fd73e0/robot/ASR.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "wzpan-wukong-robot-3fd73e0/robot/Conversation.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "vmayoral/PentestGPT": {
    "owner": "vmayoral",
    "repo": "PentestGPT",
    "ref": "58e80fa92dea24da3d4899aa625b7683100720da",
    "num_llm_files": 17,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "vmayoral-PentestGPT-58e80fa/config/chatgpt_config_sample.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "vmayoral-PentestGPT-58e80fa/extract_cookie.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "vmayoral-PentestGPT-58e80fa/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "vmayoral-PentestGPT-58e80fa/pentestgpt/config/chatgpt_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "vmayoral-PentestGPT-58e80fa/pentestgpt/config/chatgpt_config_sample.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "vmayoral-PentestGPT-58e80fa/pentestgpt/extract_cookie.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "vmayoral-PentestGPT-58e80fa/pentestgpt/main.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "vmayoral-PentestGPT-58e80fa/pentestgpt/test_connection.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "vmayoral-PentestGPT-58e80fa/pentestgpt/utils/chatgpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "vmayoral-PentestGPT-58e80fa/pentestgpt/utils/chatgpt_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "vmayoral-PentestGPT-58e80fa/pentestgpt/utils/chatgpt_browser.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "vmayoral-PentestGPT-58e80fa/pentestgpt/utils/pentest_gpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "vmayoral-PentestGPT-58e80fa/test_connection.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "vmayoral-PentestGPT-58e80fa/utils/chatgpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "vmayoral-PentestGPT-58e80fa/utils/chatgpt_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "vmayoral-PentestGPT-58e80fa/utils/chatgpt_browser.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "vmayoral-PentestGPT-58e80fa/utils/pentest_gpt.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "xtekky/gpt4free": {
    "owner": "xtekky",
    "repo": "gpt4free",
    "ref": "main",
    "num_llm_files": 154,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "groq",
      "langchain",
      "llama",
      "mistral",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/examples/audio.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/examples/mcp_tools_demo.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/examples/messages.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/examples/messages_stream.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/examples/openaichat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/examples/text_completions_demo_async.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/examples/text_completions_demo_sync.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/examples/text_completions_streaming.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/examples/vision_images.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/testing/test_all.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/testing/test_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/testing/test_interference.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/testing/test_mcp_interactive.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/testing/test_needs_auth.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/testing/test_providers.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/tool/commit.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/tool/contributers.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/tool/create_provider.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/tool/md2html.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/tool/readme_table.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/tool/translate_readme.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/tool/vercel.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/unittest/client.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/unittest/integration.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/unittest/mcp.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/etc/unittest/test_reasoning_standardization.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/ApiAirforce.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/Chatai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/Cloudflare.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/Copilot.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/DeepInfra.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/EasyChat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/ItalyGPT.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/LambdaChat.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/OIVSCodeSer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/OperaAria.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/Perplexity.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/PollinationsAI.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/Startnest.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/StringableInference.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/WeWordle.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/Yqcloud.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/audio/OpenAIFM.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/audio/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/deprecated/ARTA.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/deprecated/Blackbox.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/deprecated/DuckDuckGo.py",
        "providers": [
          "anthropic",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/hf_space/CohereForAI_C4AI_Command.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/hf_space/__init__.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/local/Local.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/local/Ollama.py",
        "providers": [
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/local/__init__.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/Anthropic.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/Azure.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/BlackboxPro.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/CablyAI.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/Cerebras.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/Claude.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/Cohere.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/CopilotAccount.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/Custom.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/DeepSeek.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/FenayAI.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/Gemini.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/GeminiCLI.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/GeminiPro.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/GithubCopilot.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/GithubCopilotAPI.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/GlhfChat.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/Groq.py",
        "providers": [
          "groq",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/LMArena.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/Nvidia.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/OpenRouter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/OpenaiAPI.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/OpenaiAccount.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/OpenaiChat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/PerplexityApi.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/PuterJS.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/Replicate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/ThebApi.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/Together.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/You.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/__init__.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/hf/HuggingFaceAPI.py",
        "providers": [
          "groq",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/hf/HuggingFaceInference.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/hf/models.py",
        "providers": [
          "cohere",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/mini_max/MiniMax.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/needs_auth/xAI.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/AI365VIP.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/AiChatOnline.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/AiChats.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/Ails.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/AllenAI.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/AmigoChat.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/ChatGpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/ChatGptEs.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/ChatGptt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/Chatgpt4o.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/ChatgptFree.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/DDG.py",
        "providers": [
          "anthropic",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/Equing.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/FlowGpt.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/Free2GPT.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/FreeGpt.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/FreeNetfly.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/FreeRouter.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/GPROChat.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/Glider.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/Koala.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/LegacyLMArena.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/Liaobots.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/Lockchat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/MagickPen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/PenguinAI.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/Phind.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/Pizzagpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/Poe.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/Raycast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/RubiksAI.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/Theb.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/TypeGPT.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/Vercel.py",
        "providers": [
          "anthropic",
          "cohere",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/Websim.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/not_working/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/openai/har_file.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/openai/models.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/openai/proofofwork.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/qwen/QwenCode.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/template/OpenaiTemplate.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/template/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/Provider/yupp/models.py",
        "providers": [
          "anthropic",
          "gemini"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/api/_tokenizer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/cli/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/client/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/gui/server/config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/integration/langchain.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/integration/markitdown/_llm_caption.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/integration/pydantic_ai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/locals/models.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/locals/provider.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/mcp/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/mcp/__main__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/mcp/server.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/mcp/tools.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/models.py",
        "providers": [
          "cohere",
          "gemini",
          "groq",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/providers/any_model_map.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "groq",
          "llama",
          "mistral",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/providers/any_provider.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/requests/raise_for_status.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/tools/auth.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f/tools/run_tools.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/g4f_cli.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xtekky-gpt4free-aa0aade/setup.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "yangchuansheng/DocsGPT": {
    "owner": "yangchuansheng",
    "repo": "DocsGPT",
    "ref": "595581b624b54046d756ad28bc845521ee4807d0",
    "num_llm_files": 7,
    "providers": [
      "cohere",
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "yangchuansheng-DocsGPT-595581b/application/app.py",
        "providers": [
          "cohere",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "yangchuansheng-DocsGPT-595581b/scripts/ingest.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "yangchuansheng-DocsGPT-595581b/scripts/old/ingest_rst.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "yangchuansheng-DocsGPT-595581b/scripts/old/ingest_rst_sphinx.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "yangchuansheng-DocsGPT-595581b/scripts/parser/file/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "yangchuansheng-DocsGPT-595581b/scripts/parser/open_ai_func.py",
        "providers": [
          "cohere",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "yangchuansheng-DocsGPT-595581b/scripts/parser/schema/base.py",
        "providers": [
          "langchain"
        ]
      }
    ],
    "error": null
  },
  "yanll/YP-GPT": {
    "owner": "yanll",
    "repo": "YP-GPT",
    "ref": "6df9f79f694ba4aaf0dc84867cd44e66c062c99f",
    "num_llm_files": 0,
    "providers": [],
    "files": [],
    "error": "failed to download zip zip not found"
  },
  "uukuguy/DB-GPT-Lite": {
    "owner": "uukuguy",
    "repo": "DB-GPT-Lite",
    "ref": "d857cb71f2c19e8535d0f5e9692e15c4e4dd100d",
    "num_llm_files": 96,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "langchain",
      "llama",
      "mistral",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/_private/config.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/_private/llm_metadata.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/agent/agents/base_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/agent/agents/expand/retrieve_summary_assistant_agent.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/app/chat_adapter.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/app/initialization/embedding_component.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/app/openapi/api_v1/api_v1.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/configs/model_config.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/core/awel/flow/base.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/core/awel/flow/flow_factory.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/core/awel/trigger/http_trigger.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/core/interface/llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/core/interface/message.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/core/interface/output_parser.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/core/interface/tests/test_message.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/adapter/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/adapter/hf_adapter.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/adapter/loader.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/adapter/model_adapter.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/adapter/old_adapter.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/adapter/proxy_adapter.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/adapter/vllm_adapter.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/base.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/cluster/apiserver/api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/cluster/apiserver/tests/test_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/cluster/embedding/loader.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/cluster/embedding/remote_embedding.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/cluster/worker/default_worker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/cluster/worker/embedding_worker.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/llm/conversation.py",
        "providers": [
          "cohere",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/llm/llama_cpp/llama_cpp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/llm/monkey_patch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/llm_out/gpt4all_llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/llm_out/hf_chat_llm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/llm_out/llama_cpp_llm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/llm_out/proxy_llm.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/llm_out/vicuna_llm.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/llm_out/vllm_llm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/operators/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/operators/llm_operator.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/parameter.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/proxy/__init__.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/proxy/base.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/proxy/llms/chatgpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/proxy/llms/claude.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/proxy/llms/gemini.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/utils/chatgpt_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/model/utils/token_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/rag/chunk.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/rag/chunk_manager.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/rag/embedding/embeddings.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/rag/knowledge/csv.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/rag/knowledge/docx.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/rag/knowledge/html.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/rag/knowledge/markdown.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/rag/knowledge/pdf.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/rag/knowledge/pptx.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/rag/knowledge/txt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/rag/knowledge/url.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/rag/operators/knowledge.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/rag/operators/rewrite.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/rag/operators/summary.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/rag/text_splitter/text_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/serve/flow/service/service.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/serve/rag/assembler/summary.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/serve/rag/operators/knowledge_space.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/storage/vector_store/chroma_store.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/storage/vector_store/pgvector_store.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/storage/vector_store/weaviate_store.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/util/benchmarks/llm/llm_benchmarks.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/util/code_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/util/global_helper.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/util/splitter_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/dbgpt/util/system_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/agents/auto_plan_agent_dialogue_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/agents/awel_layout_agents_chat_examples.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/agents/plugin_agent_dialogue_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/agents/retrieve_summary_agent_dialogue_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/agents/single_agent_dialogue_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/agents/single_summary_agent_dialogue_example.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/agents/sql_agent_dialogue_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/awel/data_analyst_assistant.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/awel/simple_chat_dag_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/awel/simple_chat_history_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/awel/simple_llm_client_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/awel/simple_nl_schema_sql_chart_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/awel/simple_rag_rewrite_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/awel/simple_rag_summary_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/rag/rag_embedding_api_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/rag/rewrite_rag_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/rag/simple_rag_retriever_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/rag/summary_extractor_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/sdk/simple_sdk_llm_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/examples/sdk/simple_sdk_llm_sql_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/setup.py",
        "providers": [
          "langchain",
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "uukuguy-DB-GPT-Lite-d857cb7/tests/unit_tests/test_plugins.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "ymcui/Chinese-LLaMA-Alpaca-2": {
    "owner": "ymcui",
    "repo": "Chinese-LLaMA-Alpaca-2",
    "ref": "main",
    "num_llm_files": 21,
    "providers": [
      "langchain",
      "llama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/attn_and_long_ctx_patches.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/ceval/eval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/ceval/llama_evaluator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/cmmlu/eval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/cmmlu/llama2_evaluator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/inference/flash_attn_patch_for_inference.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/inference/gradio_demo.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/inference/inference_hf.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/langchain/langchain_qa.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/langchain/langchain_sum.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/longbench/pred_llama2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/merge_llama2_with_chinese_lora_low_mem.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/openai_server_demo/openai_api_protocol.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/openai_server_demo/openai_api_protocol_vllm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/openai_server_demo/openai_api_server.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/openai_server_demo/openai_api_server_vllm.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/privategpt/privateGPT.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/privategpt/privateGPT_refine.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/training/peft/mapping.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/training/run_clm_pt_with_peft.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-2-a1a5203/scripts/training/run_clm_sft_with_peft.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "yoheinakajima/babyagi": {
    "owner": "yoheinakajima",
    "repo": "babyagi",
    "ref": "3532f987744e9254afacc254e3325d1910c0651d",
    "num_llm_files": 1,
    "providers": [
      "openai"
    ],
    "files": [
      {
        "file_path": "yoheinakajima-babyagi-3532f98/babyagi.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "yujiosaka/ChatIQ": {
    "owner": "yujiosaka",
    "repo": "ChatIQ",
    "ref": "def21481b0c132173b51d1d7a314b103db324ca2",
    "num_llm_files": 37,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/block_builders/home_screen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/chat_chain.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/chatiq.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/document_loaders/dummy_message.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/document_loaders/message.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/document_loaders/pdf.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/document_loaders/plain_text.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/document_loaders/slack_link.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/document_loaders/unfurlink_link.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/handlers/app_mention.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/handlers/message.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/models/slack_team.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/prompt.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/retriever.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/settings.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/text_processor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/utils.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/chatiq/vectorstore.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/block_builders/test_home_screen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/document_loaders/test_message.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/document_loaders/test_pdf.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/document_loaders/test_plain_text.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/document_loaders/test_slack_link.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/document_loaders/test_unfurling_link.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/handlers/test_app_home_opened.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/handlers/test_app_mention.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/handlers/test_context_save.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/handlers/test_file_shared.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/handlers/test_message.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/handlers/test_model_select.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/handlers/test_temperature_select.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/test_chat_chain.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/test_chatiq.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/test_retriever.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/test_text_processor.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/test_utils.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "yujiosaka-ChatIQ-def2148/tests/test_vectorstore.py",
        "providers": [
          "langchain"
        ]
      }
    ],
    "error": null
  },
  "yvann-hub/Robby-chatbot": {
    "owner": "yvann-hub",
    "repo": "Robby-chatbot",
    "ref": "5beb6894c8ba0d0b67188ba2be568a2a22a00491",
    "num_llm_files": 7,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "yvann-ba-Robby-chatbot-5beb689/src/chatbot_csv.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "yvann-ba-Robby-chatbot-5beb689/src/modules/chatbot.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "yvann-ba-Robby-chatbot-5beb689/src/modules/embedder.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "yvann-ba-Robby-chatbot-5beb689/src/modules/layout.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yvann-ba-Robby-chatbot-5beb689/src/modules/sidebar.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "yvann-ba-Robby-chatbot-5beb689/src/modules/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "yvann-ba-Robby-chatbot-5beb689/src/tuto_chatbot_csv.py",
        "providers": [
          "langchain",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "zhayujie/chatgpt-on-wechat": {
    "owner": "zhayujie",
    "repo": "chatgpt-on-wechat",
    "ref": "master",
    "num_llm_files": 28,
    "providers": [
      "anthropic",
      "gemini",
      "llama",
      "mistral",
      "openai"
    ],
    "files": [
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/ali/ali_qwen_bot.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/baidu/baidu_wenxin_session.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/bot_factory.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/chatgpt/chat_gpt_bot.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/chatgpt/chat_gpt_session.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/claude/claude_ai_bot.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/claude/claude_ai_session.py",
        "providers": [
          "anthropic"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/claudeapi/claude_api_bot.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/dashscope/dashscope_bot.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/gemini/google_gemini_bot.py",
        "providers": [
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/linkai/link_ai_bot.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/minimax/minimax_bot.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/modelscope/modelscope_bot.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/moonshot/moonshot_bot.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/openai/open_ai_bot.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/openai/open_ai_image.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/openai/open_ai_session.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bot/zhipuai/zhipuai_bot.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/bridge/bridge.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/channel/chat_channel.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/common/const.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/config.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/plugins/agent/agent.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/plugins/godcmd/godcmd.py",
        "providers": [
          "anthropic",
          "gemini",
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/plugins/tool/tool.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/voice/factory.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/voice/linkai/linkai_voice.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhayujie-chatgpt-on-wechat-7e12744/voice/openai/openai_voice.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "ymcui/Chinese-LLaMA-Alpaca": {
    "owner": "ymcui",
    "repo": "Chinese-LLaMA-Alpaca",
    "ref": "main",
    "num_llm_files": 16,
    "providers": [
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-090475f/scripts/ceval/eval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-090475f/scripts/ceval/llama_evaluator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-090475f/scripts/crawl_prompt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-090475f/scripts/inference/gradio_demo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-090475f/scripts/inference/inference_hf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-090475f/scripts/inference/patches.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-090475f/scripts/langchain/langchain_qa.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-090475f/scripts/langchain/langchain_sum.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-090475f/scripts/merge_llama_with_chinese_lora.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-090475f/scripts/merge_llama_with_chinese_lora_low_mem.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-090475f/scripts/merge_tokenizer/merge_tokenizers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-090475f/scripts/openai_server_demo/openai_api_protocol.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-090475f/scripts/openai_server_demo/openai_api_server.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-090475f/scripts/openai_server_demo/patches.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-090475f/scripts/training/run_clm_pt_with_peft.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "ymcui-Chinese-LLaMA-Alpaca-090475f/scripts/training/run_clm_sft_with_peft.py",
        "providers": [
          "llama"
        ]
      }
    ],
    "error": null
  },
  "xorbitsai/inference": {
    "owner": "xorbitsai",
    "repo": "inference",
    "ref": "main",
    "num_llm_files": 153,
    "providers": [
      "anthropic",
      "cohere",
      "langchain",
      "llama",
      "mistral",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "xorbitsai-inference-8addbfb/benchmark/benchmark_runner.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/benchmark/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/doc/source/gen_docs.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/examples/AI_podcast.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/examples/AI_podcast_ZH.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/examples/LangChain_Streamlit_Doc_Chat.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/examples/gradio_chatinterface.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/_compat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/api/restful_api.py",
        "providers": [
          "anthropic",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/client/common.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/client/restful/async_restful_client.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/client/restful/restful_client.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/client/tests/test_async_client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/client/tests/test_async_client_with_auth.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/client/tests/test_client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/client/tests/test_client_with_auth.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/core/model.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/core/supervisor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/core/tests/test_metrics.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/core/tests/test_restful_api.py",
        "providers": [
          "anthropic",
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/core/tests/test_types.py",
        "providers": [
          "anthropic",
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/core/tests/test_worker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/core/worker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/deploy/cmdline.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/deploy/test/test_cmdline.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/deploy/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/fields.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/audio/fish_speech.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/audio/funasr.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/audio/tests/test_chattts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/audio/tests/test_cosyvoice.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/audio/tests/test_f5tts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/audio/tests/test_f5tts_mlx.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/audio/tests/test_fish_speech.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/audio/tests/test_funasr.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/audio/tests/test_kokoro.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/audio/tests/test_melotts.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/audio/tests/test_whisper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/audio/tests/test_whisper_mlx.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/embedding/__init__.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/embedding/core.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/embedding/embed_family.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/embedding/llama_cpp/core.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/embedding/llama_cpp/tests/test_llama_cpp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/embedding/sentence_transformers/core.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/embedding/tests/test_integrated_embedding.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/embedding/vllm/core.py",
        "providers": [
          "langchain",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/embedding/vllm/tests/test_vllm_embedding.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/image/tests/test_stable_diffusion.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/__init__.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/llama_cpp/core.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/llama_cpp/tests/test_gguf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/llm_family.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/memory.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/sglang/core.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/tests/test_llm_family.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/tests/test_llm_model.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/tests/test_multimodal.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/tests/test_stream_options.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/tool_parsers/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/tool_parsers/deepseek_r1_tool_parser.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/tool_parsers/deepseek_v3_tool_parser.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/tool_parsers/llama3_tool_parser.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/transformers/chatglm.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/transformers/core.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/transformers/multimodal/core.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/transformers/multimodal/deepseek_vl2.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/transformers/multimodal/glm4_1v.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/transformers/multimodal/glm4v.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/transformers/multimodal/intern_vl.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/transformers/multimodal/minicpmv26.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/transformers/multimodal/minicpmv45.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/transformers/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/vllm/core.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/vllm/distributed_executor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/vllm/distributed_executor_v1.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/vllm/tests/test_core_chat_model.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/vllm/tests/test_distributed_executor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/vllm/utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/vllm/xavier/allocator.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/vllm/xavier/block.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/vllm/xavier/block_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/vllm/xavier/block_tracker.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/vllm/xavier/collective_manager.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/vllm/xavier/engine.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/vllm/xavier/executor.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/vllm/xavier/scheduler.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/vllm/xavier/test/test_xavier.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/llm/vllm/xavier/transfer.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/rerank/__init__.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/rerank/core.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/rerank/llama_cpp/core.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/rerank/llama_cpp/tests/test_llama_cpp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/rerank/rerank_family.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/rerank/sentence_transformers/core.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/rerank/tests/test_rerank.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/rerank/vllm/core.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/rerank/vllm/tests/test_vllm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/model/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/audiotools/core/whisper.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/cosyvoice/cli/cosyvoice.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/cosyvoice/cli/model.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/cosyvoice/llm/llm.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/cosyvoice/transformer/embedding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/cosyvoice/transformer/positionwise_feed_forward.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/cosyvoice/transformer/subsampling.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/cosyvoice/utils/file_utils.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/cosyvoice/vllm/cosyvoice2.py",
        "providers": [
          "vllm"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/deepseek_vl/models/modeling_vlm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/deepseek_vl/models/processing_vlm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/deepseek_vl/utils/conversation.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/deepseek_vl2/models/conversation.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/deepseek_vl2/models/modeling_deepseek.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/deepseek_vl2/models/processing_deepseek_vl_v2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/f5_tts/infer/utils_infer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/f5_tts/model/modules.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/fish_speech/models/text2semantic/lit_module.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/fish_speech/models/text2semantic/llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/fish_speech/tokenizer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/fish_speech/train.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/fish_speech/webui/manage.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/tools/api_server.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/tools/inference_engine/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/tools/llama/eval_in_context.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/tools/llama/generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/tools/llama/merge_lora.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/tools/llama/quantize.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/tools/run_webui.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/tools/server/agent/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/tools/server/agent/pre_generation_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/tools/server/api_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/tools/server/model_manager.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/tools/server/views.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/fish_speech/tools/webui/variables.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/indextts/gpt/transformers_generation_utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/indextts/gpt/transformers_gpt2.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/indextts/gpt/transformers_modeling_utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/indextts/s2mel/modules/diffusion_transformer.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/indextts/s2mel/modules/gpt_fast/model.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/indextts/s2mel/modules/gpt_fast/quantize.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/indextts/utils/maskgct/models/tts/maskgct/llama_nar.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/indextts/utils/maskgct/models/tts/maskgct/maskgct_s2a.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/internvl/conversation.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/llava/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/llava/mm_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/llava/model/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/llava/model/llava_llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/megatts3/tts/modules/aligner/whisper_small.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/whisper/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/whisper/decoding.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/thirdparty/whisper/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "xorbitsai-inference-8addbfb/xinference/types.py",
        "providers": [
          "anthropic",
          "cohere",
          "openai"
        ]
      }
    ],
    "error": null
  },
  "zilliztech/GPTCache": {
    "owner": "zilliztech",
    "repo": "GPTCache",
    "ref": "main",
    "num_llm_files": 75,
    "providers": [
      "cohere",
      "langchain",
      "llama",
      "openai"
    ],
    "files": [
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/docs/bootcamp/streamlit/gptcache-streamlit-audio/audio.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/docs/bootcamp/streamlit/gptcache-streamlit-image/imagen.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/docs/conf.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/adapter/langchain_llms.py",
        "providers": [
          "cohere",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/adapter/openai_chatgpt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/benchmark/benchmark_sqlite_faiss_onnx.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/context_process/selective_context.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/context_process/summarization_context.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/data_manager/map_manager.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/data_manager/scalar_store.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/data_manager/vector_store.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/embedding/default.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/embedding/onnx.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/embedding/paddlenlp.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/embedding/random.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/integrate/langchain/langchain_llms_mock.py",
        "providers": [
          "cohere",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/integrate/langchain/langchain_prompt_openai.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/integrate/langchain/langchain_qa_chain.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/integrate/langchain/langchain_similaritycache_openai.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/integrate/llama_cpp/basic_usage.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/integrate/openai/basic_usage.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/integrate/openai/create_image.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/integrate/openai/qa.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/integrate/openai/readme.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/integrate/openai/summarize.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/processor/llm_verifier_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/processor/temperature_example.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/session/session.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/similarity_evaluation/exact_match.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/similarity_evaluation/onnx.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/similarity_evaluation/search_distance.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/similarity_evaluation/sequence_match.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/examples/vqa_demo.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/adapter/api.py",
        "providers": [
          "cohere",
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/adapter/base.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/adapter/langchain_models.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/adapter/llama_cpp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/adapter/minigpt4.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/adapter/openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/core.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/embedding/__init__.py",
        "providers": [
          "cohere",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/embedding/cohere.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/embedding/langchain.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/embedding/openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/processor/post.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/processor/pre.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/session.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/similarity_evaluation/__init__.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/similarity_evaluation/cohere_rerank.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/utils/__init__.py",
        "providers": [
          "cohere",
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/utils/error.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache/utils/response.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/gptcache_server/server.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/integration_tests/examples/map/test_example_map.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/integration_tests/examples/sqlite_faiss_mock/test_example_sqlite_faiss.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/integration_tests/examples/sqlite_faiss_onnx/test_example_sqlite_faiss_onnx.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/integration_tests/processor/pre/test_pre_without_prompt.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/integration_tests/test_redis_onnx.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/integration_tests/test_sqlite_faiss_onnx.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/integration_tests/test_sqlite_milvus_sbert.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/unit_tests/adapter/test_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/unit_tests/adapter/test_langchain_models.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/unit_tests/adapter/test_llama_cpp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/unit_tests/adapter/test_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/unit_tests/adapter/test_replicate.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/unit_tests/embedding/test_cohere.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/unit_tests/embedding/test_embedding_openai.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/unit_tests/embedding/test_langchain.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/unit_tests/embedding/test_sbert.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/unit_tests/processor/test_context.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/unit_tests/processor/test_pre.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/unit_tests/similarity_evaluation/test_cohere_rerank.py",
        "providers": [
          "cohere"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/unit_tests/test_session.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/unit_tests/utils/test_error.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zilliztech-GPTCache-c59fb3a/tests/unit_tests/utils/test_response.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "zhjunqin/Langchain-Chatchat-InternLM": {
    "owner": "zhjunqin",
    "repo": "Langchain-Chatchat-InternLM",
    "ref": "761f0bc3a94ccdda9970761b6c769c7e0537e2e8",
    "num_llm_files": 26,
    "providers": [
      "langchain",
      "openai"
    ],
    "files": [
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/chains/llmchain_with_history.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/configs/model_config.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/configs/server_config.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/server/api.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/server/chat/__init__.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/server/chat/chat.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/server/chat/knowledge_base_chat.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/server/chat/openai_chat.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/server/chat/search_engine_chat.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/server/chat/utils.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/server/knowledge_base/kb_doc_api.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/server/knowledge_base/kb_service/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/server/knowledge_base/kb_service/default_kb_service.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/server/knowledge_base/kb_service/faiss_kb_service.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/server/knowledge_base/kb_service/milvus_kb_service.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/server/knowledge_base/kb_service/pg_kb_service.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/server/knowledge_base/utils.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/server/llm_api.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/server/llm_api_shutdown.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/server/llm_api_stale.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/startup.py",
        "providers": [
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/tests/api/test_kb_api.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/text_splitter/ali_text_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/text_splitter/chinese_text_splitter.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/text_splitter/zh_title_enhance.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "zhjunqin-Langchain-Chatchat-InternLM-761f0bc/webui_pages/utils.py",
        "providers": [
          "openai"
        ]
      }
    ],
    "error": null
  },
  "run-llama/llama_index": {
    "owner": "run-llama",
    "repo": "llama_index",
    "ref": "main",
    "num_llm_files": 3162,
    "providers": [
      "anthropic",
      "cohere",
      "gemini",
      "groq",
      "langchain",
      "litellm",
      "llama",
      "mistral",
      "ollama",
      "openai",
      "vllm"
    ],
    "files": [
      {
        "file_path": "run-llama-llama_index-9831c7c/docs/examples/finetuning/embeddings/eval_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/docs/examples/output_parsing/directory.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/docs/scripts/prepare_for_build.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-datasets/10k/uber_2021/llamaindex_baseline.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-datasets/blockchain_solana/llamaindex_baseline.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-datasets/braintrust_coda/llamaindex_baseline.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-datasets/covidqa/llamaindex_baseline.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-datasets/docugami_kg_rag/sec_10_q/llamaindex_baseline.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-datasets/eval_llm_survey_paper/llamaindex_baseline.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-datasets/history_of_alexnet/llamaindex_baseline.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-datasets/llama2_paper/llamaindex_baseline.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-datasets/mini_covidqa/llamaindex_baseline.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-datasets/mini_esg_bench/llamaindex_baseline.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-datasets/mini_mt_bench_singlegrading/baselines.py",
        "providers": [
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-datasets/mini_squadv2/llamaindex_baseline.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-datasets/mini_truthfulqa/llamaindex_baseline.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-datasets/mt_bench_humanjudgement/baselines.py",
        "providers": [
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-datasets/origin_of_covid19/llamaindex_baseline.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-datasets/patronus_financebench/llamaindex_baseline.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-datasets/paul_graham_essay/llamaindex_baseline.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-dev/llama_dev/cli.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-dev/llama_dev/pkg/bump.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-dev/llama_dev/pkg/cmd_exec.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-dev/llama_dev/pkg/info.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-dev/llama_dev/release/changelog.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-dev/llama_dev/release/check.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-dev/llama_dev/release/prepare.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-dev/llama_dev/test/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-dev/llama_dev/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-dev/tests/pkg/test_bump.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-dev/tests/pkg/test_cmd_exec.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-dev/tests/pkg/test_info.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-dev/tests/release/test_changelog.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-dev/tests/release/test_check.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-dev/tests/test/test_test.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-dev/tests/test_cli.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-dev/tests/test_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-cli/llama_index/cli/command_line.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-cli/llama_index/cli/new_package/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-cli/llama_index/cli/new_package/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-cli/llama_index/cli/new_package/templates/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-cli/llama_index/cli/new_package/templates/init.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-cli/llama_index/cli/new_package/templates/pyproject.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-cli/llama_index/cli/new_package/templates/readme.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-cli/llama_index/cli/rag/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-cli/llama_index/cli/rag/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-cli/llama_index/cli/upgrade/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-cli/llama_index/cli/upgrade/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-cli/tests/test_rag.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/agent/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/agent/react/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/agent/react/formatter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/agent/react/output_parser.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/agent/react/types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/agent/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/agent/workflow/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/agent/workflow/base_agent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/agent/workflow/codeact_agent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/agent/workflow/function_agent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/agent/workflow/multi_agent_workflow.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/agent/workflow/react_agent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/agent/workflow/workflow_events.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/async_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/base/base_auto_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/base/base_multi_modal_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/base/base_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/base/base_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/base/base_selector.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/base/embeddings/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/base/embeddings/base_sparse.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/base/llms/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/base/llms/generic_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/base/llms/types.py",
        "providers": [
          "cohere",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/base/response/schema.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/bridge/langchain.py",
        "providers": [
          "cohere",
          "langchain",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/callbacks/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/callbacks/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/callbacks/base_handler.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/callbacks/global_handlers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/callbacks/llama_debug.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/callbacks/pythonically_printing_base_handler.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/callbacks/simple_llm_handler.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/callbacks/token_counting.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/callbacks/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/chat_engine/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/chat_engine/condense_plus_context.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/chat_engine/condense_question.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/chat_engine/context.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/chat_engine/multi_modal_context.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/chat_engine/simple.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/chat_engine/types.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/chat_engine/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/chat_ui/events.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/command_line/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/command_line/upgrade.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/composability/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/composability/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/composability/joint_qa_summary.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/constants.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/data_structs/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/data_structs/data_structs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/data_structs/document_summary.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/data_structs/registry.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/data_structs/table.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/download/dataset.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/download/module.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/download/pack.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/download/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/embeddings/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/embeddings/loading.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/embeddings/mock_embed_model.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/embeddings/multi_modal_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/embeddings/utils.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/answer_relevancy.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/batch_runner.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/benchmarks/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/benchmarks/beir.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/benchmarks/hotpotqa.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/context_relevancy.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/correctness.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/dataset_generation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/eval_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/faithfulness.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/guideline.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/multi_modal/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/multi_modal/faithfulness.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/multi_modal/relevancy.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/notebook_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/pairwise.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/relevancy.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/retrieval/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/retrieval/evaluator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/retrieval/metrics.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/retrieval/metrics_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/evaluation/semantic_similarity.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/extractors/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/extractors/document_context.py",
        "providers": [
          "anthropic",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/extractors/interface.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/extractors/loading.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/extractors/metadata_extractors.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/graph_stores/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/graph_stores/prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/graph_stores/simple.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/graph_stores/simple_labelled.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/graph_stores/types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/graph_stores/utils.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/image_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/base_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/common/struct_store/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/common/struct_store/schema.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/common/struct_store/sql.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/common_tree/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/composability/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/composability/graph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/document_summary/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/document_summary/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/document_summary/retrievers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/empty/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/empty/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/empty/retrievers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/keyword_table/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/keyword_table/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/keyword_table/rake_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/keyword_table/retrievers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/keyword_table/simple_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/keyword_table/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/knowledge_graph/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/knowledge_graph/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/knowledge_graph/retrievers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/list/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/list/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/list/retrievers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/loading.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/managed/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/managed/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/multi_modal/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/multi_modal/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/multi_modal/retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/postprocessor.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/prompt_helper.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/property_graph/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/property_graph/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/property_graph/retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/property_graph/sub_retrievers/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/property_graph/sub_retrievers/custom.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/property_graph/sub_retrievers/cypher_template.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/property_graph/sub_retrievers/llm_synonym.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/property_graph/sub_retrievers/text_to_cypher.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/property_graph/sub_retrievers/vector.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/property_graph/transformations/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/property_graph/transformations/dynamic_llm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/property_graph/transformations/implicit.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/property_graph/transformations/schema_llm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/property_graph/transformations/simple_llm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/property_graph/transformations/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/query/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/query/embedding_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/query/query_transform/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/query/query_transform/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/query/query_transform/feedback_transform.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/query/query_transform/prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/query/schema.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/registry.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/struct_store/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/struct_store/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/struct_store/container_builder.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/struct_store/json_query.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/struct_store/pandas.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/struct_store/sql.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/struct_store/sql_query.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/struct_store/sql_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/tree/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/tree/all_leaf_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/tree/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/tree/inserter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/tree/select_leaf_embedding_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/tree/select_leaf_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/tree/tree_root_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/tree/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/vector_store/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/vector_store/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/vector_store/retrievers/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/vector_store/retrievers/auto_retriever/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/vector_store/retrievers/auto_retriever/auto_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/vector_store/retrievers/auto_retriever/output_parser.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/vector_store/retrievers/auto_retriever/prompts.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/indices/vector_store/retrievers/retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/ingestion/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/ingestion/api_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/ingestion/cache.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/ingestion/data_sinks.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/ingestion/data_sources.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/ingestion/pipeline.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/ingestion/transformations.py",
        "providers": [
          "cohere",
          "gemini",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/base_handler.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/dispatcher.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/event_handlers/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/event_handlers/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/event_handlers/null.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/events/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/events/agent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/events/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/events/chat_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/events/embedding.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/events/exception.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/events/llm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/events/query.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/events/rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/events/retrieval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/events/span.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/events/synthesis.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/span/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/span/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/span/simple.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/span_handlers/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/span_handlers/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/span_handlers/null.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/instrumentation/span_handlers/simple.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/langchain_helpers/__init__.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/langchain_helpers/agents/__init__.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/langchain_helpers/agents/agents.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/langchain_helpers/agents/toolkits.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/langchain_helpers/agents/tools.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/langchain_helpers/memory_wrapper.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/langchain_helpers/streaming.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/langchain_helpers/text_splitter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llama_dataset/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llama_dataset/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llama_dataset/download.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llama_dataset/evaluator_evaluation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llama_dataset/generator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llama_dataset/legacy/embedding.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llama_dataset/rag.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llama_dataset/simple.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llama_pack/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llama_pack/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llama_pack/download.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llms/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llms/callbacks.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llms/chatml_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llms/custom.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llms/function_calling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llms/llm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llms/loading.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llms/mock.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llms/structured_llm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/llms/utils.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/memory/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/memory/chat_memory_buffer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/memory/chat_summary_memory_buffer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/memory/memory.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/memory/memory_blocks/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/memory/memory_blocks/fact.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/memory/memory_blocks/static.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/memory/memory_blocks/vector.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/memory/simple_composable_memory.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/memory/types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/memory/vector_memory.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/multi_modal_llms/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/multi_modal_llms/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/multi_modal_llms/generic_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/__init__.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/file/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/file/html.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/file/json.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/file/markdown.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/file/simple_file.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/interface.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/loading.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/node_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/relational/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/relational/base_element.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/relational/hierarchical.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/relational/llama_parse_json_element.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/relational/markdown_element.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/relational/unstructured_element.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/text/__init__.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/text/code.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/text/langchain.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/text/semantic_double_merging_splitter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/text/semantic_splitter.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/text/sentence.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/text/sentence_window.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/text/token.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/node_parser/text/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/objects/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/objects/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/objects/base_node_mapping.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/objects/fn_node_mapping.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/objects/table_node_mapping.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/objects/tool_node_mapping.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/objects/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/output_parsers/__init__.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/output_parsers/langchain.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/output_parsers/pydantic.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/output_parsers/selection.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/output_parsers/utils.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/playground/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/playground/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/postprocessor/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/postprocessor/llm_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/postprocessor/metadata_replacement.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/postprocessor/node.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/postprocessor/node_recency.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/postprocessor/optimizer.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/postprocessor/pii.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/postprocessor/rankGPT_rerank.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/postprocessor/sbert_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/postprocessor/structured_llm_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/postprocessor/types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/program/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/program/function_program.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/program/llm_program.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/program/llm_prompt_program.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/program/multi_modal_llm_program.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/program/streaming_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/program/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/prompts/__init__.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/prompts/base.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/prompts/chat_prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/prompts/default_prompt_selectors.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/prompts/default_prompts.py",
        "providers": [
          "cohere",
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/prompts/display_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/prompts/guidance_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/prompts/mixin.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/prompts/prompt_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/prompts/prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/prompts/rich.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/prompts/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/citation_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/cogniswitch_query_engine.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/custom.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/flare/answer_inserter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/flare/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/flare/output_parser.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/graph_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/jsonalyze/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/jsonalyze/jsonalyze_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/knowledge_graph_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/multi_modal.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/multistep_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/pandas/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/pandas/output_parser.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/pandas/pandas_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/retriever_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/retry_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/retry_source_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/router_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/sql_join_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/sql_vector_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/sub_question_query_engine.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/query_engine/transform_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/question_gen/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/question_gen/llm_generators.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/question_gen/output_parser.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/question_gen/prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/question_gen/types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/readers/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/readers/base.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/readers/download.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/readers/file/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/readers/json.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/readers/loading.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/readers/string_iterable.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/response/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/response/notebook_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/response/pprint_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/response_synthesizers/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/response_synthesizers/accumulate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/response_synthesizers/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/response_synthesizers/compact_and_accumulate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/response_synthesizers/compact_and_refine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/response_synthesizers/context_only.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/response_synthesizers/factory.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/response_synthesizers/generation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/response_synthesizers/no_text.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/response_synthesizers/refine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/response_synthesizers/simple_summarize.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/response_synthesizers/tree_summarize.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/retrievers/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/retrievers/auto_merging_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/retrievers/fusion_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/retrievers/recursive_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/retrievers/router_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/retrievers/transform_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/schema.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/selectors/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/selectors/embedding_selectors.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/selectors/llm_selectors.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/selectors/prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/selectors/pydantic_selectors.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/selectors/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/service_context.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/service_context_elements/llama_logger.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/service_context_elements/llm_predictor.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/settings.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/sparse_embeddings/mock_sparse_embedding.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/chat_store/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/chat_store/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/chat_store/base_db.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/chat_store/loading.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/chat_store/simple_chat_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/chat_store/sql.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/docstore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/docstore/keyval_docstore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/docstore/registry.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/docstore/simple_docstore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/docstore/types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/docstore/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/index_store/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/index_store/keyval_index_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/index_store/simple_index_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/index_store/types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/index_store/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/kvstore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/kvstore/simple_kvstore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/storage/storage_context.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/text_splitter/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/tools/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/tools/calling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/tools/download.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/tools/eval_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/tools/function_tool.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/tools/ondemand_loader_tool.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/tools/query_engine.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/tools/query_plan.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/tools/retriever_tool.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/tools/tool_spec/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/tools/tool_spec/load_and_search/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/tools/tool_spec/load_and_search/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/tools/types.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/tools/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/types.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/utilities/gemini_utils.py",
        "providers": [
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/utilities/sql_wrapper.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/utilities/token_counting.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/utils.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/vector_stores/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/vector_stores/simple.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/vector_stores/types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/vector_stores/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/voice_agents/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/voice_agents/events.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/llama_index/core/workflow/drawing.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/agent/memory/test_simple_composable.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/agent/memory/test_vector_memory.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/agent/react/test_prompt_customization.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/agent/react/test_react_output_parser.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/agent/utils/test_agent_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/agent/workflow/test_agent_with_structured_output.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/agent/workflow/test_code_act_agent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/agent/workflow/test_events.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/agent/workflow/test_function_call.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/agent/workflow/test_multi_agent_workflow.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/agent/workflow/test_react_agent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/agent/workflow/test_return_direct_e2e.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/agent/workflow/test_single_agent_workflow.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/agent/workflow/test_thinking_delta.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/base/llms/test_types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/callbacks/test_llama_debug.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/callbacks/test_token_counter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/chat_engine/test_condense_plus_context.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/chat_engine/test_condense_question.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/chat_engine/test_context.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/chat_engine/test_multi_modal_context.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/chat_engine/test_simple.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/conftest.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/embeddings/test_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/embeddings/test_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/embeddings/test_with_cache.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/embeddings/todo_hf_test_utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/evaluation/test_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/evaluation/test_batch_runner.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/evaluation/test_dataset_generation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/evaluation/test_metrics.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/evaluation/test_platform_eval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/extractors/test_document_context_extractor.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/graph_stores/test_simple_lpg.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/document_summary/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/document_summary/test_index.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/document_summary/test_retrievers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/empty/test_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/keyword_table/test_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/keyword_table/test_retrievers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/keyword_table/test_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/knowledge_graph/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/knowledge_graph/test_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/knowledge_graph/test_retrievers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/list/test_index.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/list/test_retrievers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/property_graph/test_property_graph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/query/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/query/query_transform/mock_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/query/query_transform/test_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/query/test_compose.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/query/test_compose_vector.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/query/test_embedding_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/query/test_query_bundle.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/response/test_response_builder.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/response/test_tree_summarize.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/struct_store/test_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/struct_store/test_json_query.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/struct_store/test_sql_query.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/test_loading.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/test_loading_graph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/test_prompt_helper.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/test_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/tree/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/tree/test_embedding_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/tree/test_index.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/tree/test_retrievers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/vector_store/auto_retriever/test_output_parser.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/vector_store/mock_services.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/vector_store/test_retrievers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/vector_store/test_simple.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/indices/vector_store/test_simple_async.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/ingestion/test_cache.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/ingestion/test_data_sinks.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/ingestion/test_data_sources.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/ingestion/test_pipeline.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/ingestion/test_transformations.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/llms/test_callbacks.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/llms/test_custom.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/llms/test_function_calling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/llms/test_mock.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/llms/test_predict_and_call.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/memory/blocks/test_fact.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/memory/blocks/test_static.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/memory/blocks/test_vector.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/memory/test_chat_memory_buffer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/memory/test_chat_summary_memory_buffer.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/memory/test_memory_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/memory/test_memory_blocks_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/memory/test_memory_schema.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/mock_utils/mock_predict.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/mock_utils/mock_prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/mock_utils/mock_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/multi_modal_llms/test_base_multi_modal_llm_metadata.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/multi_modal_llms/test_generic_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/node_parser/metadata_extractor.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/node_parser/sentence_window.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/node_parser/test_duplicate_text_positions.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/node_parser/test_file.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/node_parser/test_hierarchical.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/node_parser/test_html.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/node_parser/test_json.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/node_parser/test_markdown.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/node_parser/test_markdown_element.py",
        "providers": [
          "anthropic",
          "cohere",
          "gemini",
          "langchain",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/node_parser/test_node_parser.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/node_parser/test_semantic_double_merging_splitter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/node_parser/test_semantic_splitter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/node_parser/test_unstructured.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/objects/test_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/objects/test_node_mapping.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/output_parsers/test_base.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/output_parsers/test_pydantic.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/output_parsers/test_selection.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/output_parsers/test_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/playground/test_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/postprocessor/test_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/postprocessor/test_llm_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/postprocessor/test_metadata_replacement.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/postprocessor/test_optimizer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/postprocessor/test_rankgpt_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/postprocessor/test_structured_llm_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/program/test_function_program.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/program/test_llm_program.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/program/test_multi_modal_llm_program.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/program/test_streaming_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/program/test_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/prompts/test_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/prompts/test_guidance_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/prompts/test_mixin.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/prompts/test_rich.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/prompts/test_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/query_engine/test_cogniswitch_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/query_engine/test_retriever_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/question_gen/test_llm_generators.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/readers/file/test_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/readers/test_json.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/readers/test_load_reader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/readers/test_string_iterable.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/response_synthesizers/test_generate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/response_synthesizers/test_refine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/retrievers/test_composable_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/schema/test_base_component.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/schema/test_base_node.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/schema/test_image_document.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/schema/test_media_resource.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/schema/test_node.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/schema/test_schema.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/selectors/test_llm_selectors.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/sparse_embeddings/test_mock_sparse_embeddings.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/storage/chat_store/test_simple_chat_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/storage/chat_store/test_sql.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/storage/chat_store/test_sql_schema.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/storage/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/storage/docstore/test_simple_docstore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/storage/index_store/test_simple_index_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/storage/kvstore/test_mutable_mapping_kvstore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/storage/kvstore/test_simple_kvstore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/storage/test_storage_context.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/test_async_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/test_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/text_splitter/test_code_splitter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/text_splitter/test_sentence_splitter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/text_splitter/test_token_splitter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/token_predictor/test_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/tools/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/tools/test_base.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/tools/test_eval_query_engine_tool.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/tools/test_ondemand_loader.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/tools/test_query_engine_tool.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/tools/test_retriever_tool.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/tools/test_types.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/tools/test_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/tools/tool_spec/test_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/tools/tool_spec/test_load_and_search.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/utilities/test_sql_wrapper.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/vector_stores/test_simple.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/vector_stores/test_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/voice_agents/test_event_serialization.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-core/tests/voice_agents/test_subclasses.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/nudge/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/nudge/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/param_tuner/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/param_tuner/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/query_engine/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/query_engine/jsonalyze/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/query_engine/jsonalyze/jsonalyze_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/query_engine/pandas/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/query_engine/pandas/output_parser.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/query_engine/pandas/pandas_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/query_engine/pandas/prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/query_engine/polars/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/query_engine/polars/output_parser.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/query_engine/polars/polars_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/query_engine/polars/prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/retrievers/natural_language/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/retrievers/natural_language/nl_csv_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/retrievers/natural_language/nl_data_frame_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/llama_index/experimental/retrievers/natural_language/nl_json_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/tests/test_exec_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/tests/test_pandas.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-experimental/tests/test_polars.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/__init__.py",
        "providers": [
          "cohere",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/azure_openai/__init__.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/azure_openai/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/callbacks/__init__.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/callbacks/finetuning_handler.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/cross_encoders/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/cross_encoders/cross_encoder.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/cross_encoders/dataset_gen.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/embeddings/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/embeddings/adapter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/embeddings/adapter_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/embeddings/common.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/embeddings/sentence_transformer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/mistralai/__init__.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/mistralai/base.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/openai/__init__.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/openai/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/openai/validate_json.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/rerankers/__init__.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/rerankers/cohere_reranker.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/rerankers/dataset_gen.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-finetuning/llama_index/finetuning/types.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-instrumentation/src/llama_index_instrumentation/base/event.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-instrumentation/src/llama_index_instrumentation/dispatcher.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-instrumentation/src/llama_index_instrumentation/event_handlers/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-instrumentation/src/llama_index_instrumentation/event_handlers/null.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-instrumentation/src/llama_index_instrumentation/events/span.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-instrumentation/src/llama_index_instrumentation/span_handlers/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-instrumentation/src/llama_index_instrumentation/span_handlers/null.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-instrumentation/src/llama_index_instrumentation/span_handlers/simple.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-instrumentation/tests/test_dispatcher.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-instrumentation/tests/test_manager.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/agent/llama-index-agent-azure/llama_index/agent/azure_foundry_agent/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/agent/llama-index-agent-azure/llama_index/agent/azure_foundry_agent/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/agent/llama-index-agent-azure/tests/test_azure_foundry_agent.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-agentops/llama_index/callbacks/agentops/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-agentops/llama_index/callbacks/agentops/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-aim/llama_index/callbacks/aim/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-aim/llama_index/callbacks/aim/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-argilla/llama_index/callbacks/argilla/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-argilla/llama_index/callbacks/argilla/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-arize-phoenix/llama_index/callbacks/arize_phoenix/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-arize-phoenix/llama_index/callbacks/arize_phoenix/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-honeyhive/llama_index/callbacks/honeyhive/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-honeyhive/llama_index/callbacks/honeyhive/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-langfuse/llama_index/callbacks/langfuse/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-langfuse/llama_index/callbacks/langfuse/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-literalai/examples/literalai_example.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-literalai/llama_index/callbacks/literalai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-literalai/llama_index/callbacks/literalai/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-openinference/llama_index/callbacks/openinference/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-openinference/llama_index/callbacks/openinference/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-openinference/tests/test_openinference_callback.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-opik/examples/opik_example.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-opik/llama_index/callbacks/opik/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-opik/llama_index/callbacks/opik/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-promptlayer/llama_index/callbacks/promptlayer/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-promptlayer/llama_index/callbacks/promptlayer/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-promptlayer/tests/test_promptlayer_callback.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-uptrain/llama_index/callbacks/uptrain/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-uptrain/llama_index/callbacks/uptrain/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-uptrain/tests/test_uptrain_callback.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-wandb/llama_index/callbacks/wandb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-wandb/llama_index/callbacks/wandb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/callbacks/llama-index-callbacks-wandb/tests/test_wandb_callback.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-adapter/llama_index/embeddings/adapter/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-adapter/llama_index/embeddings/adapter/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-adapter/tests/test_embeddings_adapter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-alephalpha/llama_index/embeddings/alephalpha/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-alephalpha/llama_index/embeddings/alephalpha/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-alephalpha/tests/test_embeddings_alephalpha.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-alibabacloud-aisearch/llama_index/embeddings/alibabacloud_aisearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-alibabacloud-aisearch/llama_index/embeddings/alibabacloud_aisearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-alibabacloud-aisearch/tests/test_embeddings_alibabacloud_aisearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-anyscale/llama_index/embeddings/anyscale/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-anyscale/llama_index/embeddings/anyscale/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-anyscale/llama_index/embeddings/anyscale/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-anyscale/tests/test_anyscale_embedding.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-autoembeddings/llama_index/embeddings/autoembeddings/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-autoembeddings/llama_index/embeddings/autoembeddings/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-autoembeddings/tests/test_autoembeddings.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-azure-inference/llama_index/embeddings/azure_inference/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-azure-inference/llama_index/embeddings/azure_inference/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-azure-inference/tests/test_embeddings_azure_inference.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-azure-openai/llama_index/embeddings/azure_openai/__init__.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-azure-openai/llama_index/embeddings/azure_openai/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-baseten/llama_index/embeddings/baseten/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-baseten/llama_index/embeddings/baseten/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-bedrock/llama_index/embeddings/bedrock/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-bedrock/llama_index/embeddings/bedrock/base.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-bedrock/tests/test_bedrock.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-bedrock/tests/test_bedrock_async.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-bedrock/tests/test_bedrock_embedding.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-clarifai/llama_index/embeddings/clarifai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-clarifai/llama_index/embeddings/clarifai/base.py",
        "providers": [
          "anthropic",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-clip/llama_index/embeddings/clip/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-clip/llama_index/embeddings/clip/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-clip/tests/test_embeddings_clip.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-cloudflare-workersai/llama_index/embeddings/cloudflare_workersai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-cloudflare-workersai/llama_index/embeddings/cloudflare_workersai/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-cloudflare-workersai/tests/test_embeddings_cloudflare-workersai.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-cohere/llama_index/embeddings/cohere/__init__.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-cohere/llama_index/embeddings/cohere/base.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-cohere/tests/test_embeddings.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-dashscope/llama_index/embeddings/dashscope/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-dashscope/llama_index/embeddings/dashscope/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-dashscope/tests/test_embeddings_dashscope.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-databricks/llama_index/embeddings/databricks/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-databricks/llama_index/embeddings/databricks/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-databricks/tests/test_embeddings_databricks.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-databricks/tests/test_integration_databricks.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-deepinfra/llama_index/embeddings/deepinfra/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-deepinfra/llama_index/embeddings/deepinfra/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-deepinfra/tests/test_embeddings_deepinfra.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-elasticsearch/llama_index/embeddings/elasticsearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-elasticsearch/llama_index/embeddings/elasticsearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-elasticsearch/tests/test_embeddings_elasticsearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-fastembed/llama_index/embeddings/fastembed/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-fastembed/llama_index/embeddings/fastembed/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-fastembed/tests/test_embeddings_fastembed.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-fireworks/llama_index/embeddings/fireworks/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-fireworks/llama_index/embeddings/fireworks/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-fireworks/llama_index/embeddings/fireworks/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-gaudi/examples/basic.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-gaudi/examples/graphrag.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-gaudi/llama_index/embeddings/gaudi/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-gaudi/llama_index/embeddings/gaudi/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-gaudi/llama_index/embeddings/gaudi/utils.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-gemini/llama_index/embeddings/gemini/__init__.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-gemini/llama_index/embeddings/gemini/base.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-gemini/tests/test_embeddings_gemini.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-gigachat/llama_index/embeddings/gigachat/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-gigachat/llama_index/embeddings/gigachat/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-gigachat/tests/test_embeddings_gigachat.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-google-genai/llama_index/embeddings/google_genai/__init__.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-google-genai/llama_index/embeddings/google_genai/base.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-google-genai/tests/test_embeddings_gemini.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-google/llama_index/embeddings/google/__init__.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-google/llama_index/embeddings/google/gemini.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-google/llama_index/embeddings/google/palm.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-google/llama_index/embeddings/google/univ_sent_encoder.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-google/tests/test_embeddings_google.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-heroku/examples/async_usage.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-heroku/examples/basic_usage.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-heroku/llama_index/embeddings/heroku/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-heroku/llama_index/embeddings/heroku/base.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-heroku/tests/test_heroku_embeddings.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface-api/llama_index/embeddings/huggingface_api/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface-api/llama_index/embeddings/huggingface_api/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface-api/tests/test_embeddings_huggingface.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface-api/tests/test_hf_inference.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface-openvino/llama_index/embeddings/huggingface_openvino/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface-openvino/llama_index/embeddings/huggingface_openvino/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface-optimum-intel/llama_index/embeddings/huggingface_optimum_intel/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface-optimum-intel/llama_index/embeddings/huggingface_optimum_intel/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface-optimum-intel/tests/test_embeddings_huggingface_optimum_intel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface-optimum/llama_index/embeddings/huggingface_optimum/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface-optimum/llama_index/embeddings/huggingface_optimum/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface-optimum/tests/test_embeddings_huggingface_optimum.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface/llama_index/embeddings/huggingface/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface/llama_index/embeddings/huggingface/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface/llama_index/embeddings/huggingface/utils.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface/tests/test_embeddings_huggingface.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface/tests/test_hf_inference.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-huggingface/tests/test_hf_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-ibm/llama_index/embeddings/ibm/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-ibm/llama_index/embeddings/ibm/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-ibm/llama_index/embeddings/ibm/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-ibm/tests/test_embeddings_ibm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-ibm/tests/test_ibm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-instructor/llama_index/embeddings/instructor/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-instructor/llama_index/embeddings/instructor/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-instructor/llama_index/embeddings/instructor/utils.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-ipex-llm/examples/basic.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-ipex-llm/llama_index/embeddings/ipex_llm/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-ipex-llm/llama_index/embeddings/ipex_llm/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-ipex-llm/llama_index/embeddings/ipex_llm/utils.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-isaacus/examples/async_usage.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-isaacus/examples/basic_usage.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-isaacus/llama_index/embeddings/isaacus/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-isaacus/llama_index/embeddings/isaacus/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-isaacus/tests/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-isaacus/tests/test_isaacus_embeddings.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-jinaai/llama_index/embeddings/jinaai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-jinaai/llama_index/embeddings/jinaai/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-jinaai/tests/test_embeddings_jinaai.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-langchain/llama_index/embeddings/langchain/__init__.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-langchain/llama_index/embeddings/langchain/base.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-langchain/tests/test_embeddings_langchain.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-litellm/llama_index/embeddings/litellm/__init__.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-litellm/llama_index/embeddings/litellm/base.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-litellm/tests/test_embeddings_litellm.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-llamafile/llama_index/embeddings/llamafile/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-llamafile/llama_index/embeddings/llamafile/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-llamafile/tests/test_embeddings_llamafile.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-llm-rails/llama_index/embeddings/llm_rails/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-llm-rails/llama_index/embeddings/llm_rails/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-llm-rails/tests/test_embeddings_llm_rails.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-mistralai/llama_index/embeddings/mistralai/__init__.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-mistralai/llama_index/embeddings/mistralai/base.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-mistralai/tests/test_embeddings_mistralai.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-mixedbreadai/llama_index/embeddings/mixedbreadai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-mixedbreadai/llama_index/embeddings/mixedbreadai/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-mixedbreadai/tests/test_embeddings_mixedbreadai.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-modelscope/llama_index/embeddings/modelscope/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-modelscope/llama_index/embeddings/modelscope/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-modelscope/llama_index/embeddings/modelscope/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-modelscope/tests/test_modelscope.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-nebius/llama_index/embeddings/nebius/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-nebius/llama_index/embeddings/nebius/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-nebius/llama_index/embeddings/nebius/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-nebius/tests/test_embeddings_nebius.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-netmind/llama_index/embeddings/netmind/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-netmind/llama_index/embeddings/netmind/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-netmind/tests/test_embeddings_netmind.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-nomic/llama_index/embeddings/nomic/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-nomic/llama_index/embeddings/nomic/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-nomic/tests/test_embeddings_nomic.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-nvidia/llama_index/embeddings/nvidia/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-nvidia/llama_index/embeddings/nvidia/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-nvidia/llama_index/embeddings/nvidia/utils.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-nvidia/tests/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-nvidia/tests/test_api_key.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-nvidia/tests/test_available_models.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-nvidia/tests/test_base_url.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-nvidia/tests/test_embeddings_nvidia.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-nvidia/tests/test_integration.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-nvidia/tests/test_truncate.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-oci-data-science/llama_index/embeddings/oci_data_science/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-oci-data-science/llama_index/embeddings/oci_data_science/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-oci-data-science/llama_index/embeddings/oci_data_science/client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-oci-data-science/llama_index/embeddings/oci_data_science/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-oci-data-science/tests/test_embeddings_oci_data_science.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-oci-data-science/tests/test_oci_data_science_client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-oci-genai/llama_index/embeddings/oci_genai/__init__.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-oci-genai/llama_index/embeddings/oci_genai/base.py",
        "providers": [
          "cohere",
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-oci-genai/tests/test_embeddings_oci_genai.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-oci-genai/tests/test_oci_genai.py",
        "providers": [
          "cohere",
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-ollama/llama_index/embeddings/ollama/__init__.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-ollama/llama_index/embeddings/ollama/base.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-ollama/tests/test_embeddings_ollama.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-opea/llama_index/embeddings/opea/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-opea/llama_index/embeddings/opea/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-openai-like/llama_index/embeddings/openai_like/__init__.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-openai-like/llama_index/embeddings/openai_like/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-openai-like/tests/test_embeddings_openai_like.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-openai/llama_index/embeddings/openai/__init__.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-openai/llama_index/embeddings/openai/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-openai/llama_index/embeddings/openai/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-openai/tests/test_embeddings_openai.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-openai/tests/test_utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-openvino-genai/llama_index/embeddings/openvino_genai/__init__.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-openvino-genai/llama_index/embeddings/openvino_genai/base.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-oracleai/llama_index/embeddings/oracleai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-oracleai/llama_index/embeddings/oracleai/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-oracleai/tests/test_embeddings_oracleai.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-premai/llama_index/embeddings/premai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-premai/llama_index/embeddings/premai/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-sagemaker-endpoint/llama_index/embeddings/sagemaker_endpoint/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-sagemaker-endpoint/llama_index/embeddings/sagemaker_endpoint/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-sagemaker-endpoint/llama_index/embeddings/sagemaker_endpoint/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-sagemaker-endpoint/tests/test_embeddings_sagemaker_endpoint.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-siliconflow/llama_index/embeddings/siliconflow/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-siliconflow/llama_index/embeddings/siliconflow/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-siliconflow/tests/test_embeddings_siliconflow.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-text-embeddings-inference/llama_index/embeddings/text_embeddings_inference/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-text-embeddings-inference/llama_index/embeddings/text_embeddings_inference/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-text-embeddings-inference/tests/test_embeddings_text_embeddings_inference.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-textembed/llama_index/embeddings/textembed/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-textembed/llama_index/embeddings/textembed/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-textembed/tests/test_embeddings_textembed.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-together/llama_index/embeddings/together/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-together/llama_index/embeddings/together/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-together/tests/test_embeddings_together.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-upstage/llama_index/embeddings/upstage/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-upstage/llama_index/embeddings/upstage/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-upstage/llama_index/embeddings/upstage/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-upstage/tests/integration_tests/test_integrations.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-upstage/tests/unit_tests/test_embeddings_upstage.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-vertex-endpoint/llama_index/embeddings/vertex_endpoint/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-vertex-endpoint/llama_index/embeddings/vertex_endpoint/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-vertex-endpoint/tests/test_embeddings_vertex_endpoint.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-vertex/llama_index/embeddings/vertex/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-vertex/llama_index/embeddings/vertex/base.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-vertex/tests/test_embeddings_vertex.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-vllm/llama_index/embeddings/vllm/__init__.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-vllm/llama_index/embeddings/vllm/base.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-vllm/tests/test_embeddings_vllm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-voyageai/llama_index/embeddings/voyageai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-voyageai/llama_index/embeddings/voyageai/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-voyageai/tests/test_embeddings_voyageai.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-voyageai/tests/test_embeddings_voyageai_integration.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-xinference/llama_index/embeddings/xinference/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-xinference/llama_index/embeddings/xinference/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-xinference/tests/test_embeddings_xinference.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-yandexgpt/llama_index/embeddings/yandexgpt/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-yandexgpt/llama_index/embeddings/yandexgpt/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-yandexgpt/tests/test_embeddings_yandexgpt.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-zhipuai/llama_index/embeddings/zhipuai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-zhipuai/llama_index/embeddings/zhipuai/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/embeddings/llama-index-embeddings-zhipuai/tests/test_embeddings_zhipuai.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/evaluation/llama-index-evaluation-tonic-validate/llama_index/evaluation/tonic_validate/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/evaluation/llama-index-evaluation-tonic-validate/llama_index/evaluation/tonic_validate/answer_consistency.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/evaluation/llama-index-evaluation-tonic-validate/llama_index/evaluation/tonic_validate/answer_consistency_binary.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/evaluation/llama-index-evaluation-tonic-validate/llama_index/evaluation/tonic_validate/answer_similarity.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/evaluation/llama-index-evaluation-tonic-validate/llama_index/evaluation/tonic_validate/augmentation_accuracy.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/evaluation/llama-index-evaluation-tonic-validate/llama_index/evaluation/tonic_validate/augmentation_precision.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/evaluation/llama-index-evaluation-tonic-validate/llama_index/evaluation/tonic_validate/retrieval_precision.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/evaluation/llama-index-evaluation-tonic-validate/llama_index/evaluation/tonic_validate/tonic_validate_evaluator.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/evaluation/llama-index-evaluation-tonic-validate/tests/test_evaluation_tonic_validate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/extractors/llama-index-extractors-entity/llama_index/extractors/entity/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/extractors/llama-index-extractors-entity/llama_index/extractors/entity/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/extractors/llama-index-extractors-entity/tests/test_extractors_entity.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/extractors/llama-index-extractors-marvin/llama_index/extractors/marvin/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/extractors/llama-index-extractors-marvin/llama_index/extractors/marvin/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/extractors/llama-index-extractors-marvin/tests/test_extractors_marvin.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/extractors/llama-index-extractors-relik/llama_index/extractors/relik/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/extractors/llama-index-extractors-relik/llama_index/extractors/relik/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_rag/llama-index-graph-rag-cognee/example.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_rag/llama-index-graph-rag-cognee/llama_index/graph_rag/cognee/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_rag/llama-index-graph-rag-cognee/llama_index/graph_rag/cognee/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_rag/llama-index-graph-rag-cognee/llama_index/graph_rag/cognee/graph_rag.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_rag/llama-index-graph-rag-cognee/tests/test_add_data.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_rag/llama-index-graph-rag-cognee/tests/test_graph_rag_cognee.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_rag/llama-index-graph-rag-cognee/tests/test_visualize_graph.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-ApertureDB/llama_index/graph_stores/ApertureDB/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-ApertureDB/llama_index/graph_stores/ApertureDB/property_graph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-ApertureDB/tests/test_pg_stores_ApertureDB.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-falkordb/llama_index/graph_stores/falkordb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-falkordb/llama_index/graph_stores/falkordb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-falkordb/llama_index/graph_stores/falkordb/falkordb_property_graph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-falkordb/tests/test_graph_stores_falkordb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-falkordb/tests/test_pg_stores_falkordb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-memgraph/llama_index/graph_stores/memgraph/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-memgraph/llama_index/graph_stores/memgraph/kg_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-memgraph/llama_index/graph_stores/memgraph/property_graph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-memgraph/tests/test_graph_stores_memgraph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-memgraph/tests/test_pg_stores_memgraph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-nebula/examples/a.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-nebula/llama_index/graph_stores/nebula/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-nebula/llama_index/graph_stores/nebula/nebula_graph_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-nebula/llama_index/graph_stores/nebula/nebula_property_graph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-nebula/tests/test_graph_stores_nebula.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-nebula/tests/test_property_graph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-neo4j/llama_index/graph_stores/neo4j/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-neo4j/llama_index/graph_stores/neo4j/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-neo4j/llama_index/graph_stores/neo4j/neo4j_property_graph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-neo4j/tests/test_graph_stores_neo4j.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-neo4j/tests/test_pg_stores_neo4j.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-neptune/llama_index/graph_stores/neptune/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-neptune/llama_index/graph_stores/neptune/analytics_property_graph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-neptune/llama_index/graph_stores/neptune/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-neptune/llama_index/graph_stores/neptune/base_property_graph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-neptune/llama_index/graph_stores/neptune/database_property_graph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-neptune/tests/test_graph_stores_neptune.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-tidb/llama_index/graph_stores/tidb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-tidb/llama_index/graph_stores/tidb/graph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-tidb/llama_index/graph_stores/tidb/property_graph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-tidb/tests/test_graph_stores_tidb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/graph_stores/llama-index-graph-stores-tidb/tests/test_property_graph_stores_tidb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-bge-m3/llama_index/indices/managed/bge_m3/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-bge-m3/llama_index/indices/managed/bge_m3/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-bge-m3/llama_index/indices/managed/bge_m3/retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-colbert/llama_index/indices/managed/colbert/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-colbert/llama_index/indices/managed/colbert/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-colbert/llama_index/indices/managed/colbert/retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-colbert/tests/test_indices_managed_colbert.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-dashscope/llama_index/indices/managed/dashscope/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-dashscope/llama_index/indices/managed/dashscope/api_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-dashscope/llama_index/indices/managed/dashscope/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-dashscope/llama_index/indices/managed/dashscope/retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-dashscope/llama_index/indices/managed/dashscope/transformations.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-dashscope/tests/test_indices_managed_dashscope.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-google/llama_index/indices/managed/google/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-google/llama_index/indices/managed/google/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-google/tests/test_indices_managed_google.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-lancedb/llama_index/indices/managed/lancedb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-lancedb/llama_index/indices/managed/lancedb/base.py",
        "providers": [
          "cohere",
          "gemini",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-lancedb/llama_index/indices/managed/lancedb/query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-lancedb/llama_index/indices/managed/lancedb/retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-lancedb/llama_index/indices/managed/lancedb/utils.py",
        "providers": [
          "cohere",
          "gemini",
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-lancedb/tests/test_index.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-llama-cloud/llama_index/indices/managed/llama_cloud/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-llama-cloud/llama_index/indices/managed/llama_cloud/api_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-llama-cloud/llama_index/indices/managed/llama_cloud/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-llama-cloud/llama_index/indices/managed/llama_cloud/composite_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-llama-cloud/llama_index/indices/managed/llama_cloud/retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-llama-cloud/tests/test_indices_managed_llama_cloud.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-postgresml/llama_index/indices/managed/postgresml/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-postgresml/llama_index/indices/managed/postgresml/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-postgresml/llama_index/indices/managed/postgresml/query.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-postgresml/llama_index/indices/managed/postgresml/retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-postgresml/tests/test_indices_managed_postgresml.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-vectara/llama_index/indices/managed/vectara/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-vectara/llama_index/indices/managed/vectara/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-vectara/llama_index/indices/managed/vectara/prompts.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-vectara/llama_index/indices/managed/vectara/query.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-vectara/llama_index/indices/managed/vectara/retriever.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-vectara/tests/test_indices_managed_vectara.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-vertexai/llama_index/indices/managed/vertexai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-vertexai/llama_index/indices/managed/vertexai/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-vertexai/llama_index/indices/managed/vertexai/retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/indices/llama-index-indices-managed-vertexai/tests/test_indices_managed_vertexai.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ai21/llama_index/llms/ai21/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ai21/llama_index/llms/ai21/base.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ai21/llama_index/llms/ai21/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ai21/tests/test_llms_ai21.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-alephalpha/llama_index/llms/alephalpha/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-alephalpha/llama_index/llms/alephalpha/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-alephalpha/llama_index/llms/alephalpha/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-alephalpha/tests/test_llms_alephalpha.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-alibabacloud-aisearch/llama_index/llms/alibabacloud_aisearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-alibabacloud-aisearch/llama_index/llms/alibabacloud_aisearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-alibabacloud-aisearch/tests/test_llms_alibabacloud_aisearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-anthropic/llama_index/llms/anthropic/__init__.py",
        "providers": [
          "anthropic",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-anthropic/llama_index/llms/anthropic/base.py",
        "providers": [
          "anthropic",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-anthropic/llama_index/llms/anthropic/utils.py",
        "providers": [
          "anthropic",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-anthropic/tests/test_anthropic_utils.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-anthropic/tests/test_llms_anthropic.py",
        "providers": [
          "anthropic",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-anyscale/llama_index/llms/anyscale/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-anyscale/llama_index/llms/anyscale/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-anyscale/llama_index/llms/anyscale/utils.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-anyscale/tests/test_llms_anyscale.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-asi/llama_index/llms/asi/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-asi/llama_index/llms/asi/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-asi/tests/test_integration_asi.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-asi/tests/test_llms_asi.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-azure-inference/llama_index/llms/azure_inference/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-azure-inference/llama_index/llms/azure_inference/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-azure-inference/tests/test_llms_azure_inference.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-azure-openai/llama_index/llms/azure_openai/__init__.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-azure-openai/llama_index/llms/azure_openai/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-azure-openai/llama_index/llms/azure_openai/utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-azure-openai/tests/test_azure_openai.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-azure-openai/tests/test_llms_azure_openai.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-baseten/llama_index/llms/baseten/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-baseten/llama_index/llms/baseten/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-baseten/llama_index/llms/baseten/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-baseten/tests/test_baseten_dynamic.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-baseten/tests/test_coverage_comprehensive.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-baseten/tests/test_llms_baseten.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-bedrock-converse/llama_index/llms/bedrock_converse/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-bedrock-converse/llama_index/llms/bedrock_converse/base.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-bedrock-converse/llama_index/llms/bedrock_converse/utils.py",
        "providers": [
          "anthropic",
          "cohere",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-bedrock-converse/tests/test_bedrock_converse_utils.py",
        "providers": [
          "anthropic",
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-bedrock-converse/tests/test_llms_bedrock_converse.py",
        "providers": [
          "anthropic",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-bedrock/llama_index/llms/bedrock/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-bedrock/llama_index/llms/bedrock/base.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-bedrock/llama_index/llms/bedrock/llama_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-bedrock/llama_index/llms/bedrock/utils.py",
        "providers": [
          "anthropic",
          "cohere",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-bedrock/tests/test_bedrock.py",
        "providers": [
          "anthropic",
          "cohere",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-bedrock/tests/test_llms_bedrock.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-bedrock/tests/test_utils.py",
        "providers": [
          "anthropic",
          "cohere",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cerebras/llama_index/llms/cerebras/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cerebras/llama_index/llms/cerebras/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cerebras/tests/test_integration_cerebras.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cerebras/tests/test_llms_cerebras.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-clarifai/llama_index/llms/clarifai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-clarifai/llama_index/llms/clarifai/base.py",
        "providers": [
          "anthropic",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cleanlab/llama_index/llms/cleanlab/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cleanlab/llama_index/llms/cleanlab/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cleanlab/tests/test_llms_cleanlab.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cloudflare-ai-gateway/llama_index/llms/cloudflare_ai_gateway/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cloudflare-ai-gateway/llama_index/llms/cloudflare_ai_gateway/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cloudflare-ai-gateway/llama_index/llms/cloudflare_ai_gateway/providers.py",
        "providers": [
          "anthropic",
          "groq",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cloudflare-ai-gateway/tests/test_cloudflare_ai_gateway.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cohere/llama_index/llms/cohere/__init__.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cohere/llama_index/llms/cohere/base.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cohere/llama_index/llms/cohere/utils.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cohere/tests/test_llms_cohere.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cohere/tests/test_rag_inference.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cometapi/llama_index/llms/cometapi/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cometapi/llama_index/llms/cometapi/base.py",
        "providers": [
          "anthropic",
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cometapi/tests/test_llms_cometapi.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-contextual/llama_index/llms/contextual/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-contextual/llama_index/llms/contextual/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-contextual/tests/test_empty.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cortex/llama_index/llms/cortex/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cortex/llama_index/llms/cortex/base.py",
        "providers": [
          "anthropic",
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cortex/tests/test_integration_cortex.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cortex/tests/test_llms_cortex.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-cortex/tests/test_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-dashscope/llama_index/llms/dashscope/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-dashscope/llama_index/llms/dashscope/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-dashscope/llama_index/llms/dashscope/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-dashscope/tests/test_dashscope.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-dashscope/tests/test_llms_dashscope.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-databricks/llama_index/llms/databricks/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-databricks/llama_index/llms/databricks/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-databricks/tests/test_integration_databricks.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-databricks/tests/test_llms_databricks.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-deepinfra/llama_index/llms/deepinfra/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-deepinfra/llama_index/llms/deepinfra/base.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-deepinfra/llama_index/llms/deepinfra/client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-deepinfra/llama_index/llms/deepinfra/constants.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-deepinfra/llama_index/llms/deepinfra/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-deepinfra/tests/test_llms_deepinfra.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-deepseek/llama_index/llms/deepseek/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-deepseek/llama_index/llms/deepseek/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-deepseek/tests/test_llms_deepseek.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-everlyai/llama_index/llms/everlyai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-everlyai/llama_index/llms/everlyai/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-everlyai/llama_index/llms/everlyai/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-everlyai/tests/test_llms_everlyai.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-featherlessai/llama_index/llms/featherlessai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-featherlessai/llama_index/llms/featherlessai/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-featherlessai/tests/test_llms_featherlessai.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-fireworks/llama_index/llms/fireworks/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-fireworks/llama_index/llms/fireworks/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-fireworks/llama_index/llms/fireworks/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-fireworks/tests/test_llms_fireworks.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-friendli/llama_index/llms/friendli/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-friendli/llama_index/llms/friendli/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-friendli/llama_index/llms/friendli/utils.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-friendli/tests/test_llms_friendli.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-gaudi/examples/basic.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-gaudi/llama_index/llms/gaudi/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-gaudi/llama_index/llms/gaudi/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-gaudi/llama_index/llms/gaudi/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-gemini/llama_index/llms/gemini/__init__.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-gemini/llama_index/llms/gemini/base.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-gemini/llama_index/llms/gemini/utils.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-gemini/tests/test_llms_gemini.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-gigachat/llama_index/llms/gigachat/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-gigachat/llama_index/llms/gigachat/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-gigachat/tests/test_llms_gigachat.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-google-genai/llama_index/llms/google_genai/__init__.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-google-genai/llama_index/llms/google_genai/base.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-google-genai/llama_index/llms/google_genai/utils.py",
        "providers": [
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-google-genai/tests/test_llms_google_genai.py",
        "providers": [
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-google-genai/tests/test_llms_google_genai_vertex.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-groq/llama_index/llms/groq/__init__.py",
        "providers": [
          "groq",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-groq/llama_index/llms/groq/base.py",
        "providers": [
          "groq",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-groq/tests/test_integration_groq.py",
        "providers": [
          "groq",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-groq/tests/test_llms_groq.py",
        "providers": [
          "groq",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-helicone/llama_index/llms/helicone/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-helicone/llama_index/llms/helicone/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-helicone/tests/test_llms_helicone.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-heroku/llama_index/llms/heroku/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-heroku/llama_index/llms/heroku/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-heroku/tests/test_api_key.py",
        "providers": [
          "anthropic",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-heroku/tests/test_integration.py",
        "providers": [
          "anthropic",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-huggingface-api/llama_index/llms/huggingface_api/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-huggingface-api/llama_index/llms/huggingface_api/base.py",
        "providers": [
          "cohere",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-huggingface-api/tests/test_huggingface_api.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-huggingface-api/tests/test_llms_huggingface_api.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-huggingface/llama_index/llms/huggingface/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-huggingface/llama_index/llms/huggingface/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-huggingface/llama_index/llms/huggingface/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-huggingface/tests/test_llms_huggingface.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ibm/llama_index/llms/ibm/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ibm/llama_index/llms/ibm/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ibm/llama_index/llms/ibm/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ibm/tests/test_ibm.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ibm/tests/test_llms_ibm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ibm/tests/test_tool_required.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ipex-llm/examples/basic.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ipex-llm/examples/low_bit.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ipex-llm/examples/more_data_type.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ipex-llm/llama_index/llms/ipex_llm/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ipex-llm/llama_index/llms/ipex_llm/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-keywordsai/llama_index/llms/keywordsai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-keywordsai/llama_index/llms/keywordsai/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-keywordsai/llama_index/llms/keywordsai/utils.py",
        "providers": [
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-keywordsai/tests/test_llms_keywordsai.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-konko/llama_index/llms/konko/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-konko/llama_index/llms/konko/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-konko/llama_index/llms/konko/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-konko/tests/test_llms_konko.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-langchain/llama_index/llms/langchain/__init__.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-langchain/llama_index/llms/langchain/base.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-langchain/llama_index/llms/langchain/utils.py",
        "providers": [
          "cohere",
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-langchain/tests/test_llms_langchain.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-litellm/llama_index/llms/litellm/__init__.py",
        "providers": [
          "litellm",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-litellm/llama_index/llms/litellm/base.py",
        "providers": [
          "cohere",
          "litellm",
          "llama",
          "ollama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-litellm/llama_index/llms/litellm/utils.py",
        "providers": [
          "langchain",
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-litellm/tests/test_llms_litellm.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-litellm/tests/test_utils.py",
        "providers": [
          "litellm",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-llama-api/llama_index/llms/llama_api/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-llama-api/llama_index/llms/llama_api/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-llama-api/tests/test_llms_llama_api.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-llama-cpp/llama_index/llms/llama_cpp/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-llama-cpp/llama_index/llms/llama_cpp/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-llama-cpp/llama_index/llms/llama_cpp/llama_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-llama-cpp/tests/test_llms_llama_cpp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-llamafile/llama_index/llms/llamafile/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-llamafile/llama_index/llms/llamafile/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-llamafile/tests/test_llms_llamafile.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-lmstudio/llama_index/llms/lmstudio/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-lmstudio/llama_index/llms/lmstudio/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-lmstudio/tests/test_llms_lmstudio.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-localai/llama_index/llms/localai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-localai/llama_index/llms/localai/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-localai/tests/test_llms_localai.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-maritalk/llama_index/llms/maritalk/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-maritalk/llama_index/llms/maritalk/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-meta/llama_index/llms/meta/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-meta/llama_index/llms/meta/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-meta/tests/test_llms_llama.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-mistral-rs/llama_index/llms/mistral_rs/__init__.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-mistral-rs/llama_index/llms/mistral_rs/base.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-mistral-rs/tests/test_llms_mistral-rs.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-mistralai/llama_index/llms/mistralai/__init__.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-mistralai/llama_index/llms/mistralai/base.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-mistralai/llama_index/llms/mistralai/utils.py",
        "providers": [
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-mistralai/tests/test_llms_mistral.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-mlx/llama_index/llms/mlx/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-mlx/llama_index/llms/mlx/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-mlx/llama_index/llms/mlx/tokenizer_utils.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-modelscope/llama_index/llms/modelscope/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-modelscope/llama_index/llms/modelscope/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-modelscope/llama_index/llms/modelscope/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-modelscope/tests/test_modelscope.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-monsterapi/llama_index/llms/monsterapi/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-monsterapi/llama_index/llms/monsterapi/base.py",
        "providers": [
          "llama",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-monsterapi/tests/test_llms_monsterapi.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-mymagic/llama_index/llms/mymagic/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-mymagic/llama_index/llms/mymagic/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nebius/llama_index/llms/nebius/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nebius/llama_index/llms/nebius/base.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nebius/tests/test_llms_nebius.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-netmind/llama_index/llms/netmind/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-netmind/llama_index/llms/netmind/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-netmind/tests/test_llms_netmind.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-neutrino/llama_index/llms/neutrino/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-neutrino/llama_index/llms/neutrino/base.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-neutrino/tests/test_llms_neutrino.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-novita/llama_index/llms/novita/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-novita/llama_index/llms/novita/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-novita/tests/test_llms_novita.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia-tensorrt/llama_index/llms/nvidia_tensorrt/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia-tensorrt/llama_index/llms/nvidia_tensorrt/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia-tensorrt/tests/test_llms_nvidia_tensorrt.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia-triton/llama_index/llms/nvidia_triton/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia-triton/llama_index/llms/nvidia_triton/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia-triton/tests/test_llms_nvidia_triton.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia/llama_index/llms/nvidia/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia/llama_index/llms/nvidia/base.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia/llama_index/llms/nvidia/utils.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia/tests/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia/tests/test_additional_kwargs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia/tests/test_api_key.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia/tests/test_available_models.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia/tests/test_base_url.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia/tests/test_integration.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia/tests/test_mode_switch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia/tests/test_nvidia.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia/tests/test_structured_output.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia/tests/test_text-completion.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia/tests/test_tools.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-nvidia/tests/test_unknown_models.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-oci-data-science/llama_index/llms/oci_data_science/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-oci-data-science/llama_index/llms/oci_data_science/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-oci-data-science/llama_index/llms/oci_data_science/client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-oci-data-science/llama_index/llms/oci_data_science/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-oci-data-science/tests/test_llms_oci_data_science.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-oci-data-science/tests/test_oci_data_science_client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-oci-data-science/tests/test_oci_data_science_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-oci-genai/llama_index/llms/oci_genai/__init__.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-oci-genai/llama_index/llms/oci_genai/base.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-oci-genai/llama_index/llms/oci_genai/utils.py",
        "providers": [
          "cohere",
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-oci-genai/tests/test_llms_oci_genai.py",
        "providers": [
          "cohere",
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-oci-genai/tests/test_oci_genai.py",
        "providers": [
          "cohere",
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-octoai/llama_index/llms/octoai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-octoai/llama_index/llms/octoai/base.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-octoai/llama_index/llms/octoai/utils.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-octoai/tests/test_llms_octoai.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ollama/llama_index/llms/ollama/__init__.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ollama/llama_index/llms/ollama/base.py",
        "providers": [
          "llama",
          "ollama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ollama/tests/test_llms_ollama.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ollama/tests/test_utils.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-opea/llama_index/llms/opea/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-opea/llama_index/llms/opea/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-opea/tests/test_llms_opea.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openai-like/llama_index/llms/openai_like/__init__.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openai-like/llama_index/llms/openai_like/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openai-like/tests/test_llms_openai_like.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openai-like/tests/test_openai_like.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openai-like/tests/test_openai_like_grok.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openai/llama_index/llms/openai/__init__.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openai/llama_index/llms/openai/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openai/llama_index/llms/openai/responses.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openai/llama_index/llms/openai/utils.py",
        "providers": [
          "langchain",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openai/tests/test_llms_openai.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openai/tests/test_openai.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openai/tests/test_openai_responses.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openai/tests/test_openai_utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openrouter/llama_index/llms/openrouter/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openrouter/llama_index/llms/openrouter/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openrouter/tests/test_llms_openrouter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openvino-genai/llama_index/llms/openvino_genai/__init__.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openvino-genai/llama_index/llms/openvino_genai/base.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openvino/llama_index/llms/openvino/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-openvino/llama_index/llms/openvino/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-optimum-intel/llama_index/llms/optimum_intel/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-optimum-intel/llama_index/llms/optimum_intel/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ovhcloud/llama_index/llms/ovhcloud/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ovhcloud/llama_index/llms/ovhcloud/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ovhcloud/llama_index/llms/ovhcloud/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ovhcloud/tests/test_coverage_comprehensive.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-ovhcloud/tests/test_llms_ovhcloud.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-paieas/llama_index/llms/paieas/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-paieas/llama_index/llms/paieas/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-paieas/tests/test_llms_paieas.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-palm/llama_index/llms/palm/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-palm/llama_index/llms/palm/base.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-palm/tests/test_llms_palm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-perplexity/llama_index/llms/perplexity/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-perplexity/llama_index/llms/perplexity/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-perplexity/tests/test_llms_perplexity.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-perplexity/tests/test_perplexity.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-pipeshift/llama_index/llms/pipeshift/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-pipeshift/llama_index/llms/pipeshift/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-pipeshift/tests/test_llms_pipeshift.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-portkey/llama_index/llms/portkey/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-portkey/llama_index/llms/portkey/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-portkey/llama_index/llms/portkey/utils.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-portkey/tests/test_llms_portkey.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-predibase/llama_index/llms/predibase/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-predibase/llama_index/llms/predibase/base.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-predibase/tests/test_llms_predibase.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-premai/llama_index/llms/premai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-premai/llama_index/llms/premai/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-premai/llama_index/llms/premai/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-qianfan/llama_index/llms/qianfan/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-qianfan/llama_index/llms/qianfan/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-qianfan/tests/test_llms_qianfan.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-reka/llama_index/llms/reka/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-reka/llama_index/llms/reka/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-reka/tests/test_llms_reka.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-reka/tests/test_reka.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-replicate/llama_index/llms/replicate/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-replicate/llama_index/llms/replicate/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-replicate/tests/test_llms_replicate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-rungpt/llama_index/llms/rungpt/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-rungpt/llama_index/llms/rungpt/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-rungpt/tests/test_llms_rungpt.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-sagemaker-endpoint/llama_index/llms/sagemaker_endpoint/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-sagemaker-endpoint/llama_index/llms/sagemaker_endpoint/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-sagemaker-endpoint/llama_index/llms/sagemaker_endpoint/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-sagemaker-endpoint/tests/test_llms_sagemaker_endpoint.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-sambanovasystems/llama_index/llms/sambanovasystems/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-sambanovasystems/llama_index/llms/sambanovasystems/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-sambanovasystems/tests/test_llms_sambanovasystems.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-sarvam/llama_index/llms/sarvam/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-sarvam/llama_index/llms/sarvam/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-sarvam/tests/test_llms_servam.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-sglang/llama_index/llms/sglang/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-sglang/llama_index/llms/sglang/base.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-sglang/llama_index/llms/sglang/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-sglang/tests/test_llms_sglang.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-siliconflow/llama_index/llms/siliconflow/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-siliconflow/llama_index/llms/siliconflow/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-siliconflow/tests/test_llms_siliconflow.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-stepfun/llama_index/llms/stepfun/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-stepfun/llama_index/llms/stepfun/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-stepfun/tests/test_llms_stepfun.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-together/llama_index/llms/together/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-together/llama_index/llms/together/base.py",
        "providers": [
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-together/tests/test_llms_together.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-upstage/llama_index/llms/upstage/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-upstage/llama_index/llms/upstage/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-upstage/llama_index/llms/upstage/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-upstage/tests/test_llms_upstage.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-upstage/tests/test_upstage.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-vercel-ai-gateway/llama_index/llms/vercel_ai_gateway/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-vercel-ai-gateway/llama_index/llms/vercel_ai_gateway/base.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-vercel-ai-gateway/tests/test_vercel_ai_gateway.py",
        "providers": [
          "anthropic",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-vertex/llama_index/llms/vertex/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-vertex/llama_index/llms/vertex/base.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-vertex/llama_index/llms/vertex/gemini_utils.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-vertex/llama_index/llms/vertex/utils.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-vertex/tests/test_gemini_utils.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-vertex/tests/test_llms_vertex.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-vertex/tests/test_tool_required.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-vllm/llama_index/llms/vllm/__init__.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-vllm/llama_index/llms/vllm/base.py",
        "providers": [
          "llama",
          "mistral",
          "openai",
          "vllm"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-vllm/tests/test_integration.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-vllm/tests/test_llms_vllm.py",
        "providers": [
          "llama",
          "vllm"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-xinference/llama_index/llms/xinference/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-xinference/llama_index/llms/xinference/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-xinference/llama_index/llms/xinference/utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-xinference/tests/test_llms_xinference.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-yi/llama_index/llms/yi/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-yi/llama_index/llms/yi/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-yi/tests/test_llms_yi.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-you/llama_index/llms/you/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-you/llama_index/llms/you/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-you/tests/test_llms_you.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-zhipuai/llama_index/llms/zhipuai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-zhipuai/llama_index/llms/zhipuai/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/llms/llama-index-llms-zhipuai/tests/test_llms_zhipuai.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/memory/llama-index-memory-bedrock-agentcore/llama_index/memory/bedrock_agentcore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/memory/llama-index-memory-bedrock-agentcore/llama_index/memory/bedrock_agentcore/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/memory/llama-index-memory-bedrock-agentcore/llama_index/memory/bedrock_agentcore/utils.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/memory/llama-index-memory-bedrock-agentcore/tests/test_agentcore_memory.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/memory/llama-index-memory-mem0/llama_index/memory/mem0/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/memory/llama-index-memory-mem0/llama_index/memory/mem0/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/memory/llama-index-memory-mem0/llama_index/memory/mem0/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/memory/llama-index-memory-mem0/tests/test_mem0.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/node_parser/llama-index-node-parser-alibabacloud-aisearch/llama_index/node_parser/alibabacloud_aisearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/node_parser/llama-index-node-parser-alibabacloud-aisearch/llama_index/node_parser/alibabacloud_aisearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/node_parser/llama-index-node-parser-alibabacloud-aisearch/tests/test_node_parser_alibabacloud_aisearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/node_parser/llama-index-node-parser-docling/llama_index/node_parser/docling/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/node_parser/llama-index-node-parser-docling/llama_index/node_parser/docling/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/node_parser/llama-index-node-parser-docling/tests/test_node_parser_docling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/node_parser/llama-index-node-parser-relational-dashscope/llama_index/node_parser/dashscope/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/node_parser/llama-index-node-parser-relational-dashscope/llama_index/node_parser/dashscope/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/node_parser/llama-index-node-parser-relational-dashscope/tests/test_node_parser_relational_dashscope.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/node_parser/llama-index-node-parser-slide/llama_index/node_parser/slide/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/node_parser/llama-index-node-parser-slide/llama_index/node_parser/slide/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/node_parser/llama-index-node-parser-slide/tests/test_node_parser_slide.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/node_parser/llama-index-node-parser-topic/llama_index/node_parser/topic/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/node_parser/llama-index-node-parser-topic/llama_index/node_parser/topic/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/node_parser/llama-index-node-parser-topic/tests/test_node_parser_topic.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/observability/llama-index-observability-otel/llama_index/observability/otel/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/observability/llama-index-observability-otel/llama_index/observability/otel/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/observability/llama-index-observability-otel/tests/test_initialization.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/output_parsers/llama-index-output-parsers-guardrails/llama_index/output_parsers/guardrails/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/output_parsers/llama-index-output-parsers-guardrails/llama_index/output_parsers/guardrails/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/output_parsers/llama-index-output-parsers-guardrails/tests/test_output_parsers_guardrails.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/output_parsers/llama-index-output-parsers-langchain/llama_index/output_parsers/langchain/__init__.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/output_parsers/llama-index-output-parsers-langchain/llama_index/output_parsers/langchain/base.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/output_parsers/llama-index-output-parsers-langchain/tests/test_output_parsers_langchain.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-aimon-rerank/llama_index/postprocessor/aimon_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-aimon-rerank/llama_index/postprocessor/aimon_rerank/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-aimon-rerank/tests/test_postprocessor_aimon_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-alibabacloud-aisearch-rerank/llama_index/postprocessor/alibabacloud_aisearch_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-alibabacloud-aisearch-rerank/llama_index/postprocessor/alibabacloud_aisearch_rerank/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-alibabacloud-aisearch-rerank/tests/test_postprocessor_alibabacloud_aisearch_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-bedrock-rerank/llama_index/postprocessor/bedrock_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-bedrock-rerank/llama_index/postprocessor/bedrock_rerank/base.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-bedrock-rerank/tests/test_postprocessor_bedrock_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-cohere-rerank/llama_index/postprocessor/cohere_rerank/__init__.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-cohere-rerank/llama_index/postprocessor/cohere_rerank/base.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-cohere-rerank/tests/test_postprocessor_cohere_rerank.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-colbert-rerank/llama_index/postprocessor/colbert_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-colbert-rerank/llama_index/postprocessor/colbert_rerank/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-colbert-rerank/tests/test_postprocessor_colbert_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-colpali-rerank/llama_index/postprocessor/colpali_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-colpali-rerank/llama_index/postprocessor/colpali_rerank/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-colpali-rerank/tests/test_postprocessor_colpali_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-contextual-rerank/llama_index/postprocessor/contextual_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-contextual-rerank/llama_index/postprocessor/contextual_rerank/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-contextual-rerank/tests/test_contextual_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-dashscope-rerank/llama_index/postprocessor/dashscope_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-dashscope-rerank/llama_index/postprocessor/dashscope_rerank/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-dashscope-rerank/tests/test_postprocessor_dashscope_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-flag-embedding-reranker/llama_index/postprocessor/flag_embedding_reranker/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-flag-embedding-reranker/llama_index/postprocessor/flag_embedding_reranker/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-flag-embedding-reranker/tests/test_postprocessor_flag_embedding_reranker.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-flashrank-rerank/llama_index/postprocessor/flashrank_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-flashrank-rerank/llama_index/postprocessor/flashrank_rerank/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-flashrank-rerank/tests/test_postprocessor_flashrank_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-ibm/llama_index/postprocessor/ibm/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-ibm/llama_index/postprocessor/ibm/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-ibm/llama_index/postprocessor/ibm/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-ibm/tests/test_ibm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-ibm/tests/test_postprocessor_ibm_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-jinaai-rerank/llama_index/postprocessor/jinaai_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-jinaai-rerank/llama_index/postprocessor/jinaai_rerank/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-jinaai-rerank/tests/test_postprocessor_jinaai_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-longllmlingua/llama_index/postprocessor/longllmlingua/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-longllmlingua/llama_index/postprocessor/longllmlingua/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-longllmlingua/tests/test_postprocessor_longllmlingua.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-mixedbreadai-rerank/llama_index/postprocessor/mixedbreadai_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-mixedbreadai-rerank/llama_index/postprocessor/mixedbreadai_rerank/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-mixedbreadai-rerank/tests/test_postprocessor_mixedbreadai_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-nvidia-rerank/llama_index/postprocessor/nvidia_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-nvidia-rerank/llama_index/postprocessor/nvidia_rerank/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-nvidia-rerank/llama_index/postprocessor/nvidia_rerank/utils.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-nvidia-rerank/tests/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-nvidia-rerank/tests/test_api_key.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-nvidia-rerank/tests/test_available_models.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-nvidia-rerank/tests/test_base_url.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-nvidia-rerank/tests/test_postprocessor_nvidia_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-nvidia-rerank/tests/test_truncate.py",
        "providers": [
          "llama",
          "mistral"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-openvino-rerank/llama_index/postprocessor/openvino_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-openvino-rerank/llama_index/postprocessor/openvino_rerank/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-pinecone-native-rerank/llama_index/postprocessor/pinecone_native_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-pinecone-native-rerank/llama_index/postprocessor/pinecone_native_rerank/base.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-pinecone-native-rerank/tests/test_pinecone_native_reranker.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-presidio/llama_index/postprocessor/presidio/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-presidio/llama_index/postprocessor/presidio/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-presidio/tests/test_postprocessor_presidio.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-rankgpt-rerank/llama_index/postprocessor/rankgpt_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-rankgpt-rerank/llama_index/postprocessor/rankgpt_rerank/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-rankgpt-rerank/tests/test_postprocessor_rankgpt_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-rankllm-rerank/llama_index/postprocessor/rankllm_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-rankllm-rerank/llama_index/postprocessor/rankllm_rerank/base.py",
        "providers": [
          "gemini",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-rankllm-rerank/tests/test_postprocessor_rankllm-rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-sbert-rerank/llama_index/postprocessor/sbert_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-sbert-rerank/llama_index/postprocessor/sbert_rerank/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-sbert-rerank/tests/test_postprocessor_sbert_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-siliconflow-rerank/llama_index/postprocessor/siliconflow_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-siliconflow-rerank/llama_index/postprocessor/siliconflow_rerank/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-siliconflow-rerank/tests/test_postprocessor_siliconflow_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-tei-rerank/llama_index/postprocessor/tei_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-tei-rerank/llama_index/postprocessor/tei_rerank/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-tei-rerank/tests/test_postprocessor_tei_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-voyageai-rerank/llama_index/postprocessor/voyageai_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-voyageai-rerank/llama_index/postprocessor/voyageai_rerank/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-voyageai-rerank/tests/test_postprocessor_voyageai-rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-xinference-rerank/llama_index/postprocessor/xinference_rerank/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-xinference-rerank/llama_index/postprocessor/xinference_rerank/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/postprocessor/llama-index-postprocessor-xinference-rerank/tests/test_postprocessor_xinference_rerank.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/program/llama-index-program-evaporate/llama_index/program/evaporate/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/program/llama-index-program-evaporate/llama_index/program/evaporate/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/program/llama-index-program-evaporate/llama_index/program/evaporate/df.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/program/llama-index-program-evaporate/llama_index/program/evaporate/extractor.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/program/llama-index-program-evaporate/llama_index/program/evaporate/prompts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/program/llama-index-program-evaporate/tests/test_program_evaporate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/program/llama-index-program-guidance/llama_index/program/guidance/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/program/llama-index-program-guidance/llama_index/program/guidance/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/program/llama-index-program-guidance/llama_index/program/guidance/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/program/llama-index-program-guidance/tests/test_program_guidance.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/program/llama-index-program-lmformatenforcer/llama_index/program/lmformatenforcer/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/program/llama-index-program-lmformatenforcer/llama_index/program/lmformatenforcer/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/program/llama-index-program-lmformatenforcer/llama_index/program/lmformatenforcer/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/program/llama-index-program-lmformatenforcer/tests/test_program_lmformatenforcer.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/protocols/llama-index-protocols-ag-ui/llama_index/protocols/ag_ui/agent.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/protocols/llama-index-protocols-ag-ui/llama_index/protocols/ag_ui/events.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/protocols/llama-index-protocols-ag-ui/llama_index/protocols/ag_ui/router.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/protocols/llama-index-protocols-ag-ui/llama_index/protocols/ag_ui/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/question_gen/llama-index-question-gen-guidance/llama_index/question_gen/guidance/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/question_gen/llama-index-question-gen-guidance/llama_index/question_gen/guidance/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/question_gen/llama-index-question-gen-guidance/tests/test_question_gen_guidance_generator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-agent-search/llama_index/readers/agent_search/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-agent-search/llama_index/readers/agent_search/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-cdk/llama_index/readers/airbyte_cdk/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-cdk/llama_index/readers/airbyte_cdk/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-cdk/tests/test_readers_airbyte_cdk.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-gong/llama_index/readers/airbyte_gong/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-gong/llama_index/readers/airbyte_gong/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-gong/tests/test_readers_airbyte_gong.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-hubspot/llama_index/readers/airbyte_hubspot/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-hubspot/llama_index/readers/airbyte_hubspot/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-hubspot/tests/test_readers_airbyte_hubspot.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-salesforce/llama_index/readers/airbyte_salesforce/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-salesforce/llama_index/readers/airbyte_salesforce/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-salesforce/tests/test_readers_airbyte_salesforce.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-shopify/llama_index/readers/airbyte_shopify/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-shopify/llama_index/readers/airbyte_shopify/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-shopify/tests/test_readers_airbyte_shopify.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-stripe/llama_index/readers/airbyte_stripe/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-stripe/llama_index/readers/airbyte_stripe/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-stripe/tests/test_readers_airbyte_stripe.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-typeform/llama_index/readers/airbyte_typeform/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-typeform/llama_index/readers/airbyte_typeform/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-typeform/tests/test_readers_airbyte_typeform.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-zendesk-support/llama_index/readers/airbyte_zendesk_support/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-zendesk-support/llama_index/readers/airbyte_zendesk_support/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airbyte-zendesk-support/tests/test_readers_airbyte_zendesk_support.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airtable/llama_index/readers/airtable/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-airtable/llama_index/readers/airtable/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-alibabacloud-aisearch/llama_index/readers/alibabacloud_aisearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-alibabacloud-aisearch/llama_index/readers/alibabacloud_aisearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-alibabacloud-aisearch/tests/test_readers_alibabacloud_aisearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-apify/llama_index/readers/apify/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-apify/llama_index/readers/apify/actor/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-apify/llama_index/readers/apify/actor/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-apify/llama_index/readers/apify/dataset/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-apify/llama_index/readers/apify/dataset/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-apify/tests/test_readers_apify.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-arango-db/llama_index/readers/arango_db/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-arango-db/llama_index/readers/arango_db/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-arango-db/tests/test_arangodb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-arango-db/tests/test_readers_arango_db.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-asana/llama_index/readers/asana/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-asana/llama_index/readers/asana/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-assemblyai/llama_index/readers/assemblyai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-assemblyai/llama_index/readers/assemblyai/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-astra-db/llama_index/readers/astra_db/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-astra-db/llama_index/readers/astra_db/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-astra-db/tests/test_astra_db.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-astra-db/tests/test_readers_astra_db.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-athena/llama_index/readers/athena/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-athena/llama_index/readers/athena/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-awadb/llama_index/readers/awadb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-awadb/llama_index/readers/awadb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-awadb/tests/test_readers_awadb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-azcognitive-search/llama_index/readers/azcognitive_search/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-azcognitive-search/llama_index/readers/azcognitive_search/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-azcognitive-search/tests/test_readers_azcognitive_search.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-azstorage-blob/llama_index/readers/azstorage_blob/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-azstorage-blob/llama_index/readers/azstorage_blob/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-azstorage-blob/tests/test_readers_azstorage_blob.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-bagel/llama_index/readers/bagel/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-bagel/llama_index/readers/bagel/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-bagel/tests/test_readers_bagel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-bilibili/llama_index/readers/bilibili/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-bilibili/llama_index/readers/bilibili/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-bitbucket/llama_index/readers/bitbucket/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-bitbucket/llama_index/readers/bitbucket/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-bitbucket/tests/test_readers_bitbucket.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-boarddocs/llama_index/readers/boarddocs/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-boarddocs/llama_index/readers/boarddocs/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-box/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-box/examples/box_reader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-box/llama_index/readers/box/BoxAPI/box_api.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-box/llama_index/readers/box/BoxAPI/box_llama_adaptors.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-box/llama_index/readers/box/BoxReader/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-box/llama_index/readers/box/BoxReaderAIExtraction/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-box/llama_index/readers/box/BoxReaderAIPrompt/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-box/llama_index/readers/box/BoxReaderTextExtraction/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-box/llama_index/readers/box/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-box/tests/test_readers_box_ai_extract.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-box/tests/test_readers_box_ai_prompt.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-box/tests/test_readers_box_jwt.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-box/tests/test_readers_box_reader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-box/tests/test_readers_box_text_extraction.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-chatgpt-plugin/llama_index/readers/chatgpt_plugin/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-chatgpt-plugin/llama_index/readers/chatgpt_plugin/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-chatgpt-plugin/tests/test_readers_chatgpt_plugin.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-chroma/llama_index/readers/chroma/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-chroma/llama_index/readers/chroma/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-chroma/tests/test_readers_chroma.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-confluence/llama_index/readers/confluence/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-confluence/llama_index/readers/confluence/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-confluence/llama_index/readers/confluence/event.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-confluence/tests/run_basic_tests.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-confluence/tests/test_html_parser.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-confluence/tests/test_integration.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-confluence/tests/test_new_features.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-confluence/tests/test_readers_confluence.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-couchbase/llama_index/readers/couchbase/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-couchbase/llama_index/readers/couchbase/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-couchbase/tests/test_readers_couchbase.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-couchdb/llama_index/readers/couchdb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-couchdb/llama_index/readers/couchdb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-dad-jokes/llama_index/readers/dad_jokes/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-dad-jokes/llama_index/readers/dad_jokes/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-dad-jokes/tests/test_readers_dad_jokes.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-dashscope/llama_index/readers/dashscope/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-dashscope/llama_index/readers/dashscope/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-dashscope/llama_index/readers/dashscope/domain/lease_domains.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-dashscope/llama_index/readers/dashscope/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-dashscope/tests/test_readers_dashscope.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-dashvector/llama_index/readers/dashvector/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-dashvector/llama_index/readers/dashvector/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-dashvector/tests/test_readers_dashvector.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-database/llama_index/readers/database/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-database/llama_index/readers/database/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-database/tests/test_readers_database.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-deeplake/llama_index/readers/deeplake/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-deeplake/llama_index/readers/deeplake/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-deeplake/tests/test_readers_deeplake.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-discord/llama_index/readers/discord/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-discord/llama_index/readers/discord/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-discord/tests/test_readers_discord_reader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-docling/llama_index/readers/docling/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-docling/llama_index/readers/docling/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-docling/tests/test_readers_docling.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-docstring-walker/llama_index/readers/docstring_walker/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-docstring-walker/llama_index/readers/docstring_walker/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-docstring-walker/tests/test_readers_docstring_walker.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-docugami/llama_index/readers/docugami/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-docugami/llama_index/readers/docugami/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-docugami/tests/test_readers_docugami.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-document360/llama_index/readers/document360/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-document360/tests/test_readers_document360.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-earnings-call-transcript/llama_index/readers/earnings_call_transcript/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-earnings-call-transcript/llama_index/readers/earnings_call_transcript/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-earnings-call-transcript/tests/test_readers_earnings_call_transcript.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-elasticsearch/llama_index/readers/elasticsearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-elasticsearch/llama_index/readers/elasticsearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-elasticsearch/tests/test_readers_elasticsearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-faiss/llama_index/readers/faiss/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-faiss/llama_index/readers/faiss/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-faiss/tests/test_readers_faiss.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-feedly-rss/llama_index/readers/feedly_rss/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-feedly-rss/llama_index/readers/feedly_rss/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-feedly-rss/tests/test_readers_feedly_rss.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-feishu-docs/llama_index/readers/feishu_docs/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-feishu-docs/llama_index/readers/feishu_docs/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-feishu-docs/tests/test_readers_feishu_docs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/docs/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/docs/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/epub/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/epub/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/flat/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/flat/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/html/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/html/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/image/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/image/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/image_caption/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/image_caption/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/image_deplot/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/image_deplot/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/image_vision_llm/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/image_vision_llm/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/ipynb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/ipynb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/markdown/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/markdown/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/mbox/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/mbox/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/paged_csv/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/paged_csv/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/pymu_pdf/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/pymu_pdf/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/rtf/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/rtf/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/slides/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/slides/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/slides/content_extractor.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/slides/image_extractor.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/tabular/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/tabular/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/unstructured/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/unstructured/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/video_audio/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/video_audio/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/xml/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/xml/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/tests/test_docs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/tests/test_file.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/tests/test_html_reader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/tests/test_image_vision_llm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/tests/test_markdown.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/tests/test_readers_file.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/tests/test_rtf.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/tests/test_slides.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-file/tests/test_xml.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-firebase-realtimedb/llama_index/readers/firebase_realtimedb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-firebase-realtimedb/llama_index/readers/firebase_realtimedb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-firebase-realtimedb/tests/test_readers_firebase_realtimedb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-firestore/llama_index/readers/firestore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-firestore/llama_index/readers/firestore/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-firestore/tests/test_readers_firestore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-gcs/llama_index/readers/gcs/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-gcs/llama_index/readers/gcs/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-gcs/tests/test_readers_gcs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-genius/llama_index/readers/genius/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-genius/llama_index/readers/genius/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-genius/tests/test_readers_genius.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-gitbook/llama_index/readers/gitbook/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-gitbook/llama_index/readers/gitbook/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-gitbook/tests/test_gitbook_client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-gitbook/tests/test_simple_gitbook_reader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-github/examples/github_app_example.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-github/llama_index/readers/github/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-github/llama_index/readers/github/collaborators/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-github/llama_index/readers/github/collaborators/github_client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-github/llama_index/readers/github/issues/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-github/llama_index/readers/github/issues/github_client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-github/llama_index/readers/github/repository/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-github/llama_index/readers/github/repository/event.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-github/llama_index/readers/github/repository/github_client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-github/llama_index/readers/github/repository/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-github/tests/test_gh_base_url.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-github/tests/test_github_app_auth.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-github/tests/test_github_repository_reader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-gitlab/llama_index/readers/gitlab/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-gitlab/llama_index/readers/gitlab/issues/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-gitlab/llama_index/readers/gitlab/repository/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-gitlab/tests/test_readers_gitlab_issues.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-gitlab/tests/test_readers_gitlab_repository.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-google/llama_index/readers/google/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-google/llama_index/readers/google/calendar/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-google/llama_index/readers/google/chat/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-google/llama_index/readers/google/docs/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-google/llama_index/readers/google/drive/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-google/llama_index/readers/google/gmail/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-google/llama_index/readers/google/keep/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-google/llama_index/readers/google/maps/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-google/llama_index/readers/google/sheets/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-google/tests/test_readers_google_drive.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-google/tests/test_readers_google_maps.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-gpt-repo/llama_index/readers/gpt_repo/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-gpt-repo/llama_index/readers/gpt_repo/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-gpt-repo/tests/test_readers_gpt_repo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-graphdb-cypher/llama_index/readers/graphdb_cypher/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-graphdb-cypher/llama_index/readers/graphdb_cypher/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-graphdb-cypher/tests/test_readers_graphdb_cypher.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-graphql/llama_index/readers/graphql/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-graphql/llama_index/readers/graphql/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-graphql/tests/test_readers_graphql.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-guru/llama_index/readers/guru/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-guru/llama_index/readers/guru/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-guru/tests/test_readers_guru.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-hatena-blog/llama_index/readers/hatena_blog/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-hatena-blog/llama_index/readers/hatena_blog/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-hatena-blog/tests/test_readers_hatena_blog.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-hubspot/llama_index/readers/hubspot/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-hubspot/llama_index/readers/hubspot/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-hubspot/tests/test_readers_hubspot.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-huggingface-fs/llama_index/readers/huggingface_fs/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-huggingface-fs/llama_index/readers/huggingface_fs/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-huggingface-fs/tests/test_readers_huggingface.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-hwp/llama_index/readers/hwp/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-hwp/llama_index/readers/hwp/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-hwp/tests/test_readers_hwp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-iceberg/llama_index/readers/iceberg/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-iceberg/llama_index/readers/iceberg/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-iceberg/tests/test_readers_iceberg.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-imdb-review/llama_index/readers/imdb_review/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-imdb-review/llama_index/readers/imdb_review/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-imdb-review/tests/test_readers_imdb_review.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-intercom/llama_index/readers/intercom/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-intercom/llama_index/readers/intercom/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-intercom/tests/test_readers_intercom.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-jaguar/llama_index/readers/jaguar/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-jaguar/llama_index/readers/jaguar/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-jaguar/tests/test_readers_jaguar.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-jira/llama_index/readers/jira/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-jira/llama_index/readers/jira/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-jira/tests/test_readers_jira.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-joplin/llama_index/readers/joplin/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-joplin/llama_index/readers/joplin/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-joplin/tests/test_readers_joplin.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-json/llama_index/readers/json/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-json/llama_index/readers/json/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-json/tests/test_readers_json.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-kaltura/llama_index/readers/kaltura_esearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-kaltura/llama_index/readers/kaltura_esearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-kaltura/tests/test_readers_kaltura.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-kibela/llama_index/readers/kibela/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-kibela/llama_index/readers/kibela/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-kibela/tests/test_readers_kibela.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-legacy-office/llama_index/readers/legacy_office/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-legacy-office/llama_index/readers/legacy_office/reader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-lilac/llama_index/readers/lilac/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-lilac/llama_index/readers/lilac/base.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-lilac/tests/test_readers_lilac_reader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-linear/llama_index/readers/linear/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-linear/llama_index/readers/linear/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-linear/tests/test_readers_linear.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-llama-parse/llama_index/readers/llama_parse/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-macrometa-gdn/llama_index/readers/macrometa_gdn/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-macrometa-gdn/llama_index/readers/macrometa_gdn/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-macrometa-gdn/tests/test_readers_macrometa_gdn.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-make-com/llama_index/readers/make_com/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-make-com/llama_index/readers/make_com/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-make-com/tests/test_readers_make_com.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-mangadex/llama_index/readers/mangadex/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-mangadex/llama_index/readers/mangadex/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-mangadex/tests/test_readers_mangadex.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-mangoapps-guides/llama_index/readers/mangoapps_guides/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-mangoapps-guides/llama_index/readers/mangoapps_guides/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-mangoapps-guides/tests/test_readers_mangoapps_guides.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-maps/llama_index/readers/maps/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-maps/llama_index/readers/maps/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-maps/tests/test_readers_maps.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-markitdown/llama_index/readers/markitdown/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-markitdown/llama_index/readers/markitdown/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-markitdown/tests/test_markitdownreader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-mbox/llama_index/readers/mbox/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-mbox/llama_index/readers/mbox/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-mbox/tests/test_readers_mbox.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-memos/llama_index/readers/memos/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-memos/llama_index/readers/memos/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-memos/tests/test_readers_memos.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-metal/llama_index/readers/metal/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-metal/llama_index/readers/metal/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-metal/tests/test_readers_metal.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-microsoft-onedrive/llama_index/readers/microsoft_onedrive/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-microsoft-onedrive/llama_index/readers/microsoft_onedrive/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-microsoft-onedrive/tests/test_readers_microsoft_onedrive.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-microsoft-outlook-emails/llama_index/readers/microsoft_outlook_emails/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-microsoft-outlook-emails/tests/test_readers_microsoft_outlook_mails.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-microsoft-outlook/llama_index/readers/microsoft_outlook/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-microsoft-outlook/llama_index/readers/microsoft_outlook/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-microsoft-outlook/tests/test_readers_outlook_localcalendar.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-microsoft-sharepoint/llama_index/readers/microsoft_sharepoint/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-microsoft-sharepoint/llama_index/readers/microsoft_sharepoint/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-microsoft-sharepoint/tests/test_readers_microsoft_sharepoint.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-milvus/llama_index/readers/milvus/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-milvus/llama_index/readers/milvus/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-milvus/tests/test_readers_milvus.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-minio/llama_index/readers/minio/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-minio/llama_index/readers/minio/boto3_client/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-minio/llama_index/readers/minio/minio_client/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-minio/tests/test_readers_minio.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-mondaydotcom/llama_index/readers/mondaydotcom/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-mondaydotcom/llama_index/readers/mondaydotcom/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-mondaydotcom/tests/test_readers_mondaydotcom.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-mongodb/llama_index/readers/mongodb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-mongodb/llama_index/readers/mongodb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-mongodb/tests/test_readers_mongo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-myscale/llama_index/readers/myscale/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-myscale/llama_index/readers/myscale/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-myscale/tests/test_readers_myscale.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-notion/llama_index/readers/notion/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-notion/llama_index/readers/notion/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-notion/tests/test_readers_notion.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-nougat-ocr/llama_index/readers/nougat_ocr/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-nougat-ocr/llama_index/readers/nougat_ocr/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-nougat-ocr/tests/test_readers_nougat_ocr.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-obsidian/llama_index/readers/obsidian/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-obsidian/llama_index/readers/obsidian/base.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-obsidian/tests/test_readers_obsidian.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-openalex/llama_index/readers/openalex/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-openalex/llama_index/readers/openalex/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-openalex/tests/test_readers_openalex.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-opendal/llama_index/readers/opendal/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-opendal/llama_index/readers/opendal/azblob/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-opendal/llama_index/readers/opendal/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-opendal/llama_index/readers/opendal/gcs/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-opendal/llama_index/readers/opendal/s3/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-opendal/tests/test_readers_opendal_reader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-opensearch/llama_index/readers/opensearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-opensearch/llama_index/readers/opensearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-opensearch/tests/test_readers_opensearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-oracleai/llama_index/readers/oracleai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-oracleai/llama_index/readers/oracleai/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-oracleai/tests/test_readers_oracleai.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-oxylabs/llama_index/readers/oxylabs/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-oxylabs/llama_index/readers/oxylabs/amazon_bestsellers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-oxylabs/llama_index/readers/oxylabs/amazon_pricing.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-oxylabs/llama_index/readers/oxylabs/amazon_product.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-oxylabs/llama_index/readers/oxylabs/amazon_reviews.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-oxylabs/llama_index/readers/oxylabs/amazon_search.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-oxylabs/llama_index/readers/oxylabs/amazon_sellers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-oxylabs/llama_index/readers/oxylabs/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-oxylabs/llama_index/readers/oxylabs/google_ads.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-oxylabs/llama_index/readers/oxylabs/google_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-oxylabs/llama_index/readers/oxylabs/google_search.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-oxylabs/llama_index/readers/oxylabs/youtube_transcripts.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-oxylabs/tests/test_readers_oxylabs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-paddle-ocr/llama_index/readers/paddle_ocr/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-paddle-ocr/llama_index/readers/paddle_ocr/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-paddle-ocr/tests/test_readers_paddle_ocr.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-pandas-ai/llama_index/readers/pandas_ai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-pandas-ai/llama_index/readers/pandas_ai/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-papers/llama_index/readers/papers/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-papers/llama_index/readers/papers/arxiv/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-papers/llama_index/readers/papers/arxiv/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-papers/llama_index/readers/papers/pubmed/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-papers/tests/test_readers_papers.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-patentsview/llama_index/readers/patentsview/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-patentsview/llama_index/readers/patentsview/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-patentsview/tests/test_readers_patentsview.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-pathway/llama_index/readers/pathway/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-pathway/llama_index/readers/pathway/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-pathway/tests/test_readers_pathway.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-pdb/llama_index/readers/pdb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-pdb/llama_index/readers/pdb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-pdb/tests/test_readers_pdb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-pdf-marker/llama_index/readers/pdf_marker/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-pdf-marker/llama_index/readers/pdf_marker/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-pdf-table/llama_index/readers/pdf_table/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-pdf-table/llama_index/readers/pdf_table/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-pdf-table/tests/test_readers_pdf_table.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-pebblo/llama_index/readers/pebblo/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-pebblo/llama_index/readers/pebblo/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-pebblo/llama_index/readers/pebblo/utility.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-pebblo/tests/test_readers_pebblo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-preprocess/llama_index/readers/preprocess/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-preprocess/llama_index/readers/preprocess/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-preprocess/tests/test_readers_preprocess.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-psychic/llama_index/readers/psychic/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-psychic/llama_index/readers/psychic/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-psychic/tests/test_readers_psychic.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-qdrant/llama_index/readers/qdrant/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-qdrant/llama_index/readers/qdrant/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-qdrant/tests/test_readers_qdrant.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-quip/llama_index/readers/quip/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-quip/llama_index/readers/quip/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-quip/tests/test_readers_quip.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-rayyan/llama_index/readers/rayyan/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-rayyan/llama_index/readers/rayyan/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-rayyan/tests/test_readers_rayyan.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-readwise/llama_index/readers/readwise/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-readwise/llama_index/readers/readwise/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-readwise/tests/test_readers_readwise.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-reddit/llama_index/readers/reddit/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-reddit/llama_index/readers/reddit/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-reddit/tests/test_readers_reddit.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-remote-depth/llama_index/readers/remote_depth/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-remote-depth/llama_index/readers/remote_depth/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-remote-depth/tests/test_readers_remote_depth.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-remote/llama_index/readers/remote/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-remote/llama_index/readers/remote/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-remote/tests/test_readers_remote.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-s3/llama_index/readers/s3/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-s3/llama_index/readers/s3/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-s3/tests/test_readers_s3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-sec-filings/llama_index/readers/sec_filings/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-sec-filings/llama_index/readers/sec_filings/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-sec-filings/llama_index/readers/sec_filings/prepline_sec_filings/api/section.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-sec-filings/llama_index/readers/sec_filings/prepline_sec_filings/fetch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-sec-filings/llama_index/readers/sec_filings/prepline_sec_filings/sec_document.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-sec-filings/llama_index/readers/sec_filings/sec_filings.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-sec-filings/tests/test_readers_sec_filings.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-semanticscholar/llama_index/readers/semanticscholar/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-semanticscholar/llama_index/readers/semanticscholar/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-semanticscholar/tests/test.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-semanticscholar/tests/test_readers_semanticscholar.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-service-now/llama_index/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-service-now/llama_index/readers/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-service-now/llama_index/readers/service_now/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-service-now/llama_index/readers/service_now/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-service-now/llama_index/readers/service_now/event.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-service-now/tests/test_snow_kb_reader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-singlestore/llama_index/readers/singlestore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-singlestore/llama_index/readers/singlestore/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-singlestore/tests/test_readers_singlestore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-slack/llama_index/readers/slack/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-slack/llama_index/readers/slack/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-slack/tests/test_readers_slack.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-smart-pdf-loader/llama_index/readers/smart_pdf_loader/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-smart-pdf-loader/llama_index/readers/smart_pdf_loader/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-snowflake/llama_index/readers/snowflake/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-snowflake/llama_index/readers/snowflake/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-snowflake/tests/test_readers_snowflake.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-solr/llama_index/readers/solr/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-solr/llama_index/readers/solr/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-solr/tests/test_readers_solr.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-spotify/llama_index/readers/spotify/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-spotify/llama_index/readers/spotify/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-spotify/tests/test_readers_spotify.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-stackoverflow/llama_index/readers/stackoverflow/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-stackoverflow/llama_index/readers/stackoverflow/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-stackoverflow/tests/test_readers_stackoverflow.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-steamship/llama_index/readers/steamship/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-steamship/llama_index/readers/steamship/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-steamship/tests/test_readers_steamship.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-string-iterable/llama_index/readers/string_iterable/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-string-iterable/llama_index/readers/string_iterable/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-string-iterable/tests/test_readers_string_iterable.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-stripe-docs/llama_index/readers/stripe_docs/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-stripe-docs/llama_index/readers/stripe_docs/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-structured-data/llama_index/readers/structured_data/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-structured-data/llama_index/readers/structured_data/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-structured-data/tests/test_readers_structured_data.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-telegram/llama_index/readers/telegram/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-telegram/llama_index/readers/telegram/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-telegram/tests/test_readers_telegram.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-toggl/llama_index/readers/toggl/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-toggl/llama_index/readers/toggl/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-trello/llama_index/readers/trello/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-trello/llama_index/readers/trello/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-trello/tests/test_readers_trello.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-twitter/llama_index/readers/twitter/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-twitter/llama_index/readers/twitter/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-twitter/tests/test_readers_twitter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-txtai/llama_index/readers/txtai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-txtai/llama_index/readers/txtai/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-txtai/tests/test_readers_txtai.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-uniprot/llama_index/readers/uniprot/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-uniprot/llama_index/readers/uniprot/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-uniprot/tests/test_uniprot_reader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-upstage/llama_index/readers/upstage/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-upstage/llama_index/readers/upstage/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-upstage/llama_index/readers/upstage/document_parse.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-upstage/tests/test_readers_upstage.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-weather/llama_index/readers/weather/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-weather/llama_index/readers/weather/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-weather/tests/test_readers_weather.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-weaviate/llama_index/readers/weaviate/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-weaviate/llama_index/readers/weaviate/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-weaviate/tests/test_readers_weaviate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/agentql_web/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/async_web/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/beautiful_soup_web/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/browserbase_web/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/firecrawl_web/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/hyperbrowser_web/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/main_content_extractor/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/news/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/olostep_web/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/oxylabs_web/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/readability_web/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/rss/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/rss_news/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/scrapfly_web/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/scrapy_web/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/scrapy_web/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/simple_web/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/sitemap/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/spider_web/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/trafilatura_web/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/unstructured_web/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/whole_site/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/zenrows_web/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/zenrows_web/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/zyte_web/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/tests/test_async_web.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/tests/test_firecrawl_requests.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/tests/test_firecrawl_web_reader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/tests/test_readers_oxylabs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/tests/test_readers_rss.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/tests/test_scrapy_web_reader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/tests/test_simple_webreader.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-web/tests/test_zenrows_web.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-whatsapp/llama_index/readers/whatsapp/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-whatsapp/llama_index/readers/whatsapp/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-whatsapp/tests/test_readers_whatsapp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-whisper/llama_index/readers/whisper/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-whisper/llama_index/readers/whisper/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-whisper/tests/test_readers_whisper.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-wikipedia/llama_index/readers/wikipedia/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-wikipedia/llama_index/readers/wikipedia/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-wikipedia/tests/test_readers_wikipedia.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-wordlift/llama_index/readers/wordlift/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-wordlift/llama_index/readers/wordlift/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-wordlift/tests/test_readers_wordlift.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-wordpress/llama_index/readers/wordpress/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-wordpress/llama_index/readers/wordpress/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-wordpress/tests/test_readers_wordpress.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-youtube-transcript/llama_index/readers/youtube_transcript/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-youtube-transcript/llama_index/readers/youtube_transcript/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-youtube-transcript/tests/test_readers_youtube_transcript.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-zendesk/llama_index/readers/zendesk/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-zendesk/llama_index/readers/zendesk/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-zendesk/tests/test_readers_zendesk.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-zep/llama_index/readers/zep/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-zep/llama_index/readers/zep/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-zep/tests/test_readers_zep.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-zulip/llama_index/readers/zulip/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-zulip/llama_index/readers/zulip/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-zulip/tests/test_readers_zulip.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-zyte-serp/llama_index/readers/zyte_serp/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-zyte-serp/llama_index/readers/zyte_serp/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/readers/llama-index-readers-zyte-serp/tests/test_readers_zyte_serp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/response_synthesizers/llama-index-response-synthesizers-google/llama_index/response_synthesizers/google/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/response_synthesizers/llama-index-response-synthesizers-google/llama_index/response_synthesizers/google/base.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/response_synthesizers/llama-index-response-synthesizers-google/tests/test_response_synthesizers_google.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-alletra-x10000/llama_index/retrievers/alletra_x10000_retriever/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-alletra-x10000/llama_index/retrievers/alletra_x10000_retriever/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-alletra-x10000/tests/test_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-bedrock/llama_index/retrievers/bedrock/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-bedrock/llama_index/retrievers/bedrock/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-bedrock/tests/test_retrievers_bedrock.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-bm25/llama_index/retrievers/bm25/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-bm25/llama_index/retrievers/bm25/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-bm25/tests/test_retrievers_bm25_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-duckdb-retriever/llama_index/retrievers/duckdb_retriever/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-duckdb-retriever/llama_index/retrievers/duckdb_retriever/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-duckdb-retriever/tests/test_retrievers_bm25_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-galaxia/examples/example_1.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-galaxia/llama_index/retrievers/galaxia/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-galaxia/llama_index/retrievers/galaxia/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-galaxia/tests/test_retrievers_galaxia.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-kendra/llama_index/retrievers/kendra/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-kendra/llama_index/retrievers/kendra/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-kendra/tests/test_retrievers_kendra.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-mongodb-atlas-bm25-retriever/llama_index/retrievers/mongodb_atlas_bm25_retriever/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-mongodb-atlas-bm25-retriever/llama_index/retrievers/mongodb_atlas_bm25_retriever/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-mongodb-atlas-bm25-retriever/tests/test_retrievers_bm25_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-pathway/llama_index/retrievers/pathway/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-pathway/llama_index/retrievers/pathway/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-pathway/tests/test_retrievers_pathway_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-superlinked/examples/steam_games_example.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-superlinked/llama_index/retrievers/superlinked/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-superlinked/llama_index/retrievers/superlinked/retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-superlinked/tests/test_integration_superlinked_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-superlinked/tests/test_unit_superlinked_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-tldw/llama_index/retrievers/tldw/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-tldw/llama_index/retrievers/tldw/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-tldw/tests/test_retrievers_tldw_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-vectorize/llama_index/retrievers/vectorize/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-vectorize/llama_index/retrievers/vectorize/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-vectorize/tests/test_retrievers_vectorize.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-vertexai-search/llama_index/retrievers/vertexai_search/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-vertexai-search/llama_index/retrievers/vertexai_search/_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-vertexai-search/llama_index/retrievers/vertexai_search/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-vertexai-search/tests/test_retrievers_vertexai_search.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-videodb/llama_index/retrievers/videodb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-videodb/llama_index/retrievers/videodb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-videodb/tests/test_retrievers_videdb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-you/llama_index/retrievers/you/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-you/llama_index/retrievers/you/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/retrievers/llama-index-retrievers-you/tests/test_retrievers_you_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/selectors/llama-index-selectors-notdiamond/llama_index/selectors/notdiamond/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/selectors/llama-index-selectors-notdiamond/llama_index/selectors/notdiamond/base.py",
        "providers": [
          "anthropic",
          "cohere",
          "llama",
          "mistral",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/sparse_embeddings/llama-index-sparse-embeddings-fastembed/llama_index/sparse_embeddings/fastembed/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/sparse_embeddings/llama-index-sparse-embeddings-fastembed/llama_index/sparse_embeddings/fastembed/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/sparse_embeddings/llama-index-sparse-embeddings-fastembed/tests/test_sparse_embeddings_fastembed.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-azure/llama_index/storage/chat_store/azure/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-azure/llama_index/storage/chat_store/azure/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-azure/tests/test_chat_store_azure_chat_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-azurecosmosmongovcore/llama_index/storage/chat_store/azurecosmosmongovcore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-azurecosmosmongovcore/llama_index/storage/chat_store/azurecosmosmongovcore/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-azurecosmosmongovcore/tests/test_storage_azurecosmosmongovcore_chat_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-azurecosmosnosql/llama_index/storage/chat_store/azurecosmosnosql/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-azurecosmosnosql/llama_index/storage/chat_store/azurecosmosnosql/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-azurecosmosnosql/tests/test_storage_azurecosmosnosql_chat_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-dynamodb/llama_index/storage/chat_store/dynamodb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-dynamodb/llama_index/storage/chat_store/dynamodb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-dynamodb/tests/test_chat_store_dynamodb_chat_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-gel/llama_index/storage/chat_store/gel/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-gel/llama_index/storage/chat_store/gel/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-gel/tests/test_chat_store_gel_chat_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-mongo/llama_index/storage/chat_store/mongo/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-mongo/llama_index/storage/chat_store/mongo/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-mongo/tests/test_chat_store_mongo_chat_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-postgres/llama_index/storage/chat_store/postgres/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-postgres/llama_index/storage/chat_store/postgres/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-postgres/tests/test_chat_store_postgres_chat_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-redis/llama_index/storage/chat_store/redis/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-redis/llama_index/storage/chat_store/redis/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-redis/tests/test_chat_store_redis_chat_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-sqlite/llama_index/storage/chat_store/sqlite/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-sqlite/llama_index/storage/chat_store/sqlite/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-sqlite/tests/test_chat_store_sqlite_chat_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-tablestore/llama_index/storage/chat_store/tablestore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-tablestore/llama_index/storage/chat_store/tablestore/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-tablestore/tests/test_chat_store_tablestore_chat_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-upstash/llama_index/storage/chat_store/upstash/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-upstash/llama_index/storage/chat_store/upstash/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-upstash/tests/test_chat_store_upstash_chat_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-yugabytedb/llama_index/storage/chat_store/yugabytedb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-yugabytedb/llama_index/storage/chat_store/yugabytedb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-yugabytedb/tests/test_chat_store_yugabytedb_chat_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-azure/llama_index/storage/docstore/azure/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-azure/llama_index/storage/docstore/azure/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-azure/tests/test_storage_docstore_azure.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-azurecosmosnosql/llama_index/storage/docstore/azurecosmosnosql/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-azurecosmosnosql/llama_index/storage/docstore/azurecosmosnosql/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-azurecosmosnosql/tests/test_storage_document_store_azurecosmosnosql.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-couchbase/llama_index/storage/docstore/couchbase/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-couchbase/llama_index/storage/docstore/couchbase/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-couchbase/tests/test_docstore_couchbase.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-duckdb/llama_index/storage/docstore/duckdb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-duckdb/llama_index/storage/docstore/duckdb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-duckdb/tests/test_storage_docstore_duckdb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-dynamodb/llama_index/storage/docstore/dynamodb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-dynamodb/llama_index/storage/docstore/dynamodb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-dynamodb/tests/test_storage_docstore_dynamodb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-elasticsearch/llama_index/storage/docstore/elasticsearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-elasticsearch/llama_index/storage/docstore/elasticsearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-elasticsearch/tests/test_storage_docstore_elasticsearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-firestore/llama_index/storage/docstore/firestore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-firestore/llama_index/storage/docstore/firestore/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-firestore/tests/test_storage_docstore_firestore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-gel/llama_index/storage/docstore/gel/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-gel/llama_index/storage/docstore/gel/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-gel/tests/test_gel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-gel/tests/test_storage_docstore_gel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-mongodb/llama_index/storage/docstore/mongodb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-mongodb/llama_index/storage/docstore/mongodb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-mongodb/tests/test_storage_docstore_mongodb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-postgres/llama_index/storage/docstore/postgres/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-postgres/llama_index/storage/docstore/postgres/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-redis/llama_index/storage/docstore/redis/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-redis/llama_index/storage/docstore/redis/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-redis/tests/test_storage_docstore_redis.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-tablestore/llama_index/storage/docstore/tablestore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-tablestore/llama_index/storage/docstore/tablestore/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/docstore/llama-index-storage-docstore-tablestore/tests/test_storage_docstore_tablestore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-azure/llama_index/storage/index_store/azure/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-azure/llama_index/storage/index_store/azure/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-azure/tests/test_storage_index_store_azure.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-azurecosmosnosql/llama_index/storage/index_store/azurecosmosnosql/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-azurecosmosnosql/llama_index/storage/index_store/azurecosmosnosql/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-azurecosmosnosql/tests/test_storage_index_store_azurecosmosnosql.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-couchbase/llama_index/storage/index_store/couchbase/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-couchbase/llama_index/storage/index_store/couchbase/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-couchbase/tests/test_index_store_couchbase.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-duckdb/llama_index/storage/index_store/duckdb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-duckdb/llama_index/storage/index_store/duckdb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-duckdb/tests/test_storage_index_store_duckdb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-dynamodb/llama_index/storage/index_store/dynamodb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-dynamodb/llama_index/storage/index_store/dynamodb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-dynamodb/tests/test_storage_index_store_dynamodb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-elasticsearch/llama_index/storage/index_store/elasticsearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-elasticsearch/llama_index/storage/index_store/elasticsearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-elasticsearch/tests/test_storage_index_store_elasticsearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-firestore/llama_index/storage/index_store/firestore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-firestore/llama_index/storage/index_store/firestore/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-firestore/tests/test_storage_index_store_firestore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-gel/llama_index/storage/index_store/gel/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-gel/llama_index/storage/index_store/gel/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-gel/tests/test_gel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-gel/tests/test_storage_index_store_gel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-mongodb/llama_index/storage/index_store/mongodb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-mongodb/llama_index/storage/index_store/mongodb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-mongodb/tests/test_storage_index_store_mongodb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-postgres/llama_index/storage/index_store/postgres/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-postgres/llama_index/storage/index_store/postgres/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-postgres/tests/test_storage_index_store_postgres.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-redis/llama_index/storage/index_store/redis/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-redis/llama_index/storage/index_store/redis/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-redis/tests/test_storage_index_store_redis.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-tablestore/llama_index/storage/index_store/tablestore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-tablestore/llama_index/storage/index_store/tablestore/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/index_store/llama-index-storage-index-store-tablestore/tests/test_storage_index_store_tablestore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-azure/llama_index/storage/kvstore/azure/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-azure/llama_index/storage/kvstore/azure/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-azure/tests/test_storage_kvstore_azure.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-azurecosmosnosql/llama_index/storage/kvstore/azurecosmosnosql/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-azurecosmosnosql/llama_index/storage/kvstore/azurecosmosnosql/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-azurecosmosnosql/tests/test_storage_azurecosmosnosql_kv_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-couchbase/llama_index/storage/kvstore/couchbase/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-couchbase/llama_index/storage/kvstore/couchbase/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-couchbase/tests/test_kvstore_couchbase.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-duckdb/llama_index/storage/kvstore/duckdb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-duckdb/llama_index/storage/kvstore/duckdb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-duckdb/tests/test_storage_kvstore_duckdb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-dynamodb/llama_index/storage/kvstore/dynamodb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-dynamodb/llama_index/storage/kvstore/dynamodb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-dynamodb/tests/test_storage_kvstore_dynamodb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-elasticsearch/llama_index/storage/kvstore/elasticsearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-elasticsearch/llama_index/storage/kvstore/elasticsearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-elasticsearch/tests/test_storage_kvstore_elasticsearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-firestore/llama_index/storage/kvstore/firestore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-firestore/llama_index/storage/kvstore/firestore/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-firestore/tests/test_storage_kvstore_firestore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-gel/llama_index/storage/kvstore/gel/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-gel/llama_index/storage/kvstore/gel/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-gel/tests/test_gel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-gel/tests/test_storage_kvstore_gel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-mongodb/llama_index/storage/kvstore/mongodb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-mongodb/llama_index/storage/kvstore/mongodb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-mongodb/tests/test_storage_kvstore_mongodb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-postgres/llama_index/storage/kvstore/postgres/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-postgres/llama_index/storage/kvstore/postgres/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-postgres/tests/test_postgres.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-postgres/tests/test_storage_kvstore_postgres.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-redis/llama_index/storage/kvstore/redis/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-redis/llama_index/storage/kvstore/redis/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-redis/tests/test_storage_kvstore_redis.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-s3/llama_index/storage/kvstore/s3/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-s3/llama_index/storage/kvstore/s3/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-s3/tests/test_store_kvstore_s3.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-tablestore/llama_index/storage/kvstore/tablestore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-tablestore/llama_index/storage/kvstore/tablestore/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/storage/kvstore/llama-index-storage-kvstore-tablestore/tests/test_storage_kvstore_tablestore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-agentql/llama_index/tools/agentql/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-agentql/llama_index/tools/agentql/agentql_browser_tool/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-agentql/llama_index/tools/agentql/agentql_rest_api_tool/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-agentql/llama_index/tools/agentql/const.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-agentql/llama_index/tools/agentql/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-agentql/tests/test_browser_spec.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-agentql/tests/test_rest_api_spec.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-airweave/llama_index/tools/airweave/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-airweave/llama_index/tools/airweave/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-airweave/tests/test_tools_airweave.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-artifact-editor/llama_index/tools/artifact_editor/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-artifact-editor/llama_index/tools/artifact_editor/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-artifact-editor/llama_index/tools/artifact_editor/memory_block.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-artifact-editor/tests/test_artifact_editor.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-arxiv/llama_index/tools/arxiv/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-arxiv/llama_index/tools/arxiv/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-arxiv/tests/test_tools_arxiv.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-aws-bedrock-agentcore/llama_index/tools/aws_bedrock_agentcore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-aws-bedrock-agentcore/llama_index/tools/aws_bedrock_agentcore/browser/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-aws-bedrock-agentcore/llama_index/tools/aws_bedrock_agentcore/browser/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-aws-bedrock-agentcore/llama_index/tools/aws_bedrock_agentcore/code_interpreter/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-aws-bedrock-agentcore/llama_index/tools/aws_bedrock_agentcore/code_interpreter/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-aws-bedrock-agentcore/tests/test_browser.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-aws-bedrock-agentcore/tests/test_browser_async.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-aws-bedrock-agentcore/tests/test_browser_session_manager.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-aws-bedrock-agentcore/tests/test_browser_spec.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-aws-bedrock-agentcore/tests/test_browser_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-aws-bedrock-agentcore/tests/test_code_interpreter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-aws-bedrock-agentcore/tests/test_code_interpreter_spec.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-azure-code-interpreter/llama_index/tools/azure_code_interpreter/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-azure-code-interpreter/llama_index/tools/azure_code_interpreter/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-azure-code-interpreter/tests/test_tools_azure_aca_session.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-azure-cv/llama_index/tools/azure_cv/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-azure-cv/llama_index/tools/azure_cv/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-azure-cv/tests/test_tools_azure_cv.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-azure-speech/llama_index/tools/azure_speech/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-azure-speech/llama_index/tools/azure_speech/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-azure-speech/tests/test_tools_azure_speech.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-azure-translate/llama_index/tools/azure_translate/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-azure-translate/llama_index/tools/azure_translate/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-azure-translate/tests/test_tools_azure_translate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-bing-search/llama_index/tools/bing_search/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-bing-search/llama_index/tools/bing_search/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-bing-search/tests/test_tools_bing_search.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-box/llama_index/tools/box/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-box/llama_index/tools/box/ai_extract/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-box/llama_index/tools/box/ai_prompt/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-box/llama_index/tools/box/search/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-box/llama_index/tools/box/search_by_metadata/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-box/llama_index/tools/box/text_extract/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-box/tests/conftest.py",
        "providers": [
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-box/tests/test_tools_box.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-box/tests/test_tools_box_ai_extract.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-box/tests/test_tools_box_ai_prompt.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-box/tests/test_tools_box_search.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-box/tests/test_tools_box_search_by_metadata.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-box/tests/test_tools_box_text_extract.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-brave-search/llama_index/tools/brave_search/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-brave-search/llama_index/tools/brave_search/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-brave-search/tests/test_tools_brave_search.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-brightdata/llama_index/tools/brightdata/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-brightdata/llama_index/tools/brightdata/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-brightdata/tests/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-brightdata/tests/test_tools_brightdata.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-cassandra/llama_index/tools/cassandra/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-cassandra/llama_index/tools/cassandra/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-cassandra/llama_index/tools/cassandra/cassandra_database_wrapper.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-cassandra/tests/test_tools_cassandra.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-chatgpt-plugin/llama_index/tools/chatgpt_plugin/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-chatgpt-plugin/llama_index/tools/chatgpt_plugin/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-chatgpt-plugin/tests/test_tools_chatgpt_plugin.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-code-interpreter/llama_index/tools/code_interpreter/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-code-interpreter/llama_index/tools/code_interpreter/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-code-interpreter/tests/test_tools_code_interpreter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-cogniswitch/llama_index/tools/cogniswitch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-cogniswitch/llama_index/tools/cogniswitch/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-cogniswitch/tests/test_tools_cogniswitch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-dappier/llama_index/tools/dappier/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-dappier/llama_index/tools/dappier/ai_recommendations/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-dappier/llama_index/tools/dappier/real_time_search/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-dappier/tests/test_tools_dappier_ai_recommendations.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-dappier/tests/test_tools_dappier_real_time_search.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-database/llama_index/tools/database/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-database/llama_index/tools/database/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-database/tests/test_tools_database.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-desearch/llama_index/tools/desearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-desearch/llama_index/tools/desearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-desearch/tests/test_tools_desearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-duckduckgo/llama_index/tools/duckduckgo/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-duckduckgo/llama_index/tools/duckduckgo/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-duckduckgo/tests/test_tools_duckduckgo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-elevenlabs/llama_index/tools/elevenlabs/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-elevenlabs/llama_index/tools/elevenlabs/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-elevenlabs/tests/test_tools_elevenlabs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-exa/llama_index/tools/exa/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-exa/llama_index/tools/exa/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-exa/tests/test_tools_exa.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-finance/llama_index/tools/finance/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-finance/llama_index/tools/finance/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-finance/llama_index/tools/finance/comparisons.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-finance/llama_index/tools/finance/news.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-finance/tests/test_finance_tools.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-google/llama_index/tools/google/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-google/llama_index/tools/google/calendar/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-google/llama_index/tools/google/gmail/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-google/llama_index/tools/google/search/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-google/tests/test_tools_google.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-graphql/llama_index/tools/graphql/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-graphql/llama_index/tools/graphql/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-graphql/tests/test_tools_graphql.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-hive/examples/hive_demo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-hive/llama_index/tools/hive/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-hive/llama_index/tools/hive/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-ionic-shopping/llama_index/tools/ionic_shopping/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-ionic-shopping/llama_index/tools/ionic_shopping/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-ionic-shopping/tests/test_tools_ionic_shopping.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-jina/llama_index/tools/jina/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-jina/llama_index/tools/jina/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-jina/tests/test_tools_jina.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-jira-issue/llama_index/tools/jira_issue/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-jira-issue/llama_index/tools/jira_issue/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-jira-issue/tests/test_tools_jira_issue.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-jira/llama_index/tools/jira/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-jira/llama_index/tools/jira/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-jira/tests/test_tools_jira.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-linkup-research/llama_index/tools/linkup_research/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-linkup-research/llama_index/tools/linkup_research/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-linkup-research/tests/test_tools_linkup_research.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-mcp/llama_index/tools/mcp/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-mcp/llama_index/tools/mcp/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-mcp/llama_index/tools/mcp/client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-mcp/llama_index/tools/mcp/tool_spec_mixins.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-mcp/llama_index/tools/mcp/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-mcp/tests/test_client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-mcp/tests/test_tools_mcp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-measurespace/examples/example.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-measurespace/llama_index/tools/measurespace/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-measurespace/llama_index/tools/measurespace/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-metaphor/llama_index/tools/metaphor/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-metaphor/llama_index/tools/metaphor/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-metaphor/tests/test_tools_metaphor.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-multion/llama_index/tools/multion/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-multion/llama_index/tools/multion/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-multion/tests/test_tools_multion.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-neo4j/llama_index/tools/neo4j/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-neo4j/llama_index/tools/neo4j/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-notion/llama_index/tools/notion/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-notion/llama_index/tools/notion/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-notion/tests/test_tools_notion.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-openai/llama_index/tools/openai/__init__.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-openai/llama_index/tools/openai/image_generation/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-openai/tests/test_tools_openai_image_generation.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-openapi/llama_index/tools/openapi/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-openapi/llama_index/tools/openapi/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-openapi/tests/test_tools_openapi.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-playgrounds/llama_index/tools/playgrounds/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-playgrounds/llama_index/tools/playgrounds/subgraph_connector/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-playgrounds/llama_index/tools/playgrounds/subgraph_inspector/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-playgrounds/tests/test_tools_playgrounds.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-playwright/llama_index/tools/playwright/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-playwright/llama_index/tools/playwright/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-playwright/tests/test_tools_playwright.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-python-file/llama_index/tools/python_file/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-python-file/llama_index/tools/python_file/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-python-file/tests/test_tools_python_file.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-requests/llama_index/tools/requests/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-requests/llama_index/tools/requests/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-requests/tests/test_tools_requests.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-salesforce/llama_index/tools/salesforce/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-salesforce/llama_index/tools/salesforce/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-salesforce/tests/test_tools_salesforce.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-scrapegraph/examples/complete-scrapegraph-examples.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-scrapegraph/examples/scrapegraph-agentic-scraper-llama-index.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-scrapegraph/examples/scrapegraph-markdowinify-llama-index.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-scrapegraph/examples/scrapegraph-scrape-llama-index.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-scrapegraph/examples/scrapegraph-search-llama-index.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-scrapegraph/examples/scrapegraph-smartscraper-lama-index.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-scrapegraph/llama_index/tools/scrapegraph/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-scrapegraph/llama_index/tools/scrapegraph/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-scrapegraph/tests/test_integration.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-scrapegraph/tests/test_tools_scrapegraph.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-serpex/examples/serpex_example.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-serpex/llama_index/tools/serpex/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-serpex/llama_index/tools/serpex/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-serpex/test_local.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-serpex/tests/test_serpex.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-shopify/llama_index/tools/shopify/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-shopify/llama_index/tools/shopify/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-shopify/tests/test_tools_shopify.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-signnow/examples/from_env.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-signnow/llama_index/tools/signnow/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-signnow/llama_index/tools/signnow/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-signnow/tests/test_delegation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-signnow/tests/test_env_and_bin.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-signnow/tests/test_tools_signnow.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-slack/llama_index/tools/slack/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-slack/llama_index/tools/slack/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-slack/tests/test_tools_slack.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-tavily-research/llama_index/tools/tavily_research/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-tavily-research/llama_index/tools/tavily_research/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-tavily-research/tests/test_tools_tavily_research.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-text-to-image/llama_index/tools/text_to_image/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-text-to-image/llama_index/tools/text_to_image/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-text-to-image/tests/test_tools_text_to_image.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-valyu/examples/context.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-valyu/examples/retriever_example.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-valyu/llama_index/tools/valyu/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-valyu/llama_index/tools/valyu/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-valyu/llama_index/tools/valyu/retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-valyu/tests/test_tools_valyu.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-vectara-query/llama_index/tools/vectara_query/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-vectara-query/llama_index/tools/vectara_query/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-vectara-query/tests/test_tools_vectara_query.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-vector-db/llama_index/tools/vector_db/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-vector-db/llama_index/tools/vector_db/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-vector-db/tests/test_tools_vector_db.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-waii/llama_index/tools/waii/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-waii/llama_index/tools/waii/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-waii/tests/test_tools_waii.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-weather/llama_index/tools/weather/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-weather/llama_index/tools/weather/base.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-weather/tests/test_tools_weather.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-wikipedia/llama_index/tools/wikipedia/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-wikipedia/llama_index/tools/wikipedia/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-wikipedia/tests/test_tools_wikipedia.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-wolfram-alpha/llama_index/tools/wolfram_alpha/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-wolfram-alpha/llama_index/tools/wolfram_alpha/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-wolfram-alpha/tests/test_tools_wolfram_alpha.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-yahoo-finance/llama_index/tools/yahoo_finance/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-yahoo-finance/llama_index/tools/yahoo_finance/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-yahoo-finance/tests/test_tools_yahoo_finance.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-yelp/llama_index/tools/yelp/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-yelp/llama_index/tools/yelp/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-yelp/tests/test_tools_yelp.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-zapier/llama_index/tools/zapier/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-zapier/llama_index/tools/zapier/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/tools/llama-index-tools-zapier/tests/test_tools_zapier.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-ApertureDB/llama_index/vector_stores/ApertureDB/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-ApertureDB/llama_index/vector_stores/ApertureDB/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-ApertureDB/tests/test_vector_stores_ApertureDB.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-alibabacloud-opensearch/llama_index/vector_stores/alibabacloud_opensearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-alibabacloud-opensearch/llama_index/vector_stores/alibabacloud_opensearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-alibabacloud-opensearch/tests/test_vector_stores_alibabacloud_opensearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-analyticdb/llama_index/vector_stores/analyticdb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-analyticdb/llama_index/vector_stores/analyticdb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-analyticdb/tests/test_analyticdb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-analyticdb/tests/test_vector_stores_analyticdb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-astra-db/llama_index/vector_stores/astra_db/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-astra-db/llama_index/vector_stores/astra_db/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-astra-db/tests/test_astra_db.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-astra-db/tests/test_vector_stores_astra_db.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-awadb/llama_index/vector_stores/awadb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-awadb/llama_index/vector_stores/awadb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-awadb/tests/test_vector_stores_awadb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-awsdocdb/llama_index/vector_stores/awsdocdb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-awsdocdb/llama_index/vector_stores/awsdocdb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-awsdocdb/tests/test_docdb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azureaisearch/llama_index/vector_stores/azureaisearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azureaisearch/llama_index/vector_stores/azureaisearch/azureaisearch_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azureaisearch/llama_index/vector_stores/azureaisearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azureaisearch/tests/test_azureaisearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azureaisearch/tests/test_vector_stores_cogsearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azurecosmosmongo/llama_index/vector_stores/azurecosmosmongo/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azurecosmosmongo/llama_index/vector_stores/azurecosmosmongo/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azurecosmosmongo/tests/test_azurecosmosmongo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azurecosmosmongo/tests/test_vector_stores_azurecosmosmongo.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azurecosmosnosql/llama_index/vector_stores/azurecosmosnosql/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azurecosmosnosql/llama_index/vector_stores/azurecosmosnosql/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azurecosmosnosql/tests/test_azurecosmosnosql.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azurecosmosnosql/tests/test_vector_stores_azurecosmosnosql.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azurepostgresql/llama_index/vector_stores/azure_postgres/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azurepostgresql/tests/common/test_connection.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azurepostgresql/tests/common/test_shared.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azurepostgresql/tests/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azurepostgresql/tests/llama_index/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-azurepostgresql/tests/llama_index/test_vectorstore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-bagel/llama_index/vector_stores/bagel/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-bagel/llama_index/vector_stores/bagel/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-bagel/tests/test_vector_stores_bagel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-baiduvectordb/llama_index/vector_stores/baiduvectordb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-baiduvectordb/llama_index/vector_stores/baiduvectordb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-baiduvectordb/tests/test_vector_stores_baiduvectordb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-bigquery/llama_index/vector_stores/bigquery/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-bigquery/llama_index/vector_stores/bigquery/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-bigquery/llama_index/vector_stores/bigquery/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-bigquery/tests/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-bigquery/tests/test_add.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-bigquery/tests/test_delete.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-bigquery/tests/test_delete_nodes.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-bigquery/tests/test_get_nodes.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-bigquery/tests/test_parameterized_queries.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-bigquery/tests/test_vector_search.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-bigquery/tests/test_vector_stores_bigquery.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-cassandra/llama_index/vector_stores/cassandra/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-cassandra/llama_index/vector_stores/cassandra/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-cassandra/tests/test_cassandra.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-cassandra/tests/test_vector_stores_cassandra.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-chroma/llama_index/vector_stores/chroma/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-chroma/llama_index/vector_stores/chroma/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-chroma/tests/test_chromadb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-chroma/tests/test_mmr.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-chroma/tests/test_vector_stores_chroma.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-clickhouse/llama_index/vector_stores/clickhouse/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-clickhouse/llama_index/vector_stores/clickhouse/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-clickhouse/tests/test_clickhouse.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-couchbase/llama_index/vector_stores/couchbase/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-couchbase/llama_index/vector_stores/couchbase/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-couchbase/tests/test_couchbase_query_vector_store.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-couchbase/tests/test_couchbase_search_vector_stores.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-dashvector/llama_index/vector_stores/dashvector/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-dashvector/llama_index/vector_stores/dashvector/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-dashvector/tests/test_vector_stores_dashvector.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-databricks/llama_index/vector_stores/databricks/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-databricks/llama_index/vector_stores/databricks/base.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-db2/llama_index/vector_stores/db2/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-db2/llama_index/vector_stores/db2/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-db2/tests/test_vector_stores_db2.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-deeplake/llama_index/vector_stores/deeplake/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-deeplake/llama_index/vector_stores/deeplake/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-deeplake/tests/test_vector_stores_deeplake.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-docarray/llama_index/vector_stores/docarray/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-docarray/llama_index/vector_stores/docarray/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-docarray/llama_index/vector_stores/docarray/hnsw.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-docarray/llama_index/vector_stores/docarray/in_memory.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-docarray/tests/test_vector_stores_docarray.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-duckdb/llama_index/vector_stores/duckdb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-duckdb/llama_index/vector_stores/duckdb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-duckdb/tests/test_duckdb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-dynamodb/llama_index/vector_stores/dynamodb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-dynamodb/llama_index/vector_stores/dynamodb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-dynamodb/tests/test_vector_stores_dynamodb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-elasticsearch/llama_index/vector_stores/elasticsearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-elasticsearch/llama_index/vector_stores/elasticsearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-elasticsearch/llama_index/vector_stores/elasticsearch/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-elasticsearch/tests/test_vector_stores_elasticsearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-epsilla/llama_index/vector_stores/epsilla/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-epsilla/llama_index/vector_stores/epsilla/base.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-epsilla/tests/test_vector_stores_epsilla.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-faiss/llama_index/vector_stores/faiss/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-faiss/llama_index/vector_stores/faiss/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-faiss/llama_index/vector_stores/faiss/map_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-faiss/tests/test_vector_stores_faiss.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-firestore/llama_index/vector_stores/firestore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-firestore/llama_index/vector_stores/firestore/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-firestore/llama_index/vector_stores/firestore/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-firestore/tests/test_firestore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-firestore/tests/test_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-firestore/tests/test_vector_store_firestore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-gel/llama_index/vector_stores/gel/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-gel/llama_index/vector_stores/gel/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-gel/tests/test_gel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-gel/tests/test_vector_stores_gel.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-google/llama_index/vector_stores/google/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-google/llama_index/vector_stores/google/base.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-google/llama_index/vector_stores/google/genai_extension.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-google/tests/test_vector_stores_google.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-hnswlib/llama_index/vector_stores/hnswlib/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-hnswlib/llama_index/vector_stores/hnswlib/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-hnswlib/tests/test_vector_stores_hnswlib.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-hologres/llama_index/vector_stores/hologres/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-hologres/llama_index/vector_stores/hologres/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-hologres/tests/test_hologres.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-hologres/tests/test_vector_stores_hologres.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-jaguar/llama_index/vector_stores/jaguar/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-jaguar/llama_index/vector_stores/jaguar/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-jaguar/tests/test_vector_stores_jaguar.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-kdbai/llama_index/vector_stores/kdbai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-kdbai/llama_index/vector_stores/kdbai/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-lancedb/llama_index/vector_stores/lancedb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-lancedb/llama_index/vector_stores/lancedb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-lancedb/llama_index/vector_stores/lancedb/util.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-lancedb/tests/test_vector_stores_lancedb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-lantern/llama_index/vector_stores/lantern/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-lantern/llama_index/vector_stores/lantern/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-lantern/tests/test_lantern.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-lantern/tests/test_vector_stores_lantern.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-lindorm/llama_index/vector_stores/lindorm/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-lindorm/llama_index/vector_stores/lindorm/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-lindorm/tests/test_lindorm_client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-lindorm/tests/test_vector_stores_lindorm.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-mariadb/llama_index/vector_stores/mariadb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-mariadb/llama_index/vector_stores/mariadb/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-mariadb/tests/test_mariadb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-mariadb/tests/test_vector_stores_mariadb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-milvus/llama_index/vector_stores/milvus/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-milvus/llama_index/vector_stores/milvus/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-milvus/llama_index/vector_stores/milvus/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-milvus/tests/test_vector_stores_milvus.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-mongodb/llama_index/vector_stores/mongodb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-mongodb/llama_index/vector_stores/mongodb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-mongodb/llama_index/vector_stores/mongodb/pipelines.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-mongodb/tests/conftest.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-mongodb/tests/test_filters.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-mongodb/tests/test_index_commands.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-mongodb/tests/test_integration.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-mongodb/tests/test_vector_stores_mongodb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-mongodb/tests/test_vectorstore.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-moorcheh/llama_index/vector_stores/moorcheh/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-moorcheh/llama_index/vector_stores/moorcheh/base.py",
        "providers": [
          "anthropic",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-moorcheh/llama_index/vector_stores/moorcheh/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-moorcheh/tests/test_vector_stores_moorcheh.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-neo4jvector/llama_index/vector_stores/neo4jvector/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-neo4jvector/llama_index/vector_stores/neo4jvector/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-neo4jvector/tests/test_vector_stores_neo4jvector.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-neptune/llama_index/vector_stores/neptune/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-neptune/llama_index/vector_stores/neptune/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-neptune/tests/test_vector_stores_neptune.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-nile/examples/multitenant.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-nile/llama_index/vector_stores/nile/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-nile/llama_index/vector_stores/nile/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-nile/tests/test_vector_stores_nile.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-objectbox/llama_index/vector_stores/objectbox/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-objectbox/llama_index/vector_stores/objectbox/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-objectbox/tests/test_objectbox.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-objectbox/tests/test_vector_stores_objectbox.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-oceanbase/llama_index/vector_stores/oceanbase/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-oceanbase/llama_index/vector_stores/oceanbase/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-oceanbase/tests/test_vector_stores_oceanbase.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-openGauss/llama_index/vector_stores/openGauss/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-openGauss/llama_index/vector_stores/openGauss/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-openGauss/tests/test_opengauss.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-openGauss/tests/test_vector_stores_opengauss.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-opensearch/llama_index/vector_stores/opensearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-opensearch/llama_index/vector_stores/opensearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-opensearch/tests/test_opensearch_client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-opensearch/tests/test_vector_stores_opensearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-oracledb/llama_index/vector_stores/oracledb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-oracledb/llama_index/vector_stores/oracledb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-oracledb/tests/test_vector_stores_orallamavs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-pgvecto-rs/llama_index/vector_stores/pgvecto_rs/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-pgvecto-rs/llama_index/vector_stores/pgvecto_rs/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-pgvecto-rs/tests/test_vector_stores_pgvecto_rs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-pinecone/llama_index/vector_stores/pinecone/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-pinecone/llama_index/vector_stores/pinecone/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-pinecone/llama_index/vector_stores/pinecone/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-pinecone/tests/test_vector_stores_pinecone.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-postgres/llama_index/vector_stores/postgres/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-postgres/llama_index/vector_stores/postgres/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-postgres/tests/test_postgres.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-postgres/tests/test_vector_stores_postgres.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-qdrant/llama_index/vector_stores/qdrant/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-qdrant/llama_index/vector_stores/qdrant/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-qdrant/llama_index/vector_stores/qdrant/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-qdrant/tests/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-qdrant/tests/test_vector_stores_qdrant.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-redis/llama_index/vector_stores/redis/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-redis/llama_index/vector_stores/redis/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-redis/llama_index/vector_stores/redis/schema.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-redis/llama_index/vector_stores/redis/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-redis/tests/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-redis/tests/test_vector_stores_redis.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-relyt/llama_index/vector_stores/relyt/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-relyt/llama_index/vector_stores/relyt/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-relyt/tests/test_vector_stores_relyt.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-rocksetdb/llama_index/vector_stores/rocksetdb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-rocksetdb/llama_index/vector_stores/rocksetdb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-rocksetdb/tests/test_vector_stores_rocksetdb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-s3/llama_index/vector_stores/s3/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-s3/llama_index/vector_stores/s3/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-s3/tests/test_s3_vector_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-singlestoredb/llama_index/vector_stores/singlestoredb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-singlestoredb/llama_index/vector_stores/singlestoredb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-singlestoredb/tests/test_vector_stores_singlestoredb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-solr/llama_index/vector_stores/solr/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-solr/llama_index/vector_stores/solr/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-solr/llama_index/vector_stores/solr/client/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-solr/llama_index/vector_stores/solr/client/_base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-solr/llama_index/vector_stores/solr/client/async_.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-solr/llama_index/vector_stores/solr/client/sync.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-solr/llama_index/vector_stores/solr/client/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-solr/llama_index/vector_stores/solr/query_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-solr/tests/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-solr/tests/integration/test_solr_vector_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-solr/tests/test_async_client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-solr/tests/test_client_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-solr/tests/test_solr_vector_store.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-solr/tests/test_solr_vector_store_query_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-solr/tests/test_sync_client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-solr/tests/test_types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-supabase/llama_index/vector_stores/supabase/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-supabase/llama_index/vector_stores/supabase/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-supabase/tests/test_vector_stores_supabase.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-tablestore/llama_index/vector_stores/tablestore/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-tablestore/llama_index/vector_stores/tablestore/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-tablestore/tests/test_vector_stores_tablestore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-tair/llama_index/vector_stores/tair/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-tair/llama_index/vector_stores/tair/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-tair/tests/test_vector_stores_tair.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-tencentvectordb/llama_index/vector_stores/tencentvectordb/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-tencentvectordb/llama_index/vector_stores/tencentvectordb/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-tencentvectordb/tests/test_vector_stores_tencentvectordb.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-tidbvector/llama_index/vector_stores/tidbvector/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-tidbvector/llama_index/vector_stores/tidbvector/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-tidbvector/tests/test_vector_stores_tidbvector.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-timescalevector/llama_index/vector_stores/timescalevector/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-timescalevector/llama_index/vector_stores/timescalevector/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-txtai/llama_index/vector_stores/txtai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-txtai/llama_index/vector_stores/txtai/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-txtai/tests/test_vector_stores_txtai.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-typesense/llama_index/vector_stores/typesense/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-typesense/llama_index/vector_stores/typesense/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-typesense/tests/test_vector_stores_typesense.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-upstash/llama_index/vector_stores/upstash/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-upstash/llama_index/vector_stores/upstash/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-upstash/tests/test_upstash.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-upstash/tests/test_vector_stores_upstash.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-vearch/llama_index/vector_stores/vearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-vearch/llama_index/vector_stores/vearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-vearch/tests/test_vector_stores_vearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-vectorx/llama_index/vector_stores/vectorx/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-vectorx/llama_index/vector_stores/vectorx/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-vectorx/tests/test_vector_stores_vectorx.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-vertexaivectorsearch/llama_index/vector_stores/vertexaivectorsearch/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-vertexaivectorsearch/llama_index/vector_stores/vertexaivectorsearch/_sdk_manager.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-vertexaivectorsearch/llama_index/vector_stores/vertexaivectorsearch/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-vertexaivectorsearch/llama_index/vector_stores/vertexaivectorsearch/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-vertexaivectorsearch/tests/test_vector_stores_vertexaivectorsearch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-vespa/llama_index/vector_stores/vespa/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-vespa/llama_index/vector_stores/vespa/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-vespa/tests/test_vespavectorstore.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-weaviate/llama_index/vector_stores/weaviate/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-weaviate/llama_index/vector_stores/weaviate/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-weaviate/llama_index/vector_stores/weaviate/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-weaviate/tests/test_to_weaviate_filter.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-weaviate/tests/test_vector_stores_weaviate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-wordlift/llama_index/vector_stores/wordlift/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-wordlift/llama_index/vector_stores/wordlift/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-wordlift/llama_index/vector_stores/wordlift/metadata_filters_to_filters.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-wordlift/tests/test_wordlift.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-zep/llama_index/vector_stores/zep/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-zep/llama_index/vector_stores/zep/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/vector_stores/llama-index-vector-stores-zep/tests/test_vector_stores_zep.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-elevenlabs/llama_index/voice_agents/elevenlabs/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-elevenlabs/llama_index/voice_agents/elevenlabs/events.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-elevenlabs/llama_index/voice_agents/elevenlabs/interface.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-elevenlabs/llama_index/voice_agents/elevenlabs/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-elevenlabs/tests/test_events.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-elevenlabs/tests/test_utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-gemini-live/llama_index/voice_agents/gemini_live/__init__.py",
        "providers": [
          "gemini"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-gemini-live/llama_index/voice_agents/gemini_live/audio_interface.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-gemini-live/llama_index/voice_agents/gemini_live/base.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-gemini-live/llama_index/voice_agents/gemini_live/events.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-gemini-live/llama_index/voice_agents/gemini_live/utils.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-gemini-live/tests/test_audio_interface.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-gemini-live/tests/test_utils.py",
        "providers": [
          "gemini",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-openai/llama_index/voice_agents/openai/__init__.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-openai/llama_index/voice_agents/openai/audio_interface.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-openai/llama_index/voice_agents/openai/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-openai/llama_index/voice_agents/openai/types.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-openai/llama_index/voice_agents/openai/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-openai/llama_index/voice_agents/openai/websocket.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-openai/tests/test_serialization.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-integrations/voice_agents/llama-index-voice-agents-openai/tests/test_utils.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-agent-search-retriever/examples/_example.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-agent-search-retriever/llama_index/packs/agent_search_retriever/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-agent-search-retriever/llama_index/packs/agent_search_retriever/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-amazon-product-extraction/llama_index/packs/amazon_product_extraction/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-amazon-product-extraction/llama_index/packs/amazon_product_extraction/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-amazon-product-extraction/tests/test_packs_amazon_product_extraction.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-arize-phoenix-query-engine/examples/example.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-arize-phoenix-query-engine/llama_index/packs/arize_phoenix_query_engine/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-arize-phoenix-query-engine/llama_index/packs/arize_phoenix_query_engine/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-arize-phoenix-query-engine/tests/test_packs_arize_phoenix_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-auto-merging-retriever/examples/example.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-auto-merging-retriever/llama_index/packs/auto_merging_retriever/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-auto-merging-retriever/llama_index/packs/auto_merging_retriever/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-auto-merging-retriever/tests/test_packs_auto_merging_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-chroma-autoretrieval/llama_index/packs/chroma_autoretrieval/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-chroma-autoretrieval/llama_index/packs/chroma_autoretrieval/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-chroma-autoretrieval/tests/test_packs_chroma_autoretrieval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-code-hierarchy/llama_index/packs/code_hierarchy/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-code-hierarchy/llama_index/packs/code_hierarchy/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-code-hierarchy/llama_index/packs/code_hierarchy/code_hierarchy.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-code-hierarchy/llama_index/packs/code_hierarchy/query_engine.py",
        "providers": [
          "langchain",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-code-hierarchy/tests/test_code_hierarchy_no_skeleton.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-code-hierarchy/tests/test_code_hierarchy_with_skeleton.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-code-hierarchy/tests/test_code_parse_nodes_special_characters.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-code-hierarchy/tests/test_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-code-hierarchy/tests/test_utility_methods.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-cohere-citation-chat/examples/example.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-cohere-citation-chat/llama_index/packs/cohere_citation_chat/__init__.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-cohere-citation-chat/llama_index/packs/cohere_citation_chat/base.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-cohere-citation-chat/llama_index/packs/cohere_citation_chat/citations_context_chat_engine.py",
        "providers": [
          "cohere",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-cohere-citation-chat/llama_index/packs/cohere_citation_chat/utils.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-cohere-citation-chat/tests/test_packs_cohere_citation_chat.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-deeplake-deepmemory-retriever/llama_index/packs/deeplake_deepmemory_retriever/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-deeplake-deepmemory-retriever/llama_index/packs/deeplake_deepmemory_retriever/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-deeplake-deepmemory-retriever/tests/test_packs_deeplake_deepmemory_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-deeplake-multimodal-retrieval/llama_index/packs/deeplake_multimodal_retrieval/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-deeplake-multimodal-retrieval/llama_index/packs/deeplake_multimodal_retrieval/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-deeplake-multimodal-retrieval/tests/test_packs_deeplake_multimodal_retrieval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-dense-x-retrieval/examples/example.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-dense-x-retrieval/llama_index/packs/dense_x_retrieval/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-dense-x-retrieval/llama_index/packs/dense_x_retrieval/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-dense-x-retrieval/tests/test_packs_dense_x_retrieval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-diff-private-simple-dataset/examples/symptom_2_disease/_create_symptom_2_disease_simple_dataset.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-diff-private-simple-dataset/examples/symptom_2_disease/_download_raw_symptom_2_disease_data.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-diff-private-simple-dataset/examples/symptom_2_disease/event_handler.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-diff-private-simple-dataset/examples/symptom_2_disease/main.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-diff-private-simple-dataset/llama_index/packs/diff_private_simple_dataset/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-diff-private-simple-dataset/llama_index/packs/diff_private_simple_dataset/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-diff-private-simple-dataset/llama_index/packs/diff_private_simple_dataset/events.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-diff-private-simple-dataset/llama_index/packs/diff_private_simple_dataset/templates.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-diff-private-simple-dataset/tests/test_packs_diff_private_examples_gen.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-diff-private-simple-dataset/tests/test_templates.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-evaluator-benchmarker/llama_index/packs/evaluator_benchmarker/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-evaluator-benchmarker/llama_index/packs/evaluator_benchmarker/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-evaluator-benchmarker/tests/test_packs_evaluator_benchmarker.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-fusion-retriever/examples/hybrid_fusion/example.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-fusion-retriever/examples/query_rewrite/example.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-fusion-retriever/llama_index/packs/fusion_retriever/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-fusion-retriever/llama_index/packs/fusion_retriever/hybrid_fusion/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-fusion-retriever/llama_index/packs/fusion_retriever/query_rewrite/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-fusion-retriever/tests/test_packs_fusion_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-fuzzy-citation/llama_index/packs/fuzzy_citation/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-fuzzy-citation/llama_index/packs/fuzzy_citation/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-fuzzy-citation/tests/test_packs_fuzzy_citation.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-gmail-openai-agent/llama_index/packs/gmail_openai_agent/__init__.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-gmail-openai-agent/llama_index/packs/gmail_openai_agent/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-gmail-openai-agent/tests/test_packs_gmail_openai_agent.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-koda-retriever/llama_index/packs/koda_retriever/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-koda-retriever/llama_index/packs/koda_retriever/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-koda-retriever/llama_index/packs/koda_retriever/constants.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-koda-retriever/tests/conftest.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-koda-retriever/tests/koda_mocking.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-koda-retriever/tests/monkeypatch.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-koda-retriever/tests/test_koda_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-llama-dataset-metadata/llama_index/packs/llama_dataset_metadata/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-llama-dataset-metadata/llama_index/packs/llama_dataset_metadata/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-llama-dataset-metadata/tests/test_packs_llama_dataset_metadata.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-llama-guard-moderator/llama_index/packs/llama_guard_moderator/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-llama-guard-moderator/llama_index/packs/llama_guard_moderator/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-llama-guard-moderator/tests/test_packs_llama_guard_moderator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-llava-completion/llama_index/packs/llava_completion/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-llava-completion/llama_index/packs/llava_completion/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-llava-completion/tests/test_packs_llava_completion.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-longrag/llama_index/packs/longrag/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-longrag/llama_index/packs/longrag/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-longrag/tests/test_packs_longrag.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-mixture-of-agents/llama_index/packs/mixture_of_agents/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-mixture-of-agents/llama_index/packs/mixture_of_agents/base.py",
        "providers": [
          "cohere",
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-mixture-of-agents/tests/test_packs_mixture_of_agents.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-multi-tenancy-rag/llama_index/packs/multi_tenancy_rag/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-multi-tenancy-rag/llama_index/packs/multi_tenancy_rag/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-multi-tenancy-rag/tests/test_packs_multi_tenancy_rag.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-multidoc-autoretrieval/llama_index/packs/multidoc_autoretrieval/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-multidoc-autoretrieval/llama_index/packs/multidoc_autoretrieval/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-multidoc-autoretrieval/tests/test_packs_multidoc_autoretrieval.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-nebulagraph-query-engine/llama_index/packs/nebulagraph_query_engine/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-nebulagraph-query-engine/llama_index/packs/nebulagraph_query_engine/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-nebulagraph-query-engine/tests/test_packs_nebulagraph_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-neo4j-query-engine/llama_index/packs/neo4j_query_engine/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-neo4j-query-engine/llama_index/packs/neo4j_query_engine/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-neo4j-query-engine/tests/test_packs_neo4j_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-node-parser-semantic-chunking/llama_index/packs/node_parser_semantic_chunking/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-node-parser-semantic-chunking/llama_index/packs/node_parser_semantic_chunking/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-node-parser-semantic-chunking/tests/test_packs_node_parser.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-ollama-query-engine/llama_index/packs/ollama_query_engine/__init__.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-ollama-query-engine/llama_index/packs/ollama_query_engine/base.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-ollama-query-engine/tests/test_packs_ollama_query_engine.py",
        "providers": [
          "llama",
          "ollama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-panel-chatbot/llama_index/packs/panel_chatbot/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-panel-chatbot/llama_index/packs/panel_chatbot/app.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-panel-chatbot/llama_index/packs/panel_chatbot/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-panel-chatbot/tests/test_packs_panel_chatbot.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-raft-dataset/llama_index/packs/raft_dataset/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-raft-dataset/llama_index/packs/raft_dataset/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-raft-dataset/tests/test_packs_raft_dataset.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-rag-evaluator/examples/example.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-rag-evaluator/llama_index/packs/rag_evaluator/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-rag-evaluator/llama_index/packs/rag_evaluator/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-rag-evaluator/tests/test_packs_rag_evaluator.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-ragatouille-retriever/llama_index/packs/ragatouille_retriever/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-ragatouille-retriever/llama_index/packs/ragatouille_retriever/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-ragatouille-retriever/tests/test_packs_ragatouille_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-raptor/llama_index/packs/raptor/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-raptor/llama_index/packs/raptor/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-raptor/llama_index/packs/raptor/clustering.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-raptor/tests_llamadev_ignore/test_packs_raptor.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-recursive-retriever/llama_index/packs/recursive_retriever/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-recursive-retriever/llama_index/packs/recursive_retriever/embedded_tables_unstructured/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-recursive-retriever/llama_index/packs/recursive_retriever/small_to_big/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-recursive-retriever/tests/test_packs_recursive_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-resume-screener/llama_index/packs/resume_screener/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-resume-screener/llama_index/packs/resume_screener/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-retry-engine-weaviate/llama_index/packs/retry_engine_weaviate/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-retry-engine-weaviate/llama_index/packs/retry_engine_weaviate/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-retry-engine-weaviate/tests/test_packs_retry_engine_weaviate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-searchain/llama_index/packs/searchain/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-searchain/llama_index/packs/searchain/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-searchain/tests/test_packs_searchain.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-self-discover/llama_index/packs/self_discover/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-self-discover/llama_index/packs/self_discover/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-self-discover/tests/test_packs_self_discover.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-self-rag/llama_index/packs/self_rag/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-self-rag/llama_index/packs/self_rag/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-self-rag/tests/test_packs_self_rag.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-sentence-window-retriever/llama_index/packs/sentence_window_retriever/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-sentence-window-retriever/llama_index/packs/sentence_window_retriever/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-sentence-window-retriever/tests/test_packs_sentence_window_retriever.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-snowflake-query-engine/llama_index/packs/snowflake_query_engine/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-snowflake-query-engine/llama_index/packs/snowflake_query_engine/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-snowflake-query-engine/tests/test_packs_snowflake_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-stock-market-data-query-engine/llama_index/packs/stock_market_data_query_engine/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-stock-market-data-query-engine/llama_index/packs/stock_market_data_query_engine/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-stock-market-data-query-engine/tests/test_packs_stock_market_data_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-streamlit-chatbot/llama_index/packs/streamlit_chatbot/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-streamlit-chatbot/llama_index/packs/streamlit_chatbot/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-streamlit-chatbot/tests/test_packs_streamlit_chatbot.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-sub-question-weaviate/llama_index/packs/sub_question_weaviate/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-sub-question-weaviate/llama_index/packs/sub_question_weaviate/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-sub-question-weaviate/tests/test_packs_sub_question_weaviate.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-timescale-vector-autoretrieval/llama_index/packs/timescale_vector_autoretrieval/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-timescale-vector-autoretrieval/llama_index/packs/timescale_vector_autoretrieval/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-trulens-eval-packs/llama_index/packs/trulens_eval_packs/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-trulens-eval-packs/llama_index/packs/trulens_eval_packs/base.py",
        "providers": [
          "cohere",
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-trulens-eval-packs/tests/test_packs_trulens_eval_packs.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-vectara-rag/llama_index/packs/vectara_rag/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-vectara-rag/llama_index/packs/vectara_rag/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-vectara-rag/tests/test_packs_vectara_rag.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-voyage-query-engine/examples/example.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-voyage-query-engine/llama_index/packs/voyage_query_engine/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-voyage-query-engine/llama_index/packs/voyage_query_engine/base.py",
        "providers": [
          "llama",
          "openai"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-voyage-query-engine/tests/test_packs_voyage_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-zenguard/llama_index/packs/zenguard/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-zenguard/llama_index/packs/zenguard/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-zenguard/tests/test_packs_zenguard.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-zephyr-query-engine/llama_index/packs/zephyr_query_engine/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-zephyr-query-engine/llama_index/packs/zephyr_query_engine/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-packs/llama-index-packs-zephyr-query-engine/tests/test_packs_zephyr_query_engine.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-utils/llama-index-utils-azure/llama_index/utils/azure/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-utils/llama-index-utils-huggingface/llama_index/utils/huggingface/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-utils/llama-index-utils-huggingface/llama_index/utils/huggingface/base.py",
        "providers": [
          "langchain"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-utils/llama-index-utils-oracleai/llama_index/utils/oracleai/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-utils/llama-index-utils-oracleai/llama_index/utils/oracleai/base.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-utils/llama-index-utils-oracleai/tests/test_utils_oracleai.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-utils/llama-index-utils-qianfan/llama_index/utils/qianfan/__init__.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-utils/llama-index-utils-qianfan/llama_index/utils/qianfan/apis.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-utils/llama-index-utils-qianfan/llama_index/utils/qianfan/client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-utils/llama-index-utils-qianfan/tests/test_apis.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-utils/llama-index-utils-qianfan/tests/test_authorization.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/llama-index-utils/llama-index-utils-qianfan/tests/test_client.py",
        "providers": [
          "llama"
        ]
      },
      {
        "file_path": "run-llama-llama_index-9831c7c/scripts/integration_health_check.py",
        "providers": [
          "llama",
          "openai"
        ]
      }
    ],
    "error": null
  }
}